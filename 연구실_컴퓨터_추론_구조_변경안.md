# ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ë° Orthanc ì €ì¥ êµ¬ì¡° ë³€ê²½ì•ˆ

## ğŸ“‹ ê°œìš”

í˜„ì¬ëŠ” **GCP ì„œë²„ì—ì„œ ì¶”ë¡ ì„ ì‹¤í–‰**í•˜ê³  ìˆì§€ë§Œ, **ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡ ì„ ì‹¤í–‰**í•˜ê³  ê²°ê³¼ë¥¼ **Orthancì— ì €ì¥**í•œ í›„, **GCPì—ì„œëŠ” Orthancì—ì„œ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°ë§Œ** í•˜ëŠ” êµ¬ì¡°ë¡œ ë³€ê²½í•˜ëŠ” ë°©ì•ˆì…ë‹ˆë‹¤.

---

## ğŸ”„ í˜„ì¬ êµ¬ì¡° vs ì œì•ˆ êµ¬ì¡°

### í˜„ì¬ êµ¬ì¡° (GCP ì„œë²„ì—ì„œ ì¶”ë¡ )
```
[í”„ë¡ íŠ¸ì—”ë“œ] 
    â†“
[Django (GCP)] 
    â†“
[Mosec ì¶”ë¡  ì„œë¹„ìŠ¤ (GCP)] â†’ ì¶”ë¡  ì‹¤í–‰
    â†“
[Orthanc (GCP)] â†’ ê²°ê³¼ ì €ì¥
    â†“
[Django (GCP)] â†’ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    â†“
[í”„ë¡ íŠ¸ì—”ë“œ]
```

**ë¬¸ì œì :**
- GCP ì„œë²„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© (CPU/ë©”ëª¨ë¦¬)
- ì¶”ë¡  ì‹œê°„ ë™ì•ˆ GCP ì„œë²„ ë¶€í•˜
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì‚¬ìš©

---

### ì œì•ˆ êµ¬ì¡° (ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡ )
```
[í”„ë¡ íŠ¸ì—”ë“œ]
    â†“
[Django (GCP)] â†’ ì¶”ë¡  ìš”ì²­ íì— ì¶”ê°€
    â†“
[ì—°êµ¬ì‹¤ ì»´í“¨í„°] â†’ Orthancì—ì„œ DICOM ë‹¤ìš´ë¡œë“œ
    â†“
[ì—°êµ¬ì‹¤ ì»´í“¨í„°] â†’ ì¶”ë¡  ì‹¤í–‰
    â†“
[ì—°êµ¬ì‹¤ ì»´í“¨í„°] â†’ Orthanc (GCP)ì— ê²°ê³¼ ì—…ë¡œë“œ
    â†“
[Django (GCP)] â†’ Orthancì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    â†“
[í”„ë¡ íŠ¸ì—”ë“œ]
```

**ì¥ì :**
- âœ… GCP ì„œë²„ ë¦¬ì†ŒìŠ¤ ì ˆì•½
- âœ… ì—°êµ¬ì‹¤ ì»´í“¨í„°ì˜ GPU í™œìš© ê°€ëŠ¥
- âœ… ì¶”ë¡  ì†ë„ í–¥ìƒ (ë¡œì»¬ GPU ì‚¬ìš© ì‹œ)
- âœ… GCP ë¹„ìš© ì ˆê°

---

## âœ… ê°€ëŠ¥ ì—¬ë¶€

**ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤!** 

í˜„ì¬ ì‹œìŠ¤í…œ êµ¬ì¡°ìƒ ë‹¤ìŒì´ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
1. âœ… Orthancì— DICOM SEG ì—…ë¡œë“œ ê¸°ëŠ¥ (`orthanc_client.upload_dicom()`)
2. âœ… Orthancì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥ (`get_segmentation_frames()`)
3. âœ… ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (`SegmentationInferencePipeline`)

ë”°ë¼ì„œ **ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ í›„ Orthancì— ì €ì¥**ë§Œ í•˜ë©´, GCP DjangoëŠ” ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ Orthancì—ì„œ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ› ï¸ í•„ìš”í•œ ê²ƒë“¤

### 1. ì—°êµ¬ì‹¤ ì»´í“¨í„° í™˜ê²½ êµ¬ì¶•

#### 1.1 Python í™˜ê²½ ì„¤ì •
```bash
# Python 3.8 ì´ìƒ í•„ìš”
python --version

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ë˜ëŠ”
venv\Scripts\activate  # Windows
```

#### 1.2 ì˜ì¡´ì„± ì„¤ì¹˜
```bash
cd backend/mri_segmentation
pip install -r src/requirements.txt

# ë˜ëŠ” ì§ì ‘ ì„¤ì¹˜
pip install torch torchvision monai
pip install nibabel scipy pydicom
pip install highdicom pydicom-seg
pip install requests
```

#### 1.3 ëª¨ë¸ íŒŒì¼ ì¤€ë¹„
```bash
# ëª¨ë¸ íŒŒì¼ì„ ì—°êµ¬ì‹¤ ì»´í“¨í„°ì— ë³µì‚¬
# ê²½ë¡œ: backend/mri_segmentation/src/best_model.pth
# ë˜ëŠ” backend/mri_segmentation/checkpoints/best_model.pth
```

---

### 2. Orthanc ì ‘ê·¼ ê¶Œí•œ ì„¤ì •

#### 2.1 ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ í™•ì¸
ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ GCP Orthanc ì„œë²„ì— ì ‘ê·¼ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤:

```bash
# GCP Orthanc ì„œë²„ ì£¼ì†Œ í™•ì¸
# í˜„ì¬: http://34.42.223.43:8042

# ì ‘ê·¼ í…ŒìŠ¤íŠ¸
curl http://34.42.223.43:8042/system
# ë˜ëŠ”
curl -u admin:admin123 http://34.42.223.43:8042/system
```

#### 2.2 ë°©í™”ë²½ ì„¤ì • (í•„ìš”ì‹œ)
GCP ë°©í™”ë²½ ê·œì¹™ì—ì„œ ì—°êµ¬ì‹¤ ì»´í“¨í„° IPë¥¼ í—ˆìš©í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- GCP Console â†’ VPC ë„¤íŠ¸ì›Œí¬ â†’ ë°©í™”ë²½ ê·œì¹™
- í¬íŠ¸ 8042 (Orthanc) í—ˆìš©

#### 2.3 ì¸ì¦ ì •ë³´
```python
ORTHANC_URL = "http://34.42.223.43:8042"
ORTHANC_USER = "admin"
ORTHANC_PASSWORD = "admin123"  # ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë³€ê²½
```

---

### 3. ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰í•  ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

#### 3.1 ê¸°ë³¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ (`local_inference.py`)

```python
"""
ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰í•˜ëŠ” ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
Orthancì—ì„œ DICOM ë‹¤ìš´ë¡œë“œ â†’ ì¶”ë¡  â†’ Orthancì— ì—…ë¡œë“œ
"""
import sys
import os
from pathlib import Path
import tempfile
import shutil
import requests
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent
SRC_DIR = BASE_DIR / "src"
sys.path.insert(0, str(SRC_DIR))

from inference_pipeline import SegmentationInferencePipeline
from orthanc_client import OrthancClient

# ì„¤ì •
ORTHANC_URL = "http://34.42.223.43:8042"
ORTHANC_USER = "admin"
ORTHANC_PASSWORD = "admin123"  # ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë³€ê²½
MODEL_PATH = SRC_DIR / "best_model.pth"

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
import torch
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
logger.info(f"Using device: {DEVICE}")


def download_dicom_series(orthanc_client, series_ids):
    """
    Orthancì—ì„œ 4ê°œ ì‹œë¦¬ì¦ˆì˜ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    
    Args:
        orthanc_client: OrthancClient ì¸ìŠ¤í„´ìŠ¤
        series_ids: 4ê°œ ì‹œë¦¬ì¦ˆ ID ë¦¬ìŠ¤íŠ¸
    
    Returns:
        temp_dir: ì„ì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (seq_0, seq_1, seq_2, seq_3 í´ë” í¬í•¨)
    """
    temp_dir = tempfile.mkdtemp(prefix="mri_seg_")
    logger.info(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±: {temp_dir}")
    
    for seq_idx, series_id in enumerate(series_ids):
        # ì‹œë¦¬ì¦ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        series_info = orthanc_client.get_series_info(series_id)
        instance_ids = series_info.get("Instances", [])
        
        if len(instance_ids) == 0:
            raise ValueError(f"ì‹œë¦¬ì¦ˆ {series_id}ì— ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹œí€€ìŠ¤ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
        seq_dir = Path(temp_dir) / f"seq_{seq_idx:02d}"
        seq_dir.mkdir(parents=True, exist_ok=True)
        
        # ê° ì¸ìŠ¤í„´ìŠ¤ì˜ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        logger.info(f"ì‹œí€€ìŠ¤ {seq_idx+1}/4: {len(instance_ids)}ê°œ ìŠ¬ë¼ì´ìŠ¤ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        for inst_idx, instance_id in enumerate(instance_ids):
            dicom_bytes = orthanc_client.get_instance_file(instance_id)
            dicom_path = seq_dir / f"slice_{inst_idx:04d}.dcm"
            with open(dicom_path, 'wb') as f:
                f.write(dicom_bytes)
            
            if (inst_idx + 1) % 20 == 0:
                logger.info(f"  {inst_idx+1}/{len(instance_ids)} ì™„ë£Œ")
        
        logger.info(f"âœ… ì‹œí€€ìŠ¤ {seq_idx+1}/4 ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    
    return temp_dir


def run_inference_local(series_ids):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰
    
    Args:
        series_ids: 4ê°œ ì‹œë¦¬ì¦ˆ ID ë¦¬ìŠ¤íŠ¸
    
    Returns:
        seg_instance_id: Orthancì— ì—…ë¡œë“œëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ID
    """
    try:
        # 1. Orthanc í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        orthanc_client = OrthancClient(
            base_url=ORTHANC_URL,
            username=ORTHANC_USER,
            password=ORTHANC_PASSWORD
        )
        
        # 2. Orthancì—ì„œ DICOM ë‹¤ìš´ë¡œë“œ
        logger.info("ğŸ“¥ Orthancì—ì„œ DICOM ë‹¤ìš´ë¡œë“œ ì¤‘...")
        temp_dir = download_dicom_series(orthanc_client, series_ids)
        
        try:
            # 3. ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            logger.info("ğŸ”„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")
            pipeline = SegmentationInferencePipeline(
                model_path=str(MODEL_PATH),
                device=DEVICE,
                threshold=0.5
            )
            
            # 4. ì¶”ë¡  ì‹¤í–‰
            logger.info("ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì¤‘...")
            seg_dicom_path = Path(temp_dir) / "segmentation.dcm"
            
            result = pipeline.predict(
                image_path=temp_dir,  # 4ê°œ seq_XX í´ë”ê°€ ìˆëŠ” ë£¨íŠ¸ í´ë”
                output_path=str(seg_dicom_path),
                output_format="dicom"
            )
            
            logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ: tumor_detected={result['tumor_detected']}, volume={result['tumor_volume_voxels']} voxels")
            
            # 5. DICOM SEGë¥¼ Orthancì— ì—…ë¡œë“œ
            logger.info("ğŸ“¤ Orthancì— ì—…ë¡œë“œ ì¤‘...")
            with open(seg_dicom_path, 'rb') as f:
                seg_dicom_bytes = f.read()
            
            upload_result = orthanc_client.upload_dicom(seg_dicom_bytes)
            seg_instance_id = upload_result.get('ID')
            
            logger.info(f"âœ… Orthanc ì—…ë¡œë“œ ì™„ë£Œ: {seg_instance_id}")
            
            return {
                'success': True,
                'seg_instance_id': seg_instance_id,
                'tumor_detected': result['tumor_detected'],
                'tumor_volume_voxels': result['tumor_volume_voxels']
            }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_dir and Path(temp_dir).exists():
                shutil.rmtree(temp_dir)
                logger.info("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            'success': False,
            'error': str(e)
        }


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì‹¤í–‰")
    parser.add_argument("--series-ids", nargs=4, required=True, 
                       help="4ê°œ ì‹œë¦¬ì¦ˆ ID (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)")
    
    args = parser.parse_args()
    
    result = run_inference_local(args.series_ids)
    print(f"\nê²°ê³¼: {result}")
```

#### 3.2 ì‚¬ìš© ë°©ë²•

```bash
# ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰
cd backend/mri_segmentation
python local_inference.py \
    --series-ids \
    "series-id-1" \
    "series-id-2" \
    "series-id-3" \
    "series-id-4"
```

---

### 4. Django ì—°ë™ (ì„ íƒì‚¬í•­)

ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡ ì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ë„ë¡ Djangoì™€ ì—°ë™í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

#### 4.1 ì¶”ë¡  í ì‹œìŠ¤í…œ (ì„ íƒì‚¬í•­)

**ì˜µì…˜ 1: ê°„ë‹¨í•œ íŒŒì¼ ê¸°ë°˜ í**
```python
# Djangoì—ì„œ ì¶”ë¡  ìš”ì²­ì„ JSON íŒŒì¼ë¡œ ì €ì¥
# ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸í•˜ì—¬ ì²˜ë¦¬
```

**ì˜µì…˜ 2: Redis í (ê³ ê¸‰)**
```python
# Django â†’ Redis íì— ì¶”ë¡  ìš”ì²­ ì¶”ê°€
# ì—°êµ¬ì‹¤ ì»´í“¨í„° â†’ Redis íì—ì„œ ìš”ì²­ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬
```

**ì˜µì…˜ 3: ì§ì ‘ API í˜¸ì¶œ**
```python
# ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ Django APIë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ í´ë§
# ìƒˆë¡œìš´ ì¶”ë¡  ìš”ì²­ì´ ìˆìœ¼ë©´ ì²˜ë¦¬
```

---

## ğŸ“ êµ¬í˜„ ë‹¨ê³„

### ë‹¨ê³„ 1: ì—°êµ¬ì‹¤ ì»´í“¨í„° í™˜ê²½ êµ¬ì¶•
1. âœ… Python í™˜ê²½ ì„¤ì •
2. âœ… ì˜ì¡´ì„± ì„¤ì¹˜
3. âœ… ëª¨ë¸ íŒŒì¼ ë³µì‚¬
4. âœ… Orthanc ì ‘ê·¼ í…ŒìŠ¤íŠ¸

### ë‹¨ê³„ 2: ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
1. âœ… `local_inference.py` ì‘ì„±
2. âœ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
3. âœ… Orthanc ì—…ë¡œë“œ í™•ì¸

### ë‹¨ê³„ 3: Django ìˆ˜ì • (ì„ íƒì‚¬í•­)
1. ì¶”ë¡  ìš”ì²­ í ì‹œìŠ¤í…œ êµ¬í˜„ (ì„ íƒ)
2. ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì²˜ë¦¬ ì™„ë£Œ í›„ Djangoì— ì•Œë¦¼ (ì„ íƒ)

### ë‹¨ê³„ 4: í…ŒìŠ¤íŠ¸
1. ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰
2. Orthancì— ê²°ê³¼ ì €ì¥ í™•ì¸
3. GCP Djangoì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° í™•ì¸
4. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê²°ê³¼ í‘œì‹œ í™•ì¸

---

## ğŸ”§ ìƒì„¸ êµ¬í˜„ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ìˆ˜ë™ ì‹¤í–‰ (ê°€ì¥ ê°„ë‹¨)

**ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ:**
```bash
# 1. Orthancì—ì„œ ì‹œë¦¬ì¦ˆ ID í™•ì¸ (ì›¹ UI ë˜ëŠ” API)
# 2. ì¶”ë¡  ì‹¤í–‰
python local_inference.py \
    --series-ids \
    "2d3aba01-388e3a29-38c2bec0-3bbae0ef-17be8283" \
    "series-id-2" \
    "series-id-3" \
    "series-id-4"

# 3. ê²°ê³¼ í™•ì¸
# seg_instance_idê°€ ì¶œë ¥ë¨
```

**GCP DjangoëŠ” ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ ì‚¬ìš©:**
```python
# segmentation_views.pyì˜ get_segmentation_frames() í•¨ìˆ˜ê°€
# Orthancì—ì„œ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜´ (ë³€ê²½ ë¶ˆí•„ìš”)
```

---

### ì˜ˆì‹œ 2: Django API ì—°ë™ (ìë™í™”)

**Djangoì— ì¶”ë¡  ìš”ì²­ API ì¶”ê°€:**
```python
# backend/mri_viewer/segmentation_views.py

@api_view(['POST'])
def request_local_inference(request, series_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­
    (ì‹¤ì œë¡œëŠ” íì— ì¶”ê°€í•˜ê±°ë‚˜ íŒŒì¼ë¡œ ì €ì¥)
    """
    sequence_series_ids = request.data.get("sequence_series_ids", [])
    
    # ì¶”ë¡  ìš”ì²­ì„ íŒŒì¼ë¡œ ì €ì¥ (ë˜ëŠ” Redis íì— ì¶”ê°€)
    request_data = {
        'series_ids': sequence_series_ids,
        'requested_at': timezone.now().isoformat(),
        'status': 'pending'
    }
    
    # íŒŒì¼ë¡œ ì €ì¥ (ê°„ë‹¨í•œ ë°©ë²•)
    request_file = Path('/tmp/inference_requests') / f"{series_id}.json"
    request_file.parent.mkdir(exist_ok=True)
    with open(request_file, 'w') as f:
        json.dump(request_data, f)
    
    return Response({
        'success': True,
        'message': 'ì¶”ë¡  ìš”ì²­ì´ íì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.',
        'series_id': series_id
    })
```

**ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸:**
```python
# local_inference_worker.py
import time
import json
from pathlib import Path

REQUEST_DIR = Path('/tmp/inference_requests')  # Djangoì™€ ê³µìœ  ë””ë ‰í† ë¦¬

while True:
    # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ í™•ì¸
    for request_file in REQUEST_DIR.glob("*.json"):
        with open(request_file, 'r') as f:
            request_data = json.load(f)
        
        if request_data['status'] == 'pending':
            # ì¶”ë¡  ì‹¤í–‰
            result = run_inference_local(request_data['series_ids'])
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            request_data['status'] = 'completed' if result['success'] else 'failed'
            request_data['result'] = result
            with open(request_file, 'w') as f:
                json.dump(request_data, f)
    
    time.sleep(10)  # 10ì´ˆë§ˆë‹¤ í™•ì¸
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. ë„¤íŠ¸ì›Œí¬ ì—°ê²°
- ì—°êµ¬ì‹¤ ì»´í“¨í„°ê°€ GCP Orthanc ì„œë²„ì— **ì•ˆì •ì ìœ¼ë¡œ ì ‘ê·¼** ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì´ ì¶”ë¡  ì‹œê°„ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤

### 2. ë™ì‹œì„± ì²˜ë¦¬
- ì—¬ëŸ¬ ì¶”ë¡  ìš”ì²­ì´ ë™ì‹œì— ë“¤ì–´ì˜¬ ê²½ìš° ì²˜ë¦¬ ë°©ë²• ê³ ë ¤ í•„ìš”
- í ì‹œìŠ¤í…œ ë˜ëŠ” ìˆœì°¨ ì²˜ë¦¬

### 3. ì—ëŸ¬ ì²˜ë¦¬
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¡œì§ í•„ìš”
- Orthanc ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ë°±ì—… ì €ì¥

### 4. ë³´ì•ˆ
- Orthanc ì¸ì¦ ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬
- ì—°êµ¬ì‹¤ ì»´í“¨í„°ì™€ GCP ì„œë²„ ê°„ í†µì‹  ì•”í˜¸í™” (HTTPS ê¶Œì¥)

---

## ğŸ“Š ë¹„êµí‘œ

| í•­ëª© | í˜„ì¬ êµ¬ì¡° (GCP ì¶”ë¡ ) | ì œì•ˆ êµ¬ì¡° (ì—°êµ¬ì‹¤ ì¶”ë¡ ) |
|------|---------------------|------------------------|
| **ì¶”ë¡  ìœ„ì¹˜** | GCP ì„œë²„ | ì—°êµ¬ì‹¤ ì»´í“¨í„° |
| **GCP ë¦¬ì†ŒìŠ¤ ì‚¬ìš©** | ë†’ìŒ (CPU/ë©”ëª¨ë¦¬) | ë‚®ìŒ (Orthancë§Œ) |
| **ì¶”ë¡  ì†ë„** | CPU ë˜ëŠ” ì œí•œëœ GPU | ì—°êµ¬ì‹¤ GPU í™œìš© ê°€ëŠ¥ |
| **ë¹„ìš©** | GCP ì»´í“¨íŒ… ë¹„ìš© ë°œìƒ | GCP ë¹„ìš© ì ˆê° |
| **êµ¬í˜„ ë³µì¡ë„** | ë‚®ìŒ (ì´ë¯¸ êµ¬í˜„ë¨) | ì¤‘ê°„ (ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ í•„ìš”) |
| **ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±** | ë‚®ìŒ (ê°™ì€ ì„œë²„) | ë†’ìŒ (ì—°êµ¬ì‹¤ â†” GCP) |
| **í™•ì¥ì„±** | ë†’ìŒ (GCP ìë™ ìŠ¤ì¼€ì¼ë§) | ì¤‘ê°„ (ì—°êµ¬ì‹¤ ì»´í“¨í„° ì„±ëŠ¥ì— ì˜ì¡´) |

---

## ğŸ¯ ê²°ë¡ 

**ê°€ëŠ¥í•©ë‹ˆë‹¤!** 

ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê³  Orthancì— ì €ì¥í•˜ëŠ” êµ¬ì¡°ë¡œ ë³€ê²½í•˜ë©´:
1. âœ… GCP ì„œë²„ ë¦¬ì†ŒìŠ¤ ì ˆì•½
2. âœ… ì—°êµ¬ì‹¤ GPU í™œìš© ê°€ëŠ¥
3. âœ… GCP ë¹„ìš© ì ˆê°
4. âœ… ê¸°ì¡´ Django ì½”ë“œ ë³€ê²½ ìµœì†Œí™” (Orthancì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°ë§Œ í•˜ë©´ ë¨)

**í•„ìš”í•œ ê²ƒ:**
1. ì—°êµ¬ì‹¤ ì»´í“¨í„° í™˜ê²½ êµ¬ì¶• (Python, ì˜ì¡´ì„±, ëª¨ë¸)
2. Orthanc ì ‘ê·¼ ê¶Œí•œ (ë„¤íŠ¸ì›Œí¬)
3. ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`local_inference.py`)
4. (ì„ íƒ) Djangoì™€ ì—°ë™í•˜ì—¬ ìë™í™”

**êµ¬í˜„ ë‚œì´ë„:** ì¤‘ê°„
- ê¸°ë³¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸: â­â­ (ì‰¬ì›€)
- Django ìë™í™” ì—°ë™: â­â­â­ (ì¤‘ê°„)

---

**ì‘ì„±ì¼**: 2026ë…„ 1ì›”
**ì‘ì„±ì**: AI Assistant

================================================================================
연구실 컴퓨터 MRI 추론 패키지 - 간단 사용법
================================================================================

📦 파일 위치:
/Users/nogeon-u/Desktop/건양대_바이오메디컬/Django/Django-React--main/연구실_컴퓨터_추론_패키지.zip
크기: 약 90MB

================================================================================
🚀 빠른 시작 (3단계)
================================================================================

1️⃣ 압축 해제
   cd ~
   unzip 연구실_컴퓨터_추론_패키지.zip
   cd 연구실_컴퓨터_추론_패키지/mri_segmentation

2️⃣ 환경 설정
   python -m venv venv
   source venv/bin/activate
   pip install -r src/requirements.txt
   cp env.example .env
   nano .env  # ORTHANC_PASSWORD 수정

3️⃣ 모델 파일 복사 (중요!)
   scp user@34.42.223.43:/path/to/best_model.pth src/

================================================================================
💻 추론 실행 방법
================================================================================

방법 1: 수동 실행 (테스트용)
---------------------------------------------------------------------------
python local_inference.py \
    --series-ids "series1" "series2" "series3" "series4"

방법 2: 자동 워커 (권장)
---------------------------------------------------------------------------
python local_inference_worker.py

방법 3: 백그라운드 실행
---------------------------------------------------------------------------
nohup python local_inference_worker.py > worker.log 2>&1 &

================================================================================
📁 패키지 내용
================================================================================

연구실_컴퓨터_추론_패키지/
├── README.md                           # 패키지 설명
├── 연구실_컴퓨터_추론_구조_변경안.md      # 전체 구조 설명
└── mri_segmentation/
    ├── local_inference.py              ⭐ 수동 추론 스크립트
    ├── local_inference_worker.py       ⭐ 자동 워커
    ├── env.example                     # 환경 변수 예시
    ├── README_LOCAL_INFERENCE.md       # 완전 가이드
    ├── 연구실_컴퓨터_실행_가이드.md        # 빠른 시작
    ├── 변경사항_요약.md                 # 변경 요약
    ├── systemd/
    │   └── mri-inference-worker.service # systemd 서비스
    └── src/
        ├── inference_pipeline.py       # 추론 파이프라인
        ├── inference_preprocess.py     # 전처리
        ├── inference_postprocess.py    # 후처리
        ├── requirements.txt            # Python 의존성
        ├── config.py                   # 설정
        └── best_model.pth              ⚠️ 약 500MB-1GB (별도 다운로드 필요)

================================================================================
⚠️ 중요 사항
================================================================================

1. 모델 파일 필수
   - src/best_model.pth 파일이 반드시 필요합니다
   - GCP 서버에서 복사하거나 다른 위치에서 가져오세요
   - 크기: 약 500MB-1GB

2. 환경 변수 설정
   - .env 파일에서 ORTHANC_PASSWORD를 실제 값으로 변경
   - chmod 600 .env (보안)

3. GPU 사용 (권장)
   - NVIDIA GPU가 있으면 훨씬 빠릅니다 (20초 vs 15분)
   - pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

================================================================================
📊 성능 비교
================================================================================

| 환경              | 디바이스      | 추론 시간 |
|-------------------|--------------|----------|
| 연구실 (RTX 4090) | GPU          | ~20초    |
| 연구실 (RTX 3090) | GPU          | ~30초    |
| 연구실 (i9 CPU)   | CPU          | ~15분    |
| GCP (4 vCPU)      | CPU          | ~20분    |

================================================================================
🔧 문제 해결
================================================================================

Q1. ModuleNotFoundError
    → pip install -r src/requirements.txt

Q2. 모델 파일 없음
    → scp user@server:/path/to/best_model.pth src/

Q3. Orthanc 연결 실패
    → ping 34.42.223.43
    → curl http://34.42.223.43:8042/system

Q4. GPU 인식 안 됨
    → nvidia-smi
    → python -c "import torch; print(torch.cuda.is_available())"

================================================================================
📖 상세 문서
================================================================================

- README.md                      → 패키지 개요
- README_LOCAL_INFERENCE.md      → 완전한 설치/설정 가이드
- 연구실_컴퓨터_실행_가이드.md      → 빠른 시작 가이드
- 변경사항_요약.md                → 변경 사항 요약
- 연구실_컴퓨터_추론_구조_변경안.md → 전체 구조 및 배경

================================================================================
💡 팁
================================================================================

1. 먼저 수동 실행으로 테스트하세요
   python local_inference.py --series-ids id1 id2 id3 id4

2. 정상 작동 확인 후 워커 실행
   python local_inference_worker.py

3. 프로덕션에서는 systemd 서비스 사용
   sudo systemctl enable mri-inference-worker
   sudo systemctl start mri-inference-worker

================================================================================
✅ 체크리스트
================================================================================

설치:
□ 압축 해제 완료
□ Python 가상환경 생성
□ 의존성 설치 완료
□ 모델 파일 복사 완료 ⚠️ 중요!
□ .env 파일 설정 완료

테스트:
□ Orthanc 연결 테스트
□ 수동 추론 실행 성공
□ 결과가 Orthanc에 업로드됨

프로덕션:
□ 워커 자동 실행 설정
□ systemd 서비스 등록 (선택)
□ 로그 모니터링 설정

================================================================================

생성일: 2026년 1월
버전: 1.0.0

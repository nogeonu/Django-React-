"""
ë³‘ë¦¬ ì´ë¯¸ì§€ ë¡œì»¬ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
Orthancì—ì„œ ì›ë³¸ SVS íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì•„ ì¶”ë¡  ì‹¤í–‰

ì‚¬ìš©ë²•:
    python local_inference.py --instance-id <instance_id>
    
    ë˜ëŠ”
    
    python local_inference.py --instance-id <instance_id> --device cuda
"""
import sys
import os
from pathlib import Path
import requests
import logging
import argparse
from typing import Dict, Any, Optional
import glob

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent
SRC_DIR = BASE_DIR / "src"
sys.path.insert(0, str(SRC_DIR))

# í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’
ORTHANC_URL = os.getenv("ORTHANC_URL", "http://34.42.223.43:8042")
ORTHANC_USER = os.getenv("ORTHANC_USER", "admin")
ORTHANC_PASSWORD = os.getenv("ORTHANC_PASSWORD", "admin123")

# ëª¨ë¸ ê²½ë¡œ (CLAM ëª¨ë¸)
MODEL_PATH = os.getenv("MODEL_PATH", str(SRC_DIR / "best_model.pth"))

# GPU í™•ì¸
try:
    import torch
    GPU_AVAILABLE = torch.cuda.is_available()
    if GPU_AVAILABLE:
        logger.info(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
    else:
        logger.info("â„¹ï¸ GPU ì‚¬ìš© ë¶ˆê°€, CPU ëª¨ë“œë¡œ ì‹¤í–‰")
except ImportError:
    logger.warning("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    GPU_AVAILABLE = False


def get_svs_file_path(instance_id: str) -> Optional[str]:
    """
    Orthancì—ì„œ ì›ë³¸ SVS íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    
    Args:
        instance_id: Orthanc instance ID
    
    Returns:
        ì›ë³¸ SVS íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        # Orthancì—ì„œ DICOM ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        logger.info(f"ğŸ“¥ Orthancì—ì„œ DICOM ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì¤‘...")
        metadata_response = requests.get(
            f"{ORTHANC_URL}/instances/{instance_id}/tags?simplify",
            auth=(ORTHANC_USER, ORTHANC_PASSWORD),
            timeout=30
        )
        
        if metadata_response.status_code != 200:
            logger.error(f"âŒ Orthanc ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {metadata_response.status_code}")
            return None
        
        metadata = metadata_response.json()
        
        # Private Tagì—ì„œ ì›ë³¸ SVS ê²½ë¡œ ì¶”ì¶œ (0011,1001)
        original_svs_path = metadata.get('0011,1001')
        
        # Private Tagê°€ ì—†ìœ¼ë©´ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰
        if not original_svs_path:
            logger.warning(f"âš ï¸ DICOMì— ì›ë³¸ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì‹œìŠ¤í…œ ê²€ìƒ‰ ì¤‘...")
            
            # í™˜ì IDì™€ Series Descriptionì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            patient_id = metadata.get('PatientID', '')
            series_desc = metadata.get('SeriesDescription', '')
            
            # Series Descriptionì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ (ì˜ˆ: "Pathology WSI - xxx.svs")
            if ' - ' in series_desc:
                original_filename = series_desc.split(' - ', 1)[1]
                
                # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰
                SVS_STORAGE_DIR = os.getenv('SVS_STORAGE_DIR', '/home/shrjsdn908/pathology_images')
                if os.path.exists(SVS_STORAGE_DIR):
                    # íŒ¨í„´: {patient_id}_*_{original_filename}
                    pattern = os.path.join(SVS_STORAGE_DIR, f"{patient_id}_*_{original_filename}")
                    matching_files = glob.glob(pattern)
                    
                    if matching_files:
                        original_svs_path = matching_files[0]  # ì²« ë²ˆì§¸ ë§¤ì¹­ íŒŒì¼ ì‚¬ìš©
                        logger.info(f"âœ… íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë°œê²¬: {original_svs_path}")
        
        if not original_svs_path or not os.path.exists(original_svs_path):
            logger.error(f"âŒ ì›ë³¸ SVS íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_svs_path}")
            return None
        
        logger.info(f"âœ… ì›ë³¸ SVS íŒŒì¼ ê²½ë¡œ: {original_svs_path}")
        return original_svs_path
        
    except Exception as e:
        logger.error(f"âŒ SVS íŒŒì¼ ê²½ë¡œ ì°¾ê¸° ì‹¤íŒ¨: {str(e)}")
        return None


def run_inference_local(filename: str, device: str = "cuda") -> Dict[str, Any]:
    """
    ë³‘ë¦¬ ì´ë¯¸ì§€ ë¡œì»¬ ì¶”ë¡  ì‹¤í–‰ (êµìœ¡ì› ì›Œì»¤ìš©)
    
    Args:
        filename: wsi/ í´ë”ì—ì„œ ì°¾ì„ íŒŒì¼ëª… (ì˜ˆ: "tumor_083.tif" ë˜ëŠ” "2024/01/case1.tif")
        device: 'cuda' or 'cpu'
    
    Returns:
        ì¶”ë¡  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # 1. wsi/ í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸°
        WSI_DIR = Path(os.getenv("WSI_DIR", "wsi"))  # ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ wsi/ í´ë”
        svs_file_path = WSI_DIR / filename
        
        if not svs_file_path.exists():
            logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {svs_file_path}")
            return {
                'success': False,
                'error': f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename} (wsi/ í´ë” í™•ì¸ í•„ìš”)',
                'class_id': None,
                'class_name': None,
                'confidence': 0.0,
                'probabilities': {},
                'num_patches': 0,
                'top_attention_patches': []
            }
        
        logger.info(f"âœ… íŒŒì¼ ë°œê²¬: {svs_file_path}")
        
        # 2. CLAM ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
        logger.info(f"ğŸš€ ì¶”ë¡  ì‹œì‘: {svs_file_path}")
        
        # CLAM ëª¨ë¸ ì¶”ë¡  (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ì¸í„°í˜ì´ìŠ¤ë§Œ ì •ì˜í•˜ê³ , ì‹¤ì œ ëª¨ë¸ ì½”ë“œëŠ” ë³„ë„ë¡œ í†µí•© í•„ìš”
        result = run_clam_inference(str(svs_file_path), device)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            'success': False,
            'error': str(e),
            'class_id': None,
            'class_name': None,
            'confidence': 0.0,
            'probabilities': {},
            'num_patches': 0,
            'top_attention_patches': []
        }


def run_clam_inference(svs_file_path: str, device: str = "cuda") -> Dict[str, Any]:
    """
    CLAM ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
    
    Args:
        svs_file_path: ì›ë³¸ SVS íŒŒì¼ ê²½ë¡œ
        device: 'cuda' or 'cpu'
    
    Returns:
        ì¶”ë¡  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    
    Note:
        ì‹¤ì œ CLAM ëª¨ë¸ ì½”ë“œë¥¼ ì—¬ê¸°ì— í†µí•©í•´ì•¼ í•©ë‹ˆë‹¤.
        í˜„ì¬ëŠ” ì¸í„°í˜ì´ìŠ¤ë§Œ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        # TODO: CLAM ëª¨ë¸ ì½”ë“œ í†µí•© í•„ìš”
        # ì˜ˆì‹œ êµ¬ì¡°:
        # 1. SVS íŒŒì¼ ë¡œë“œ
        # 2. íŒ¨ì¹˜ ì¶”ì¶œ (224x224, ìµœëŒ€ 1000ê°œ)
        # 3. Feature ì¶”ì¶œ (H-optimus-0)
        # 4. CLAM ëª¨ë¸ë¡œ ë¶„ë¥˜
        # 5. Attention íŒ¨ì¹˜ ì¶”ì¶œ
        
        logger.warning("âš ï¸ CLAM ëª¨ë¸ ì½”ë“œê°€ ì•„ì§ í†µí•©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.warning("âš ï¸ ì‹¤ì œ ì¶”ë¡ ì„ ìœ„í•´ì„œëŠ” CLAM ëª¨ë¸ ì½”ë“œë¥¼ í†µí•©í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        # ì„ì‹œ ë”ë¯¸ ê²°ê³¼ (ì‹¤ì œ êµ¬í˜„ ì „ê¹Œì§€)
        return {
            'success': False,
            'error': 'CLAM ëª¨ë¸ ì½”ë“œê°€ ì•„ì§ í†µí•©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
            'class_id': None,
            'class_name': None,
            'confidence': 0.0,
            'probabilities': {},
            'num_patches': 0,
            'top_attention_patches': []
        }
        
        # ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ (ì£¼ì„ ì²˜ë¦¬):
        # from src.models.clam_model import CLAMInference
        # 
        # model = CLAMInference(model_path=MODEL_PATH, device=device)
        # result = model.predict(svs_file_path)
        # 
        # return {
        #     'success': True,
        #     'class_id': result['class_id'],
        #     'class_name': result['class_name'],
        #     'confidence': result['confidence'],
        #     'probabilities': result['probabilities'],
        #     'num_patches': result['num_patches'],
        #     'top_attention_patches': result['top_attention_patches']
        # }
        
    except Exception as e:
        logger.error(f"âŒ CLAM ì¶”ë¡  ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            'success': False,
            'error': str(e),
            'class_id': None,
            'class_name': None,
            'confidence': 0.0,
            'probabilities': {},
            'num_patches': 0,
            'top_attention_patches': []
        }


def main():
    """ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(description="ë³‘ë¦¬ ì´ë¯¸ì§€ ë¡œì»¬ ì¶”ë¡ ")
    parser.add_argument("--filename", required=True, help="wsi/ í´ë”ì—ì„œ ì°¾ì„ íŒŒì¼ëª… (ì˜ˆ: tumor_083.tif)")
    parser.add_argument("--device", default="cuda", choices=["cuda", "cpu"], help="ë””ë°”ì´ìŠ¤")
    
    args = parser.parse_args()
    
    # ì¶”ë¡  ì‹¤í–‰
    result = run_inference_local(args.filename, args.device)
    
    # ê²°ê³¼ ì¶œë ¥
    if result.get('success'):
        print("\nâœ… ì¶”ë¡  ì™„ë£Œ!")
        print(f"í´ë˜ìŠ¤: {result.get('class_name')}")
        print(f"ì‹ ë¢°ë„: {result.get('confidence'):.4f}")
        print(f"íŒ¨ì¹˜ ìˆ˜: {result.get('num_patches')}")
    else:
        print(f"\nâŒ ì¶”ë¡  ì‹¤íŒ¨: {result.get('error')}")


if __name__ == "__main__":
    main()

# 🚀 병리 이미지 추론 자동화 빠른 시작 가이드

## ✅ 프론트엔드 자동 연동 완료!

**프론트엔드에서 "AI 분석" 버튼을 누르면 자동으로 교육원 컴퓨터에서 추론됩니다!**

---

## 🎯 3단계로 시작하기

### 1단계: 환경 설정

```bash
cd ~/연구실_컴퓨터_추론_패키지/pathology_inference

# 가상환경 생성
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 의존성 설치
pip install -r requirements.txt

# GPU 버전 (권장)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# 환경 변수 설정
cp env.example .env
nano .env  # ORTHANC_PASSWORD, DJANGO_API_URL 수정
```

### 2단계: 모델 파일 복사

```bash
# GCP 서버에서 모델 파일 복사
scp user@34.42.223.43:/path/to/clam_model.pth src/best_model.pth

# 모델 파일 확인
ls -lh src/best_model.pth
```

### 3단계: 워커 실행

```bash
# 백그라운드 실행
nohup python local_inference_worker_http.py > worker.log 2>&1 &

# 또는 systemd 서비스 (권장)
sudo cp systemd/pathology-inference-worker.service /etc/systemd/system/
# 파일 내 경로 수정 후:
sudo systemctl daemon-reload
sudo systemctl enable pathology-inference-worker
sudo systemctl start pathology-inference-worker
```

**✅ 이제 프론트엔드에서 "AI 분석" 버튼을 누르면 자동으로 추론됩니다!**

---

## 🔄 동작 방식

```
[프론트엔드] "AI 분석" 버튼 클릭
    ↓
[Django] 자동으로 교육원 컴퓨터 요청 생성
    ↓
[교육원 컴퓨터 워커] 30초마다 자동 확인 → 요청 발견
    ↓
[교육원 컴퓨터 워커] 자동 처리:
  - Orthanc에서 원본 SVS 경로 찾기
  - 추론 실행 (GPU: 2-5분)
  - 결과를 Django API로 업로드
    ↓
[Django] 완료 확인 (최대 10분 대기)
    ↓
[프론트엔드] 결과 표시 ✅
```

---

## ⚙️ GCP Django 서버 설정 (한 번만)

**GCP 서버에서:**

```bash
# 환경 변수 설정
export USE_LOCAL_INFERENCE=true

# Django 재시작
sudo systemctl restart gunicorn
```

---

## ✅ 확인 방법

### 워커 실행 확인

```bash
# 프로세스 확인
ps aux | grep local_inference_worker_http

# 로그 확인
tail -f worker.log

# systemd 서비스 확인
sudo systemctl status pathology-inference-worker
```

### 요청 처리 확인

```bash
# 요청 파일 확인 (Django 서버에서)
ls -lh /tmp/pathology_inference_requests/

# 로그에서 처리 확인
tail -f worker.log | grep "요청 처리"
```

---

## 📊 처리 시간

- **GPU 사용 시**: 약 3-6분
- **CPU 사용 시**: 약 10-20분

---

## 🔧 문제 해결

### 워커가 요청을 처리하지 않음

```bash
# 1. 워커 실행 확인
ps aux | grep local_inference_worker_http

# 2. Django API 연결 확인
curl http://34.42.223.43/api/pathology/pending-requests/

# 3. 로그 확인
tail -f worker.log

# 4. 환경 변수 확인
cat .env
```

### Django가 타임아웃 응답

- 워커가 실행 중인지 확인
- 추론 시간이 10분 초과 시 정상 (나중에 상태 확인 가능)
- 네트워크 연결 확인

### CLAM 모델 코드 통합 필요

**중요:** 현재 워커 구조는 완성되었으나, 실제 CLAM 모델 추론 코드는 아직 통합되지 않았습니다.

**통합 필요:**
1. CLAM 모델 코드를 `src/models/clam_model.py`에 추가
2. `local_inference.py`의 `run_clam_inference()` 함수에 실제 추론 로직 구현

---

## 💡 핵심 포인트

1. **프론트엔드 코드 변경 불필요** ✅
   - 기존 "AI 분석" 버튼 그대로 사용

2. **워커만 실행 중이면 자동 작동** ✅
   - 교육원 컴퓨터에서 워커 실행
   - 30초마다 자동으로 요청 확인 및 처리

3. **결과 자동 업로드** ✅
   - 추론 완료 후 자동으로 Django API로 업로드
   - 프론트엔드에서 자동으로 결과 표시

---

## 📖 상세 가이드

- `HTTP_API_방식_설정_가이드.md` - 완전한 설정 가이드
- `README.md` - 전체 사용 가이드

---

**워커만 실행 중이면 자동으로 작동합니다!** 🚀

**주의:** CLAM 모델 코드 통합이 필요합니다!

# ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡  êµ¬ì¡° ë³€ê²½ - ì™„ë£Œ ìš”ì•½

## âœ… ë³€ê²½ ì™„ë£Œ ë‚´ì—­

### 1. ìƒì„±ëœ íŒŒì¼

#### ì¶”ë¡  ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸
- âœ… `local_inference.py` - ì—°êµ¬ì‹¤ ì»´í“¨í„°ìš© ì¶”ë¡  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
- âœ… `local_inference_worker.py` - ìë™ ì¶”ë¡  ì›Œì»¤ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
- âœ… `env.example` - í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì‹œ íŒŒì¼

#### ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤
- âœ… `systemd/mri-inference-worker.service` - systemd ì„œë¹„ìŠ¤ íŒŒì¼

#### ë¬¸ì„œ
- âœ… `README_LOCAL_INFERENCE.md` - ì™„ì „ ê°€ì´ë“œ (ì„¤ì¹˜, ì„¤ì •, ì‚¬ìš©ë²•)
- âœ… `ì—°êµ¬ì‹¤_ì»´í“¨í„°_ì‹¤í–‰_ê°€ì´ë“œ.md` - ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
- âœ… `ë³€ê²½ì‚¬í•­_ìš”ì•½.md` - ì´ íŒŒì¼

### 2. ìˆ˜ì •ëœ íŒŒì¼

#### Django API
- âœ… `backend/mri_viewer/segmentation_views.py` - ì¶”ë¡  ìš”ì²­ API ì¶”ê°€
  - `request_local_inference()` - ì¶”ë¡  ìš”ì²­ ìƒì„±
  - `check_inference_status()` - ìƒíƒœ í™•ì¸
  - `list_inference_requests()` - ìš”ì²­ ëª©ë¡ ì¡°íšŒ

- âœ… `backend/mri_viewer/urls.py` - URL ë¼ìš°íŒ… ì¶”ê°€
  - `POST /api/mri/segmentation/series/<series_id>/request-local/`
  - `GET /api/mri/segmentation/status/<request_id>/`
  - `GET /api/mri/segmentation/requests/`

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: ìˆ˜ë™ ì‹¤í–‰ (ê°„ë‹¨, í…ŒìŠ¤íŠ¸ìš©)

```bash
cd backend/mri_segmentation

# ì¶”ë¡  ì‹¤í–‰
python local_inference.py \
    --series-ids \
    "series-id-1" \
    "series-id-2" \
    "series-id-3" \
    "series-id-4"
```

### ë°©ë²• 2: ìë™ ì›Œì»¤ (ê¶Œì¥, í”„ë¡œë•ì…˜)

```bash
# 1. ì›Œì»¤ ì‹¤í–‰ (í¬ê·¸ë¼ìš´ë“œ)
python local_inference_worker.py

# 2. ë˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup python local_inference_worker.py > worker.log 2>&1 &

# 3. ë˜ëŠ” systemd ì„œë¹„ìŠ¤ë¡œ ì‹¤í–‰ (ê¶Œì¥)
sudo systemctl start mri-inference-worker
sudo systemctl enable mri-inference-worker
```

### ë°©ë²• 3: Django API ì—°ë™ (ìë™í™”)

#### í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìš”ì²­
```typescript
// ì¶”ë¡  ìš”ì²­
const response = await fetch('/api/mri/segmentation/series/{series_id}/request-local/', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    sequence_series_ids: [series1, series2, series3, series4]
  })
});

const data = await response.json();
// { success: true, request_id: "...", status: "pending" }

// ìƒíƒœ í™•ì¸
const statusResponse = await fetch(`/api/mri/segmentation/status/${data.request_id}/`);
const statusData = await statusResponse.json();
// { status: "completed", result: { seg_instance_id: "..." } }
```

#### Djangoì—ì„œ ì§ì ‘ ìš”ì²­
```python
import requests

# ì¶”ë¡  ìš”ì²­
response = requests.post(
    'http://localhost:8000/api/mri/segmentation/series/series-id-1/request-local/',
    json={
        'sequence_series_ids': ['series1', 'series2', 'series3', 'series4']
    }
)

# ìƒíƒœ í™•ì¸
status_response = requests.get(
    f'http://localhost:8000/api/mri/segmentation/status/{response.json()["request_id"]}/'
)
```

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
backend/mri_segmentation/
â”œâ”€â”€ local_inference.py          # ğŸ‘ˆ NEW: ìˆ˜ë™ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ local_inference_worker.py   # ğŸ‘ˆ NEW: ìë™ ì›Œì»¤
â”œâ”€â”€ env.example                 # ğŸ‘ˆ NEW: í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ
â”œâ”€â”€ systemd/
â”‚   â””â”€â”€ mri-inference-worker.service  # ğŸ‘ˆ NEW: systemd ì„œë¹„ìŠ¤
â”œâ”€â”€ README_LOCAL_INFERENCE.md   # ğŸ‘ˆ NEW: ì™„ì „ ê°€ì´ë“œ
â”œâ”€â”€ ì—°êµ¬ì‹¤_ì»´í“¨í„°_ì‹¤í–‰_ê°€ì´ë“œ.md     # ğŸ‘ˆ NEW: ë¹ ë¥¸ ê°€ì´ë“œ
â”œâ”€â”€ ë³€ê²½ì‚¬í•­_ìš”ì•½.md             # ğŸ‘ˆ NEW: ì´ íŒŒì¼
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ inference_pipeline.py  # ê¸°ì¡´: ì¶”ë¡  íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ best_model.pth          # ëª¨ë¸ íŒŒì¼ (ë³„ë„ ë‹¤ìš´ë¡œë“œ í•„ìš”)
â”‚   â””â”€â”€ ...
â””â”€â”€ ...

backend/mri_viewer/
â”œâ”€â”€ segmentation_views.py       # ğŸ‘ˆ MODIFIED: API ì¶”ê°€
â”œâ”€â”€ urls.py                     # ğŸ‘ˆ MODIFIED: URL ì¶”ê°€
â””â”€â”€ ...
```

---

## ğŸ”„ ì „ì²´ ì›Œí¬í”Œë¡œìš°

### ìˆ˜ë™ ëª¨ë“œ
```
1. [í”„ë¡ íŠ¸ì—”ë“œ] ì‚¬ìš©ìê°€ 4ê°œ ì‹œë¦¬ì¦ˆ ì„ íƒ
   â†“
2. [ì‚¬ìš©ì] Orthancì—ì„œ ì‹œë¦¬ì¦ˆ ID í™•ì¸
   â†“
3. [ì—°êµ¬ì‹¤ ì»´í“¨í„°] local_inference.py ìˆ˜ë™ ì‹¤í–‰
   â†“
4. [ì—°êµ¬ì‹¤ ì»´í“¨í„°] Orthancì—ì„œ DICOM ë‹¤ìš´ë¡œë“œ â†’ ì¶”ë¡  â†’ ì—…ë¡œë“œ
   â†“
5. [GCP Django] Orthancì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
   â†“
6. [í”„ë¡ íŠ¸ì—”ë“œ] ê²°ê³¼ í‘œì‹œ
```

### ìë™ ëª¨ë“œ (ì›Œì»¤)
```
1. [í”„ë¡ íŠ¸ì—”ë“œ] "AI ë¶„ì„" ë²„íŠ¼ í´ë¦­
   â†“
2. [Django] ì¶”ë¡  ìš”ì²­ JSON íŒŒì¼ ìƒì„± (/tmp/mri_inference_requests/)
   â†“
3. [ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤] 30ì´ˆë§ˆë‹¤ ìš”ì²­ í™•ì¸ (ìë™)
   â†“
4. [ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤] ìš”ì²­ ë°œê²¬ â†’ ìë™ ì²˜ë¦¬
   â†“
5. [ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤] Orthancì—ì„œ DICOM ë‹¤ìš´ë¡œë“œ â†’ ì¶”ë¡  â†’ ì—…ë¡œë“œ
   â†“
6. [ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤] ìš”ì²­ ìƒíƒœë¥¼ 'completed'ë¡œ ë³€ê²½
   â†“
7. [í”„ë¡ íŠ¸ì—”ë“œ] ìƒíƒœ API í˜¸ì¶œí•˜ì—¬ ì™„ë£Œ í™•ì¸
   â†“
8. [GCP Django] Orthancì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
   â†“
9. [í”„ë¡ íŠ¸ì—”ë“œ] ê²°ê³¼ í‘œì‹œ
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | GCP ì¶”ë¡  (ì´ì „) | ì—°êµ¬ì‹¤ ì¶”ë¡  (í˜„ì¬) |
|------|----------------|-------------------|
| **ì¶”ë¡  ìœ„ì¹˜** | GCP ì„œë²„ | ì—°êµ¬ì‹¤ ì»´í“¨í„° |
| **ë¦¬ì†ŒìŠ¤** | GCP CPU/ë©”ëª¨ë¦¬ | ì—°êµ¬ì‹¤ GPU |
| **ì¶”ë¡  ì‹œê°„** | ~20ë¶„ (CPU) | ~30ì´ˆ (GPU) |
| **GCP ë¹„ìš©** | ë†’ìŒ | ë‚®ìŒ (Orthancë§Œ) |
| **í™•ì¥ì„±** | ë†’ìŒ | ì¤‘ê°„ |
| **ë„¤íŠ¸ì›Œí¬ ì˜ì¡´** | ë‚®ìŒ | ë†’ìŒ |

---

## ğŸ”§ ì„¤ì¹˜ ê°€ì´ë“œ (ì—°êµ¬ì‹¤ ì»´í“¨í„°)

### 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •
```bash
cd backend/mri_segmentation

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r src/requirements.txt

# GPU ë²„ì „ PyTorch (NVIDIA GPUê°€ ìˆëŠ” ê²½ìš°)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 2ë‹¨ê³„: ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
```bash
# GCP ì„œë²„ì—ì„œ ë³µì‚¬
scp user@34.42.223.43:/srv/django-react/app/backend/mri_segmentation/src/best_model.pth src/
```

### 3ë‹¨ê³„: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
cp env.example .env

# .env íŒŒì¼ ìˆ˜ì •
nano .env
```

### 4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# Orthanc ì—°ê²° í…ŒìŠ¤íŠ¸
curl -u admin:password http://34.42.223.43:8042/system

# ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ìˆ˜ë™)
python local_inference.py \
    --series-ids test1 test2 test3 test4

# ì›Œì»¤ ì‹¤í–‰ (ìë™)
python local_inference_worker.py
```

---

## ğŸ¯ API ëª…ì„¸

### 1. ì¶”ë¡  ìš”ì²­ ìƒì„±
```http
POST /api/mri/segmentation/series/{series_id}/request-local/
Content-Type: application/json

{
  "sequence_series_ids": [
    "series-id-1",
    "series-id-2",
    "series-id-3",
    "series-id-4"
  ]
}
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "message": "ì¶”ë¡  ìš”ì²­ì´ íì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.",
  "request_id": "series-id-1_1704067200000",
  "series_id": "series-id-1",
  "status": "pending"
}
```

### 2. ìƒíƒœ í™•ì¸
```http
GET /api/mri/segmentation/status/{request_id}/
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "request_id": "series-id-1_1704067200000",
  "status": "completed",
  "message": "ì™„ë£Œ: ì¶”ë¡ ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
  "requested_at": "2024-01-01T00:00:00",
  "started_at": "2024-01-01T00:00:30",
  "completed_at": "2024-01-01T00:01:00",
  "result": {
    "success": true,
    "seg_instance_id": "abc123-def456",
    "tumor_detected": true,
    "tumor_volume_voxels": 12345,
    "elapsed_time_seconds": 30.5
  }
}
```

### 3. ìš”ì²­ ëª©ë¡ ì¡°íšŒ
```http
GET /api/mri/segmentation/requests/?status=completed&limit=20
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "count": 5,
  "requests": [
    {
      "request_id": "series-id-1_1704067200000",
      "status": "completed",
      "requested_at": "2024-01-01T00:00:00",
      "has_result": true
    }
  ]
}
```

---

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **ì¸ì¦ ì •ë³´ ë³´í˜¸**
   - `.env` íŒŒì¼ì— Orthanc ë¹„ë°€ë²ˆí˜¸ ì €ì¥
   - `.gitignore`ì— `.env` ì¶”ê°€
   - íŒŒì¼ ê¶Œí•œ: `chmod 600 .env`

2. **ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ**
   - GCP ë°©í™”ë²½ì—ì„œ ì—°êµ¬ì‹¤ ì»´í“¨í„° IPë§Œ í—ˆìš©
   - VPN ì‚¬ìš© ê¶Œì¥
   - HTTPS ì‚¬ìš© (Orthanc SSL ì¸ì¦ì„œ ì„¤ì •)

3. **ìš”ì²­ ë””ë ‰í† ë¦¬ ë³´ì•ˆ**
   - `/tmp/mri_inference_requests/` ê¶Œí•œ ì„¤ì •
   - ì •ê¸°ì ì¸ ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬ (24ì‹œê°„ ì´ìƒ)

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì—°êµ¬ì‹¤ ì»´í“¨í„° ì„¤ì •
- [ ] Python í™˜ê²½ ì„¤ì • ì™„ë£Œ
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ
- [ ] ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] `.env` íŒŒì¼ ì„¤ì • ì™„ë£Œ
- [ ] Orthanc ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] GPU ì‚¬ìš© ê°€ëŠ¥ í™•ì¸ (ì„ íƒ)

### ì¶”ë¡  ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] ìˆ˜ë™ ì‹¤í–‰ ì„±ê³µ (`local_inference.py`)
- [ ] Orthanc ì—…ë¡œë“œ í™•ì¸
- [ ] GCP Djangoì—ì„œ ê²°ê³¼ í™•ì¸
- [ ] í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê²°ê³¼ í‘œì‹œ í™•ì¸

### ìë™ ì›Œì»¤ ì„¤ì •
- [ ] ì›Œì»¤ ì‹¤í–‰ ì„±ê³µ
- [ ] systemd ì„œë¹„ìŠ¤ ë“±ë¡ ì™„ë£Œ (ì„ íƒ)
- [ ] ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ
- [ ] Django API ì—°ë™ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

---

## ğŸ“ ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

1. **ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ**
   ```bash
   pip install -r src/requirements.txt
   ```

2. **Orthanc ì—°ê²° ì‹¤íŒ¨**
   ```bash
   # ë„¤íŠ¸ì›Œí¬ í™•ì¸
   ping 34.42.223.43
   
   # Orthanc ìƒíƒœ í™•ì¸
   curl http://34.42.223.43:8042/system
   ```

3. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```bash
   # CPU ëª¨ë“œë¡œ ì „í™˜
   python local_inference.py --device cpu --series-ids ...
   ```

4. **ì›Œì»¤ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ**
   ```bash
   # ì›Œì»¤ ë¡œê·¸ í™•ì¸
   tail -f worker.log
   
   # ìš”ì²­ íŒŒì¼ í™•ì¸
   ls -lh /tmp/mri_inference_requests/
   ```

---

## ğŸ‰ ì™„ë£Œ!

ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ëŠ” ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.

### ë‹¤ìŒ ë‹¨ê³„
1. âœ… ì—°êµ¬ì‹¤ ì»´í“¨í„° í™˜ê²½ ì„¤ì •
2. âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸
3. âœ… ì›Œì»¤ ìë™í™” ì„¤ì •
4. âœ… Django API ì—°ë™ í…ŒìŠ¤íŠ¸
5. âœ… í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ (ì„ íƒ)

### ì°¸ê³  ë¬¸ì„œ
- `README_LOCAL_INFERENCE.md` - ì™„ì „ ê°€ì´ë“œ
- `ì—°êµ¬ì‹¤_ì»´í“¨í„°_ì‹¤í–‰_ê°€ì´ë“œ.md` - ë¹ ë¥¸ ì‹œì‘
- `ì—°êµ¬ì‹¤_ì»´í“¨í„°_ì¶”ë¡ _êµ¬ì¡°_ë³€ê²½ì•ˆ.md` - ê¸°íš ë¬¸ì„œ

---

**ë³€ê²½ì¼**: 2026ë…„ 1ì›”
**ì‘ì„±ì**: AI Assistant
**ë²„ì „**: 1.0.0

# HTTP API ë°©ì‹ êµ¬í˜„ ê³„íš

**ì‘ì„±ì¼**: 2026ë…„ 1ì›” 20ì¼  
**í†µì‹  ë°©ì‹**: HTTP API (í´ë§)

---

## ğŸ¯ ì „ì²´ êµ¬ì¡°

```
[í”„ë¡ íŠ¸ì—”ë“œ] "AI ë¶„ì„" ë²„íŠ¼ í´ë¦­
    â†“
[GCP Django] DBì— ìš”ì²­ ì €ì¥ (status='pending')
    â†“
[ì—°êµ¬ì‹¤ PC ì›Œì»¤] 30ì´ˆë§ˆë‹¤ HTTP GET ìš”ì²­
    â† GET /api/inference/pending
[GCP Django] ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ë°˜í™˜
    â†“
[ì—°êµ¬ì‹¤ PC ì›Œì»¤] ì¶”ë¡  ì‹¤í–‰
    â†“
[ì—°êµ¬ì‹¤ PC ì›Œì»¤] ê²°ê³¼ ì „ì†¡
    â†’ POST /api/inference/{id}/complete
[GCP Django] ê²°ê³¼ ì €ì¥ ë° í”„ë¡ íŠ¸ì—”ë“œ ì‘ë‹µ
```

---

## ğŸ‘¥ ì—­í•  ë¶„ë‹´

### ğŸ”µ ì¡°ì›ë‹˜ (GCP Django ì„œë²„)

#### 1. Django ëª¨ë¸ ìƒì„±

```python
# models.py
from django.db import models
from django.utils import timezone

class InferenceRequest(models.Model):
    STATUS_CHOICES = [
        ('pending', 'Pending'),
        ('processing', 'Processing'),
        ('completed', 'Completed'),
        ('failed', 'Failed'),
    ]
    
    # ìš”ì²­ ì •ë³´
    series_id = models.CharField(max_length=255, unique=True)
    series_ids = models.JSONField()  # 4ê°œ ì‹œë¦¬ì¦ˆ ID ë¦¬ìŠ¤íŠ¸
    
    # ìƒíƒœ
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending')
    
    # ê²°ê³¼
    result = models.JSONField(null=True, blank=True)
    seg_instance_id = models.CharField(max_length=255, null=True, blank=True)
    
    # ì‹œê°„
    created_at = models.DateTimeField(auto_now_add=True)
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    
    class Meta:
        ordering = ['-created_at']
```

#### 2. API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±

```python
# views.py
from rest_framework.decorators import api_view
from rest_framework.response import Response
from django.utils import timezone
from .models import InferenceRequest

@api_view(['GET'])
def get_pending_inference(request):
    """
    ëŒ€ê¸° ì¤‘ì¸ ì¶”ë¡  ìš”ì²­ ë°˜í™˜
    ì—°êµ¬ì‹¤ PC ì›Œì»¤ê°€ 30ì´ˆë§ˆë‹¤ í˜¸ì¶œ
    """
    # ê°€ì¥ ì˜¤ë˜ëœ pending ìš”ì²­ ê°€ì ¸ì˜¤ê¸°
    pending = InferenceRequest.objects.filter(status='pending').first()
    
    if pending:
        # ìƒíƒœë¥¼ processingìœ¼ë¡œ ë³€ê²½
        pending.status = 'processing'
        pending.started_at = timezone.now()
        pending.save()
        
        return Response({
            'id': pending.id,
            'series_id': pending.series_id,
            'series_ids': pending.series_ids,
        })
    
    # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì—†ìŒ
    return Response({'id': None})


@api_view(['POST'])
def complete_inference(request, request_id):
    """
    ì¶”ë¡  ì™„ë£Œ ê²°ê³¼ ì €ì¥
    ì—°êµ¬ì‹¤ PC ì›Œì»¤ê°€ ì¶”ë¡  ì™„ë£Œ í›„ í˜¸ì¶œ
    """
    try:
        inference = InferenceRequest.objects.get(id=request_id)
        
        # ê²°ê³¼ ì €ì¥
        result_data = request.data
        
        if result_data.get('success'):
            inference.status = 'completed'
            inference.result = result_data
            inference.seg_instance_id = result_data.get('seg_instance_id')
        else:
            inference.status = 'failed'
            inference.result = result_data
        
        inference.completed_at = timezone.now()
        inference.save()
        
        return Response({'success': True})
        
    except InferenceRequest.DoesNotExist:
        return Response({'success': False, 'error': 'Request not found'}, status=404)


@api_view(['GET'])
def get_inference_status(request, series_id):
    """
    ì¶”ë¡  ìƒíƒœ í™•ì¸
    í”„ë¡ íŠ¸ì—”ë“œê°€ ê²°ê³¼ ëŒ€ê¸° ì¤‘ í˜¸ì¶œ
    """
    try:
        inference = InferenceRequest.objects.get(series_id=series_id)
        
        return Response({
            'status': inference.status,
            'result': inference.result,
            'seg_instance_id': inference.seg_instance_id,
            'created_at': inference.created_at,
            'completed_at': inference.completed_at,
        })
        
    except InferenceRequest.DoesNotExist:
        return Response({'error': 'Not found'}, status=404)
```

#### 3. URL ì„¤ì •

```python
# urls.py
from django.urls import path
from . import views

urlpatterns = [
    # ì—°êµ¬ì‹¤ PC ì›Œì»¤ìš©
    path('api/inference/pending', views.get_pending_inference, name='get_pending_inference'),
    path('api/inference/<int:request_id>/complete', views.complete_inference, name='complete_inference'),
    
    # í”„ë¡ íŠ¸ì—”ë“œìš©
    path('api/inference/<str:series_id>/status', views.get_inference_status, name='get_inference_status'),
]
```

#### 4. ê¸°ì¡´ ì¶”ë¡  API ìˆ˜ì •

```python
# ê¸°ì¡´ ì¶”ë¡  API (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œ)
@api_view(['POST'])
def start_inference(request, series_id):
    """
    ì¶”ë¡  ì‹œì‘ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œ)
    """
    series_ids = request.data.get('series_ids')  # 4ê°œ ì‹œë¦¬ì¦ˆ ID
    
    # DBì— ìš”ì²­ ìƒì„±
    inference_request = InferenceRequest.objects.create(
        series_id=series_id,
        series_ids=series_ids,
        status='pending'
    )
    
    # ì¦‰ì‹œ ì‘ë‹µ (ë¹„ë™ê¸° ì²˜ë¦¬)
    return Response({
        'success': True,
        'request_id': inference_request.id,
        'message': 'ì¶”ë¡  ìš”ì²­ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì—°êµ¬ì‹¤ PCì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.',
    })
```

#### 5. ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ë°°í¬

```bash
# ë§ˆì´ê·¸ë ˆì´ì…˜
python manage.py makemigrations
python manage.py migrate

# Gunicorn ì¬ì‹œì‘
sudo systemctl restart gunicorn
```

---

### ğŸŸ¢ ì œê°€ í•  ì¼ (ì—°êµ¬ì‹¤ PC ì›Œì»¤)

#### 1. ì›Œì»¤ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •

```python
# local_inference_worker.py (HTTP API ë²„ì „)
import requests
import time
import logging
from pathlib import Path

# ì„¤ì •
GCP_API_URL = "http://34.42.223.43"  # GCP Django ì„œë²„ URL
POLL_INTERVAL = 30  # 30ì´ˆë§ˆë‹¤ í™•ì¸

logger = logging.getLogger(__name__)

def poll_for_requests():
    """GCPì—ì„œ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ í™•ì¸"""
    try:
        response = requests.get(
            f"{GCP_API_URL}/api/inference/pending",
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        logger.error(f"ìš”ì²­ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {'id': None}


def send_result(request_id, result):
    """ì¶”ë¡  ê²°ê³¼ ì „ì†¡"""
    try:
        response = requests.post(
            f"{GCP_API_URL}/api/inference/{request_id}/complete",
            json=result,
            timeout=30
        )
        response.raise_for_status()
        logger.info(f"âœ… ê²°ê³¼ ì „ì†¡ ì™„ë£Œ: {request_id}")
        return True
    except Exception as e:
        logger.error(f"ê²°ê³¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
        return False


def main():
    logger.info("ğŸš€ HTTP API ì›Œì»¤ ì‹œì‘")
    logger.info(f"ğŸ“¡ GCP ì„œë²„: {GCP_API_URL}")
    logger.info(f"â±ï¸  í´ë§ ê°„ê²©: {POLL_INTERVAL}ì´ˆ")
    
    while True:
        try:
            # 1. ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ í™•ì¸
            request_data = poll_for_requests()
            
            if request_data.get('id'):
                logger.info(f"ğŸ“‹ ìƒˆ ìš”ì²­ ë°œê²¬: {request_data['id']}")
                
                # 2. ì¶”ë¡  ì‹¤í–‰
                from local_inference import run_inference_local
                result = run_inference_local(
                    series_ids=request_data['series_ids']
                )
                
                # 3. ê²°ê³¼ ì „ì†¡
                send_result(request_data['id'], result)
            
            # 4. ë‹¤ìŒ í´ë§ê¹Œì§€ ëŒ€ê¸°
            time.sleep(POLL_INTERVAL)
            
        except KeyboardInterrupt:
            logger.info("ì›Œì»¤ ì¢…ë£Œ")
            break
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            time.sleep(POLL_INTERVAL)


if __name__ == "__main__":
    main()
```

#### 2. ì„¤ì • íŒŒì¼ ìˆ˜ì •

```bash
# .env íŒŒì¼ì— ì¶”ê°€
GCP_API_URL=http://34.42.223.43
POLL_INTERVAL=30
```

#### 3. ì›Œì»¤ ì¬ì‹œì‘

```powershell
# ê¸°ì¡´ ì›Œì»¤ ì¢…ë£Œ (Ctrl+C)
# ìƒˆ ì›Œì»¤ ì‹œì‘
python local_inference_worker.py
```

---

## ğŸ“‹ êµ¬í˜„ ìˆœì„œ

### 1ë‹¨ê³„: GCP Django ì„¤ì • (ì¡°ì›ë‹˜)
1. âœ… ëª¨ë¸ ìƒì„± (`InferenceRequest`)
2. âœ… API ì—”ë“œí¬ì¸íŠ¸ 3ê°œ ìƒì„±
3. âœ… URL ì„¤ì •
4. âœ… ë§ˆì´ê·¸ë ˆì´ì…˜
5. âœ… Gunicorn ì¬ì‹œì‘

### 2ë‹¨ê³„: ì—°êµ¬ì‹¤ PC ì›Œì»¤ ìˆ˜ì • (ì œê°€)
1. âœ… ì›Œì»¤ ìŠ¤í¬ë¦½íŠ¸ HTTP API ë²„ì „ìœ¼ë¡œ ìˆ˜ì •
2. âœ… ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
3. âœ… ì›Œì»¤ ì¬ì‹œì‘

### 3ë‹¨ê³„: í…ŒìŠ¤íŠ¸
1. âœ… í”„ë¡ íŠ¸ì—”ë“œì—ì„œ "AI ë¶„ì„" ë²„íŠ¼ í´ë¦­
2. âœ… ì›Œì»¤ ë¡œê·¸ í™•ì¸
3. âœ… ê²°ê³¼ í™•ì¸

---

## ğŸ” API ëª…ì„¸

### 1. GET /api/inference/pending

**ìš”ì²­**: ì—†ìŒ

**ì‘ë‹µ**:
```json
{
  "id": 123,
  "series_id": "abc-def-ghi",
  "series_ids": ["id1", "id2", "id3", "id4"]
}
```

ë˜ëŠ” (ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì—†ìŒ):
```json
{
  "id": null
}
```

### 2. POST /api/inference/{request_id}/complete

**ìš”ì²­**:
```json
{
  "success": true,
  "seg_instance_id": "orthanc-instance-id",
  "tumor_detected": true,
  "tumor_volume_voxels": 1234,
  "inference_time_seconds": 45.2
}
```

**ì‘ë‹µ**:
```json
{
  "success": true
}
```

### 3. GET /api/inference/{series_id}/status

**ìš”ì²­**: ì—†ìŒ

**ì‘ë‹µ**:
```json
{
  "status": "completed",
  "result": { ... },
  "seg_instance_id": "orthanc-instance-id",
  "created_at": "2026-01-20T17:00:00Z",
  "completed_at": "2026-01-20T17:01:30Z"
}
```

---

## âœ… ì¥ì 

1. **ê°„ë‹¨í•¨**: HTTPë§Œ ì‚¬ìš©
2. **ì•ˆì •ì **: ì—°êµ¬ì‹¤ PC â†’ GCP ë‹¨ë°©í–¥ í†µì‹ 
3. **ë°©í™”ë²½ ë¬¸ì œ ì—†ìŒ**: ngrok ë¶ˆí•„ìš”
4. **ì¶”ê°€ ì¸í”„ë¼ ë¶ˆí•„ìš”**: Redis, ê³µìœ  í´ë” ë¶ˆí•„ìš”
5. **ëª¨ë‹ˆí„°ë§ ì‰¬ì›€**: Django Adminì—ì„œ ìš”ì²­ ìƒíƒœ í™•ì¸ ê°€ëŠ¥

---

## ğŸ“ ì¡°ì›ë‹˜ê»˜ ì „ë‹¬í•  ë‚´ìš©

1. **Django ëª¨ë¸ ì½”ë“œ** (ìœ„ ì½”ë“œ ë³µì‚¬)
2. **API ì—”ë“œí¬ì¸íŠ¸ ì½”ë“œ** (ìœ„ ì½”ë“œ ë³µì‚¬)
3. **URL ì„¤ì •** (ìœ„ ì½”ë“œ ë³µì‚¬)
4. **ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ì¬ì‹œì‘ ëª…ë ¹ì–´**

**ì´ ë¬¸ì„œë¥¼ ì¡°ì›ë‹˜ê»˜ ì „ë‹¬í•˜ì‹œë©´ ë©ë‹ˆë‹¤!** ğŸ“¤

---

*ì‘ì„±ì¼: 2026-01-20 17:38*  
*ì‘ì„±ì: AI Assistant*

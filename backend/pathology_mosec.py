#!/usr/bin/env python3
"""
ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ Mosec ì„œë¹„ìŠ¤ (í¬íŠ¸ 5008)
CLAM (Attention MIL) + H-optimus-0 Feature Extractor
2-class ë¶„ë¥˜: Normal vs Tumor
"""

import os
import io
import json
import logging
import numpy as np
import openslide
from PIL import Image
from typing import List, Dict
import tempfile

import torch
import torch.nn as nn
import timm
from torchvision import transforms
from torch.utils.data import Dataset

from mosec import Server, Worker, get_logger

# ë¡œê¹… ì„¤ì •
logger = get_logger()
logger.setLevel(logging.INFO)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = "/home/shrjsdn908/pathology_model/best_clam_model.pth"

# í´ë˜ìŠ¤ ì´ë¦„
CLASS_NAMES = {
    0: 'Normal',
    1: 'Tumor'
}

# ì „ì²˜ë¦¬ ì„¤ì •
PATCH_SIZE = 224
TARGET_MAG = 20.0


class AttentionMIL(nn.Module):
    """CLAM-style Attention MIL ëª¨ë¸"""
    def __init__(self, input_dim=1536, hidden_dim=512, n_classes=2):
        super(AttentionMIL, self).__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.25)
        )
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim, 256),
            nn.Tanh(),
            nn.Linear(256, 1)
        )
        self.classifier = nn.Linear(hidden_dim, n_classes)

    def forward(self, x):
        """
        Args:
            x: (N, input_dim) - Nê°œì˜ íŒ¨ì¹˜ feature
        Returns:
            logits: (1, n_classes)
            attention: (1, N) - ê° íŒ¨ì¹˜ì˜ attention weight
        """
        h = self.feature_extractor(x)  # (N, hidden_dim)
        A = self.attention(h)  # (N, 1)
        A = torch.transpose(A, 1, 0)  # (1, N)
        A = torch.softmax(A, dim=1)  # (1, N)
        M = torch.mm(A, h)  # (1, hidden_dim)
        logits = self.classifier(M)  # (1, n_classes)
        return logits, A


class WSIPatchDataset(Dataset):
    """WSI íŒ¨ì¹˜ ì¶”ì¶œ Dataset"""
    def __init__(self, svs_path, patch_size=224, target_mag=20.0, max_patches=1000):
        self.wsi = openslide.OpenSlide(svs_path)
        self.patch_size = patch_size
        self.target_mag = target_mag
        self.max_patches = max_patches
        
        # íŒ¨ì¹˜ ì¢Œí‘œ ìƒì„±
        self.patch_coords = self._generate_patch_coords()
        
        # Transform
        self.transform = transforms.Compose([
            transforms.Resize((patch_size, patch_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def _generate_patch_coords(self):
        """íŒ¨ì¹˜ ì¢Œí‘œ ìƒì„± (ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ ìƒ˜í”Œë§)"""
        width, height = self.wsi.dimensions
        stride = self.patch_size * 2  # 50% ì˜¤ë²„ë©
        
        coords = []
        for y in range(0, height - self.patch_size, stride):
            for x in range(0, width - self.patch_size, stride):
                coords.append((x, y))
                if len(coords) >= self.max_patches:
                    return coords
        return coords
    
    def __len__(self):
        return len(self.patch_coords)
    
    def __getitem__(self, idx):
        x, y = self.patch_coords[idx]
        patch = self.wsi.read_region((x, y), 0, (self.patch_size, self.patch_size))
        patch = patch.convert('RGB')
        
        # ë°°ê²½ í•„í„°ë§ (í°ìƒ‰ ë°°ê²½ ì œê±°)
        patch_np = np.array(patch)
        if patch_np.mean() > 220:  # ëŒ€ë¶€ë¶„ í°ìƒ‰ì´ë©´ ìŠ¤í‚µ
            return None
        
        return self.transform(patch)


class PathologyWorker(Worker):
    """ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ì›Œì»¤"""
    
    def __init__(self):
        super().__init__()
        self.clam_model = None
        self.backbone = None
        logger.info(f"ğŸ’» Device: {DEVICE}")
    
    def deserialize(self, data: bytes) -> dict:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™”"""
        try:
            json_data = json.loads(data.decode('utf-8'))
            logger.info(f"ğŸ“¥ ìˆ˜ì‹ í•œ ë°ì´í„° í‚¤: {list(json_data.keys())}")
            return json_data
        except Exception as e:
            logger.error(f"âŒ ì—­ì§ë ¬í™” ì˜¤ë¥˜: {str(e)}")
            raise
    
    def serialize(self, data: dict) -> bytes:
        """ê²°ê³¼ ì§ë ¬í™”"""
        logger.info(f"ğŸ“¦ serialize ì…ë ¥ íƒ€ì…: {type(data)}")
        
        if not isinstance(data, dict):
            logger.error(f"âŒ serialize ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì…: {type(data)}")
            data = {"error": f"Invalid data type: {type(data)}"}
        
        json_str = json.dumps(data)
        logger.info(f"ğŸ“¦ JSON ê¸¸ì´: {len(json_str)} bytes")
        return json_str.encode('utf-8')
    
    def forward(self, data) -> list:
        """
        ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡ 
        
        Args:
            data: dict ë˜ëŠ” List[dict]
                {
                    "svs_file_path": "/path/to/svs/file.svs"
                }
        
        Returns:
            list: [{"results": {...}}]
        """
        # ë°ì´í„° ì¶”ì¶œ
        if isinstance(data, list):
            request_data = data[0]
        else:
            request_data = data
        
        logger.info(f"ğŸ“Š forward ì…ë ¥ íƒ€ì…: {type(data)}")
        
        # ëª¨ë¸ ë¡œë“œ (ì²« ìš”ì²­ ì‹œ)
        if self.clam_model is None:
            logger.info(f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # CLAM ëª¨ë¸ ë¡œë“œ
            self.clam_model = AttentionMIL(input_dim=1536).to(DEVICE)
            self.clam_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
            self.clam_model.eval()
            
            # H-optimus-0 ë°±ë³¸ ë¡œë“œ
            logger.info(f"ğŸ§  H-optimus-0 ë°±ë³¸ ë¡œë”© ì¤‘...")
            self.backbone = timm.create_model(
                "hf-hub:bioptimus/H-optimus-0",
                pretrained=True,
                init_values=1e-5
            ).to(DEVICE).eval()
            
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
        
        try:
            # SVS íŒŒì¼ ê²½ë¡œ ë°›ê¸°
            svs_file_path = request_data.get("svs_file_path", "")
            
            if not svs_file_path or not os.path.exists(svs_file_path):
                raise ValueError(f"SVS íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {svs_file_path}")
            
            logger.info(f"ğŸ“¥ SVS íŒŒì¼ ê²½ë¡œ: {svs_file_path}")
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(svs_file_path)
            logger.info(f"ğŸ“Š SVS íŒŒì¼ í¬ê¸°: {file_size} bytes ({file_size / 1024 / 1024:.2f} MB)")
            
            # OpenSlideë¡œ ì§ì ‘ ì—´ê¸° (íŒŒì¼ ë³µì‚¬ ë¶ˆí•„ìš”)
            tmp_path = svs_file_path
            
            # íŒ¨ì¹˜ ì¶”ì¶œ
            logger.info(f"ğŸ” íŒ¨ì¹˜ ì¶”ì¶œ ì¤‘...")
            dataset = WSIPatchDataset(tmp_path, patch_size=PATCH_SIZE, max_patches=1000)
            
            # Feature ì¶”ì¶œ
            logger.info(f"ğŸ§¬ Feature ì¶”ì¶œ ì¤‘ ({len(dataset)} íŒ¨ì¹˜)...")
            features = []
            with torch.no_grad():
                for i in range(len(dataset)):
                    patch = dataset[i]
                    if patch is None:
                        continue
                    patch = patch.unsqueeze(0).to(DEVICE)
                    feat = self.backbone(patch)  # (1, 1536)
                    features.append(feat.cpu())
            
            if len(features) == 0:
                raise ValueError("ìœ íš¨í•œ íŒ¨ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            features = torch.cat(features, dim=0)  # (N, 1536)
            logger.info(f"âœ… Feature ì¶”ì¶œ ì™„ë£Œ: {features.shape}")
            
            # CLAM ì¶”ë¡ 
            logger.info(f"ğŸ”® CLAM ì¶”ë¡  ì¤‘...")
            with torch.no_grad():
                features = features.to(DEVICE)
                logits, attention = self.clam_model(features)
                probabilities = torch.softmax(logits, dim=1)[0]
                confidence, predicted_class = torch.max(probabilities, 0)
            
            # ê²°ê³¼ ìƒì„±
            class_id = predicted_class.item()
            class_name = CLASS_NAMES[class_id]
            confidence_value = confidence.item()
            
            result = {
                'success': True,
                'class_id': class_id,
                'class_name': class_name,
                'confidence': confidence_value,
                'probabilities': {
                    CLASS_NAMES[i]: float(probabilities[i].item())
                    for i in range(2)
                },
                'num_patches': len(features),
                'top_attention_patches': attention[0].topk(5).indices.tolist()
            }
            
            logger.info(f"âœ… ë¶„ë¥˜ ì™„ë£Œ: {class_name} (ì‹ ë¢°ë„: {confidence_value:.4f})")
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ë¡  ì˜¤ë¥˜: {str(e)}", exc_info=True)
            result = {
                'success': False,
                'error': str(e)
            }
        
        return [{"results": result}]


if __name__ == "__main__":
    logger.info("="*70)
    logger.info("ğŸš€ ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ Mosec ì„œë¹„ìŠ¤ ì‹œì‘ (í¬íŠ¸ 5008)")
    logger.info("="*70)
    logger.info(f"ğŸ“¦ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {DEVICE}")
    logger.info(f"ğŸ“Š í´ë˜ìŠ¤: {list(CLASS_NAMES.values())}")
    logger.info("="*70)
    logger.info("âš ï¸  ëª…ë ¹ì¤„ ì¸ìë¡œ ì„¤ì •: --port 5008 --timeout 300000 --max-body-size 524288000")
    logger.info("="*70)
    
    server = Server()
    server.append_worker(
        PathologyWorker, 
        num=1, 
        max_batch_size=1,  # WSIëŠ” í¬ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° 1
        max_wait_time=120  # 120ì´ˆ ëŒ€ê¸°
    )
    server.run()  # ëª…ë ¹ì¤„ ì¸ìëŠ” Mosecì´ ìë™ìœ¼ë¡œ íŒŒì‹±


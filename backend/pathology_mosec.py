#!/usr/bin/env python3
"""
ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ Mosec ì„œë¹„ìŠ¤ (í¬íŠ¸ 5008)
CLAM (Attention MIL) + H-optimus-0 Feature Extractor
2-class ë¶„ë¥˜: Normal vs Tumor
"""

import os
import io
import json
import logging
import numpy as np
import openslide
from PIL import Image
from typing import List, Dict
import tempfile

import torch
import torch.nn as nn
import timm
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader

from mosec import Server, Worker, get_logger

# ë¡œê¹… ì„¤ì •
logger = get_logger()
logger.setLevel(logging.INFO)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = "/home/shrjsdn908/pathology_model/best_clam_model.pth"

# í´ë˜ìŠ¤ ì´ë¦„
CLASS_NAMES = {
    0: 'Normal',
    1: 'Tumor'
}

# ì „ì²˜ë¦¬ ì„¤ì •
PATCH_SIZE = 224
TARGET_MAG = 20.0


class AttentionMIL(nn.Module):
    """CLAM-style Attention MIL ëª¨ë¸"""
    def __init__(self, input_dim=1536, hidden_dim=512, n_classes=2):
        super(AttentionMIL, self).__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.25)
        )
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim, 256),
            nn.Tanh(),
            nn.Linear(256, 1)
        )
        self.classifier = nn.Linear(hidden_dim, n_classes)

    def forward(self, x):
        """
        Args:
            x: (N, input_dim) - Nê°œì˜ íŒ¨ì¹˜ feature
        Returns:
            logits: (1, n_classes)
            attention: (1, N) - ê° íŒ¨ì¹˜ì˜ attention weight
        """
        h = self.feature_extractor(x)  # (N, hidden_dim)
        A = self.attention(h)  # (N, 1)
        A = torch.transpose(A, 1, 0)  # (1, N)
        A = torch.softmax(A, dim=1)  # (1, N)
        M = torch.mm(A, h)  # (1, hidden_dim)
        logits = self.classifier(M)  # (1, n_classes)
        return logits, A


class WSIPatchDataset(Dataset):
    """WSI íŒ¨ì¹˜ ì¶”ì¶œ Dataset (TCGA í•™ìŠµ ë°©ì‹ê³¼ ë™ì¼)"""
    def __init__(self, svs_path, patch_size=224, target_mag=20.0):
        self.wsi = openslide.OpenSlide(svs_path)
        self.patch_size = patch_size
        
        # ë°°ìœ¨ ê³„ì‚°
        mag = float(self.wsi.properties.get(openslide.PROPERTY_NAME_OBJECTIVE_POWER, 40))
        self.scale = mag / target_mag
        
        # Tissue Masking (Thumbnail ê¸°ë°˜)
        logger.info(f"ğŸ” Tissue masking ì¤‘...")
        thumb_width = self.wsi.dimensions[0] // 100
        thumb_height = self.wsi.dimensions[1] // 100
        thumb = self.wsi.get_thumbnail((thumb_width, thumb_height))
        thumb_gray = np.array(thumb.convert('L'))
        self.mask = thumb_gray < 235  # ì¡°ì§ ì˜ì—­ë§Œ ì„ íƒ
        
        logger.info(f"ğŸ“Š Tissue mask í¬ê¸°: {self.mask.shape}")
        logger.info(f"ğŸ“Š Tissue ë¹„ìœ¨: {self.mask.sum() / self.mask.size * 100:.2f}%")
        
        # ì¡°ì§ ì˜ì—­ì—ì„œë§Œ íŒ¨ì¹˜ ì¢Œí‘œ ìƒì„±
        self.coords = []
        step = int(patch_size * self.scale)
        for y in range(0, self.wsi.dimensions[1] - step, step):
            for x in range(0, self.wsi.dimensions[0] - step, step):
                my = int(y / self.wsi.dimensions[1] * self.mask.shape[0])
                mx = int(x / self.wsi.dimensions[0] * self.mask.shape[1])
                if self.mask[my, mx]:  # ì¡°ì§ ì˜ì—­ì¸ ê²½ìš°ë§Œ ì¶”ê°€
                    self.coords.append((x, y))
        
        logger.info(f"âœ… ì´ {len(self.coords)}ê°œ íŒ¨ì¹˜ ì¢Œí‘œ ìƒì„±")
        
        # Transform (TCGA ë°ì´í„°ì…‹ í†µê³„ ì‚¬ìš©)
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(
                mean=(0.707, 0.578, 0.703),  # TCGA í†µê³„
                std=(0.212, 0.230, 0.182)
            )
        ])
    
    def __len__(self):
        return len(self.coords)
    
    def __getitem__(self, idx):
        x, y = self.coords[idx]
        step = int(self.patch_size * self.scale)
        
        # íŒ¨ì¹˜ ì½ê¸° ë° ë¦¬ì‚¬ì´ì¦ˆ
        patch = self.wsi.read_region((x, y), 0, (step, step)).convert('RGB')
        patch = patch.resize((self.patch_size, self.patch_size), Image.LANCZOS)
        
        return self.transform(patch)


class PathologyWorker(Worker):
    """ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ì›Œì»¤"""
    
    def __init__(self):
        super().__init__()
        self.clam_model = None
        self.backbone = None
        logger.info(f"ğŸ’» Device: {DEVICE}")
    
    def deserialize(self, data: bytes) -> dict:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™”"""
        try:
            json_data = json.loads(data.decode('utf-8'))
            logger.info(f"ğŸ“¥ ìˆ˜ì‹ í•œ ë°ì´í„° í‚¤: {list(json_data.keys())}")
            return json_data
        except Exception as e:
            logger.error(f"âŒ ì—­ì§ë ¬í™” ì˜¤ë¥˜: {str(e)}")
            raise
    
    def serialize(self, data) -> bytes:
        """ê²°ê³¼ ì§ë ¬í™”"""
        logger.info(f"ğŸ“¦ serialize ì…ë ¥ íƒ€ì…: {type(data)}")
        
        # Mosecì€ listë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŒ
        if isinstance(data, list):
            if len(data) > 0 and isinstance(data[0], dict):
                # list[dict] í˜•íƒœ -> ì²« ë²ˆì§¸ dict ì¶”ì¶œ
                data = data[0]
            else:
                data = {"error": f"Unexpected list content: {type(data[0]) if data else 'empty'}"}
        elif not isinstance(data, dict):
            logger.error(f"âŒ serialize ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì…: {type(data)}")
            data = {"error": f"Invalid data type: {type(data)}"}
        
        json_str = json.dumps(data)
        logger.info(f"ğŸ“¦ JSON ê¸¸ì´: {len(json_str)} bytes")
        return json_str.encode('utf-8')
    
    def forward(self, data) -> list:
        """
        ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡ 
        
        Args:
            data: dict ë˜ëŠ” List[dict]
                {
                    "svs_file_path": "/path/to/svs/file.svs"
                }
        
        Returns:
            list: [{"results": {...}}]
        """
        # ë°ì´í„° ì¶”ì¶œ
        if isinstance(data, list):
            request_data = data[0]
        else:
            request_data = data
        
        logger.info(f"ğŸ“Š forward ì…ë ¥ íƒ€ì…: {type(data)}")
        
        # ëª¨ë¸ ë¡œë“œ (ì²« ìš”ì²­ ì‹œ)
        if self.clam_model is None:
            logger.info(f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # CLAM ëª¨ë¸ ë¡œë“œ
            self.clam_model = AttentionMIL(input_dim=1536).to(DEVICE)
            self.clam_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
            self.clam_model.eval()
            
            # H-optimus-0 ë°±ë³¸ ë¡œë“œ
            logger.info(f"ğŸ§  H-optimus-0 ë°±ë³¸ ë¡œë”© ì¤‘...")
            
            # HuggingFace í† í° í™•ì¸ (ì„ íƒì )
            hf_token = os.getenv('HF_TOKEN') or os.getenv('HUGGINGFACE_TOKEN')
            if hf_token:
                logger.info(f"ğŸ”‘ HuggingFace í† í° ì‚¬ìš©")
                try:
                    from huggingface_hub import login
                    login(token=hf_token)
                except Exception as e:
                    logger.warning(f"âš ï¸ HuggingFace ë¡œê·¸ì¸ ì‹¤íŒ¨: {str(e)}")
                    logger.info(f"ğŸ’¡ ìºì‹œì—ì„œ ëª¨ë¸ì„ ì°¾ìœ¼ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤...")
            else:
                logger.info(f"ğŸ’¡ í† í° ì—†ì´ ìºì‹œì—ì„œ ëª¨ë¸ì„ ì°¾ìœ¼ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤...")
            
            try:
                self.backbone = timm.create_model(
                    "hf-hub:bioptimus/H-optimus-0",
                    pretrained=True,
                    init_values=1e-5
                ).to(DEVICE).eval()
                logger.info(f"âœ… H-optimus-0 ë¡œë“œ ì„±ê³µ!")
            except Exception as e:
                error_msg = str(e)
                logger.error(f"âŒ H-optimus-0 ë¡œë“œ ì‹¤íŒ¨: {error_msg}")
                
                # Gated repo ì—ëŸ¬ì¸ ê²½ìš°
                if "401" in error_msg or "gated" in error_msg.lower() or "restricted" in error_msg.lower():
                    logger.error(f"ğŸ’¡ HuggingFace í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤!")
                    logger.error(f"ğŸ’¡ í•´ê²° ë°©ë²•:")
                    logger.error(f"   1. HF_TOKEN í™˜ê²½ë³€ìˆ˜ ì„¤ì •: export HF_TOKEN='your_token'")
                    logger.error(f"   2. ë˜ëŠ” í•œ ë²ˆ ë‹¤ìš´ë¡œë“œ: python3 -c \"from huggingface_hub import login; login(token='token'); import timm; timm.create_model('hf-hub:bioptimus/H-optimus-0', pretrained=True)\"")
                raise
            
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
        
        try:
            # SVS íŒŒì¼ ê²½ë¡œ ë°›ê¸°
            svs_file_path = request_data.get("svs_file_path", "")
            
            logger.info(f"ğŸ“¥ ë°›ì€ svs_file_path: '{svs_file_path}' (íƒ€ì…: {type(svs_file_path)})")
            logger.info(f"ğŸ“¥ request_data ì „ì²´: {list(request_data.keys())}")
            
            if not svs_file_path:
                logger.error(f"âŒ svs_file_pathê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
                raise ValueError("svs_file_pathê°€ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if not os.path.exists(svs_file_path):
                logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {svs_file_path}")
                # ë””ë ‰í† ë¦¬ í™•ì¸
                if os.path.dirname(svs_file_path):
                    logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(os.path.dirname(svs_file_path))}")
                raise ValueError(f"SVS íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {svs_file_path}")
            
            logger.info(f"âœ… SVS íŒŒì¼ ê²½ë¡œ í™•ì¸: {svs_file_path}")
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(svs_file_path)
            logger.info(f"ğŸ“Š SVS íŒŒì¼ í¬ê¸°: {file_size} bytes ({file_size / 1024 / 1024:.2f} MB)")
            
            # OpenSlideë¡œ ì§ì ‘ ì—´ê¸° (íŒŒì¼ ë³µì‚¬ ë¶ˆí•„ìš”)
            tmp_path = svs_file_path
            
            # íŒ¨ì¹˜ ì¶”ì¶œ (Tissue Masking í¬í•¨)
            logger.info(f"ğŸ” íŒ¨ì¹˜ ì¶”ì¶œ ì¤‘...")
            dataset = WSIPatchDataset(tmp_path, patch_size=PATCH_SIZE, target_mag=TARGET_MAG)
            
            logger.info(f"ğŸ“Š ì´ ì¡°ì§ íŒ¨ì¹˜ ê°œìˆ˜: {len(dataset)}")
            
            if len(dataset) == 0:
                logger.error(f"âŒ ì¡°ì§ íŒ¨ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤! Tissue masking ê²°ê³¼ ìœ íš¨í•œ ì˜ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
                raise ValueError("ì¡°ì§ íŒ¨ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ê°€ ëŒ€ë¶€ë¶„ ë°°ê²½ì…ë‹ˆë‹¤.")
            
            # Feature ì¶”ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)
            loader = DataLoader(dataset, batch_size=128, shuffle=False)
            
            all_features = []
            with torch.no_grad():
                for i, batch in enumerate(loader):
                    batch = batch.to(DEVICE)
                    
                    # H-optimus-0ì˜ Feature ì¶”ì¶œ
                    try:
                        # ë¨¼ì € forward_features() ì‹œë„ (ì¡°ì› ì½”ë“œ ë°©ì‹)
                        if hasattr(self.backbone, 'forward_features'):
                            outputs = self.backbone.forward_features(batch)
                        else:
                            # forward_features()ê°€ ì—†ìœ¼ë©´ forward() ì‚¬ìš©
                            outputs = self.backbone(batch)
                        
                        # ì¶œë ¥ í˜•íƒœ í™•ì¸ (ì²« ë°°ì¹˜ë§Œ)
                        if i == 0:
                            logger.info(f"ğŸ” Backbone ì¶œë ¥ í˜•íƒœ: {outputs.shape if hasattr(outputs, 'shape') else type(outputs)}")
                            logger.info(f"ğŸ” Backbone ë©”ì„œë“œ: {'forward_features' if hasattr(self.backbone, 'forward_features') else 'forward'}")
                        
                        # Feature ì¶”ì¶œ
                        if hasattr(outputs, 'shape'):
                            if len(outputs.shape) == 3:
                                # (batch, tokens, features) í˜•íƒœ - CLS token ì¶”ì¶œ
                                feats = outputs[:, 0].cpu()  # CLS token
                            elif len(outputs.shape) == 2:
                                # (batch, features) í˜•íƒœ - ì´ë¯¸ poolingë¨
                                feats = outputs.cpu()
                            else:
                                logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì¶œë ¥ í˜•íƒœ: {outputs.shape}")
                                raise ValueError(f"Unexpected output shape: {outputs.shape}")
                        else:
                            logger.error(f"âŒ ì¶œë ¥ì´ Tensorê°€ ì•„ë‹™ë‹ˆë‹¤: {type(outputs)}")
                            raise ValueError(f"Output is not a tensor: {type(outputs)}")
                        
                        # Feature ì°¨ì› í™•ì¸
                        if i == 0:
                            logger.info(f"ğŸ” ì¶”ì¶œëœ Feature í˜•íƒœ: {feats.shape}")
                        
                        all_features.append(feats)
                        
                    except Exception as e:
                        logger.error(f"âŒ Feature ì¶”ì¶œ ì˜¤ë¥˜ (ë°°ì¹˜ {i}): {str(e)}", exc_info=True)
                        raise  # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œì„œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
            
            if len(all_features) == 0:
                logger.error(f"âŒ Feature ì¶”ì¶œ ì‹¤íŒ¨!")
                raise ValueError("Feature ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            slide_features = torch.cat(all_features, dim=0).to(DEVICE)  # (N, 1536)
            logger.info(f"âœ… Feature ì¶”ì¶œ ì™„ë£Œ: {slide_features.shape}")
            
            # CLAM ì¶”ë¡ 
            logger.info(f"ğŸ”® CLAM ì¶”ë¡  ì¤‘...")
            with torch.no_grad():
                logits, attention = self.clam_model(slide_features)
                probabilities = torch.softmax(logits, dim=1)[0]
                confidence, predicted_class = torch.max(probabilities, 0)
            
            # ê²°ê³¼ ìƒì„±
            class_id = predicted_class.item()
            class_name = CLASS_NAMES[class_id]
            confidence_value = confidence.item()
            
            result = {
                'success': True,
                'class_id': class_id,
                'class_name': class_name,
                'confidence': confidence_value,
                'probabilities': {
                    CLASS_NAMES[i]: float(probabilities[i].item())
                    for i in range(2)
                },
                'num_patches': len(slide_features),
                'top_attention_patches': attention[0].topk(5).indices.tolist()
            }
            
            logger.info(f"âœ… ë¶„ë¥˜ ì™„ë£Œ: {class_name} (ì‹ ë¢°ë„: {confidence_value:.4f})")
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ë¡  ì˜¤ë¥˜: {str(e)}", exc_info=True)
            result = {
                'success': False,
                'error': str(e)
            }
        
        return [{"results": result}]


if __name__ == "__main__":
    logger.info("="*70)
    logger.info("ğŸš€ ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ë¥˜ Mosec ì„œë¹„ìŠ¤ ì‹œì‘ (í¬íŠ¸ 5008)")
    logger.info("="*70)
    logger.info(f"ğŸ“¦ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {DEVICE}")
    logger.info(f"ğŸ“Š í´ë˜ìŠ¤: {list(CLASS_NAMES.values())}")
    logger.info("="*70)
    logger.info("âš ï¸  ëª…ë ¹ì¤„ ì¸ìë¡œ ì„¤ì •: --port 5008 --timeout 300000 --max-body-size 524288000")
    logger.info("="*70)
    
    server = Server()
    server.append_worker(
        PathologyWorker, 
        num=1, 
        max_batch_size=1,  # WSIëŠ” í¬ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° 1
        max_wait_time=120  # 120ì´ˆ ëŒ€ê¸°
    )
    server.run()  # ëª…ë ¹ì¤„ ì¸ìëŠ” Mosecì´ ìë™ìœ¼ë¡œ íŒŒì‹±


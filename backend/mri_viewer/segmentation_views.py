"""
MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ API Views (MAMA_MIA_DELIVERY_PKG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
- Orthanc ì—°ë™: ê¸°ì¡´ ì‹œìŠ¤í…œ ë¡œì§ ìœ ì§€
- ì¶”ë¡ : ìƒˆë¡œìš´ MAMA_MIA íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
- ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡ : ë¡œì»¬ í™˜ê²½ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ê°€ëŠ¥
"""
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.response import Response
from rest_framework import status
from rest_framework.authentication import SessionAuthentication
from rest_framework.permissions import AllowAny
from django.utils import timezone
from django.views.decorators.csrf import csrf_exempt
import requests
import io
import logging
import os
import base64
import numpy as np
import pydicom
import tempfile
import shutil
import json
from pathlib import Path
from .orthanc_client import OrthancClient
import sys

# ìƒˆë¡œìš´ MAMA_MIA ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ import (ì§€ì—° ë¡œë“œë¡œ ë³€ê²½)
# Django ì‹œì‘ ì‹œ import ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import

logger = logging.getLogger(__name__)

# Orthanc ì„¤ì •
ORTHANC_URL = os.getenv('ORTHANC_URL', 'http://34.42.223.43:8042')
ORTHANC_USER = os.getenv('ORTHANC_USER', 'admin')
ORTHANC_PASSWORD = os.getenv('ORTHANC_PASSWORD', 'admin123')

# ëª¨ë¸ ê²½ë¡œ (ìš°ì„ ìˆœìœ„: src/best_model.pth -> checkpoints/best_model.pth)
MODEL_PATH = Path(__file__).parent.parent / "mri_segmentation" / "src" / "best_model.pth"
if not MODEL_PATH.exists():
    MODEL_PATH = Path(__file__).parent.parent / "mri_segmentation" / "checkpoints" / "best_model.pth"
if not MODEL_PATH.exists():
    logger.warning(f"Model file not found at expected locations. Searched: {MODEL_PATH}")

# ì „ì—­ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (í•œ ë²ˆë§Œ ë¡œë“œ)
_pipeline = None

def get_pipeline():
    """ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹±ê¸€í†¤ (ì§€ì—° ë¡œë“œ)"""
    global _pipeline
    if _pipeline is None:
        # ì§€ì—° importë¡œ Django ì‹œì‘ ì‹œ ì˜¤ë¥˜ ë°©ì§€
        sys.path.insert(0, str(Path(__file__).parent.parent / "mri_segmentation" / "src"))
        from inference_pipeline import SegmentationInferencePipeline
        
        logger.info(f"Loading segmentation model from: {MODEL_PATH}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        import torch
        device = "cpu"  # ê¸°ë³¸ê°’ì€ CPU
        if os.getenv('USE_GPU', 'false').lower() == 'true':
            if torch.cuda.is_available():
                device = "cuda"
                logger.info("Using CUDA GPU for inference")
            else:
                logger.warning("GPU requested but not available. Using CPU instead.")
        else:
            logger.info("Using CPU for inference (set USE_GPU=true to enable GPU)")
        
        _pipeline = SegmentationInferencePipeline(
            model_path=str(MODEL_PATH),
            device=device,
            threshold=0.5
        )
        logger.info("Model loaded successfully!")
    return _pipeline


# CSRF ì²´í¬ë¥¼ ê±´ë„ˆë›°ëŠ” ì»¤ìŠ¤í…€ ì¸ì¦ í´ë˜ìŠ¤
class CSRFExemptSessionAuthentication(SessionAuthentication):
    def enforce_csrf(self, request):
        return  # CSRF ì²´í¬ë¥¼ ê±´ë„ˆëœ€


@api_view(['POST'])
@authentication_classes([CSRFExemptSessionAuthentication])
@permission_classes([AllowAny])
def mri_segmentation(request, instance_id):
    """
    MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ë° Orthancì— ì €ì¥ (ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” 4ì±„ë„)
    
    POST /api/mri/segmentation/instances/<instance_id>/segment/
    """
    try:
        # Request bodyì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ ID ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œ)
        sequence_ids = request.data.get('sequence_instance_ids', [instance_id])
        
        logger.info(f"ğŸ” MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘: {len(sequence_ids)}ê°œ ì‹œí€€ìŠ¤")
        logger.info(f"   Instance IDs: {sequence_ids}")
        
        # 4ì±„ë„ì¸ ê²½ìš° perform_segment_series_logic ì‚¬ìš©
        if len(sequence_ids) == 4:
            # ê° ì¸ìŠ¤í„´ìŠ¤ì˜ ì‹œë¦¬ì¦ˆ ID ì°¾ê¸°
            client = OrthancClient()
            sequence_series_ids = []
            for inst_id in sequence_ids:
                inst_info = client.get_instance_info(inst_id)
                parent_series = inst_info.get('ParentSeries')
                if parent_series:
                    sequence_series_ids.append(parent_series)
            
            if len(sequence_series_ids) == 4:
                return _perform_segment_series_logic(request, sequence_series_ids[0], sequence_series_ids)
            else:
                return Response({
                    'success': False,
                    'error': '4ê°œ ì‹œí€€ìŠ¤ì˜ ì‹œë¦¬ì¦ˆ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=400)
        else:
            # ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œëŠ” ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠìŒ
            return Response({
                'success': False,
                'error': 'ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œëŠ” ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 4ì±„ë„ DCE-MRIë§Œ ì§€ì›í•©ë‹ˆë‹¤.'
            }, status=400)
            
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'instance_id': instance_id,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def segmentation_health(request):
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ API ì„œë²„ ìƒíƒœ í™•ì¸
    
    GET /api/mri/segmentation/health/
    """
    try:
        # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        model_file_exists = MODEL_PATH.exists()
        
        # ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        model_loaded = False
        error_msg = None
        try:
            pipeline = get_pipeline()
            model_loaded = pipeline is not None
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            error_msg = str(e)
            model_loaded = False
        
        return Response({
            'success': True,
            'status': 'healthy' if model_loaded else 'model_not_loaded',
            'service': 'New Segmentation Pipeline',
            'model_loaded': model_loaded,
            'model_file_exists': model_file_exists,
            'model_path': str(MODEL_PATH),
            'orthanc_url': ORTHANC_URL,
            'error': error_msg if error_msg else None
        })
    except Exception as e:
        return Response({
            'success': False,
            'status': 'unavailable',
            'error': str(e)
        }, status=status.HTTP_503_SERVICE_UNAVAILABLE)


@api_view(['POST'])
@authentication_classes([CSRFExemptSessionAuthentication])
@permission_classes([AllowAny])
def segment_series(request, series_id):
    """
    ì‹œë¦¬ì¦ˆ ì „ì²´ë¥¼ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜í•˜ê³  Orthancì— ì €ì¥
    
    POST /api/mri/segmentation/series/<series_id>/segment/
    """
    sequence_series_ids = request.data.get("sequence_series_ids", [])
    if len(sequence_series_ids) != 4:
        return Response({
            "success": False,
            "error": "4ê°œ ì‹œë¦¬ì¦ˆê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."
        }, status=400)
    
    return _perform_segment_series_logic(request, series_id, sequence_series_ids)


def _perform_segment_series_logic(request, series_id, sequence_series_ids):
    """
    ì‹œë¦¬ì¦ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ í•µì‹¬ ë¡œì§ (ë‚´ë¶€ helper í•¨ìˆ˜)
    """
    try:
        logger.info(f"ğŸ” ì‹œë¦¬ì¦ˆ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘: series_id={series_id}")
        
        # ì—°êµ¬ì‹¤ ì»´í“¨í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        use_local = request.query_params.get('use_local', '').lower() == 'true'
        force_gcp = request.query_params.get('force_gcp', '').lower() == 'true'
        
        if not use_local and not force_gcp:
            use_local = os.getenv('USE_LOCAL_INFERENCE', 'false').lower() == 'true'
        
        # ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ ì‚¬ìš© ì‹œ
        if use_local and not force_gcp:
            logger.info("ğŸ  ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ë¥¼ í†µí•´ ì¶”ë¡  ìš”ì²­ ìƒì„±")
            return _create_local_inference_request(request, series_id, sequence_series_ids)
        
        # GCPì—ì„œ ì§ì ‘ ì‹¤í–‰
        logger.info("â˜ï¸ GCP ì„œë²„ì—ì„œ ì§ì ‘ ì¶”ë¡  ì‹¤í–‰")
        
        client = OrthancClient()
        temp_dir = tempfile.mkdtemp(prefix="mri_seg_")
        
        try:
            # 1. Orthancì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ì˜ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
            for seq_idx, seq_series_id in enumerate(sequence_series_ids):
                seq_info = client.get(f"/series/{seq_series_id}")
                seq_instances = seq_info.get("Instances", [])
                
                if len(seq_instances) == 0:
                    return Response({
                        "success": False,
                        "error": f"ì‹œí€€ìŠ¤ {seq_idx+1}ì— ìŠ¬ë¼ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
                    }, status=400)
                
                seq_dir = Path(temp_dir) / f"seq_{seq_idx:02d}"
                seq_dir.mkdir(parents=True, exist_ok=True)
                
                for inst_idx, instance_id in enumerate(seq_instances):
                    dicom_bytes = client.get_instance_file(instance_id)
                    dicom_path = seq_dir / f"slice_{inst_idx:04d}.dcm"
                    with open(dicom_path, 'wb') as f:
                        f.write(dicom_bytes)
                
                logger.info(f"âœ… ì‹œí€€ìŠ¤ {seq_idx+1}/4: {len(seq_instances)}ê°œ ìŠ¬ë¼ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")
            
            # 2. MAMA-MIA ëª¨ë¸ ë¡œë“œ (ì‹±ê¸€í†¤ ì‚¬ìš©)
            pipeline = get_pipeline()
            if pipeline is None:
                return Response({
                    "success": False,
                    "error": "ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }, status=500)
            
            # 3. ì¶”ë¡  ì‹¤í–‰
            seg_dicom_path = Path(temp_dir) / "segmentation.dcm"
            result = pipeline.predict(
                image_path=temp_dir,
                output_path=str(seg_dicom_path),
                output_format="dicom"
            )
            
            logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ: tumor_detected={result['tumor_detected']}")
            
            # 4. DICOM SEGë¥¼ Orthancì— ì—…ë¡œë“œ
            if not seg_dicom_path.exists():
                raise Exception("ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ íŒŒì¼(DICOM SEG)ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
            with open(seg_dicom_path, 'rb') as f:
                seg_dicom_bytes = f.read()
            
            upload_result = client.upload_dicom(seg_dicom_bytes)
            seg_instance_id = upload_result.get('ID')
            
            logger.info(f"âœ… Orthanc ì—…ë¡œë“œ ì™„ë£Œ: {seg_instance_id}")
            
            return Response({
                'success': True,
                'series_id': series_id,
                'tumor_detected': result['tumor_detected'],
                'tumor_volume_voxels': result['tumor_volume_voxels'],
                'seg_instance_id': seg_instance_id,
                'saved_to_orthanc': True
            })
            
        finally:
            if temp_dir and Path(temp_dir).exists():
                shutil.rmtree(temp_dir)
                logger.info("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
    
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¡œì§ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'series_id': series_id,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_segmentation_frames(request, seg_instance_id):
    """
    DICOM SEG íŒŒì¼ì—ì„œ ëª¨ë“  í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    """
    try:
        logger.info(f"ğŸ” DICOM SEG í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘: {seg_instance_id}")
        client = OrthancClient()
        seg_dicom_bytes = client.get_instance_file(seg_instance_id)
        
        dicom_data = io.BytesIO(seg_dicom_bytes)
        ds = pydicom.dcmread(dicom_data, force=True)
        
        num_frames = getattr(ds, 'NumberOfFrames', 1)
        rows = ds.Rows
        cols = ds.Columns
        
        try:
            pixel_array = ds.pixel_array
            if pixel_array.ndim == 2:
                pixel_array = pixel_array[np.newaxis, ...]
        except:
            pixel_data = np.frombuffer(ds.PixelData, dtype=np.uint8)
            if ds.BitsAllocated == 1:
                pixel_array = np.unpackbits(pixel_data).reshape(num_frames, rows, cols)
            else:
                pixel_array = pixel_data.reshape(num_frames, rows, cols)
        
        frames = []
        for i in range(num_frames):
            frame_data = (pixel_array[i] > 0).astype(np.uint8) * 255
            from PIL import Image
            img = Image.fromarray(frame_data, mode='L')
            buffer = io.BytesIO()
            img.save(buffer, format='PNG')
            mask_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            frames.append({
                "index": i,
                "mask_base64": mask_base64
            })
        
        return Response({
            "success": True,
            "num_frames": len(frames),
            "frames": frames
        })
        
    except Exception as e:
        logger.error(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            "success": False,
            "error": str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ============================================================
# ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡  ìš”ì²­ API
# ============================================================

REQUEST_DIR = Path(os.getenv('INFERENCE_REQUEST_DIR', '/tmp/mri_inference_requests'))

def _create_local_inference_request(request, series_id, sequence_series_ids):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­ ìƒì„± (ë‚´ë¶€ í•¨ìˆ˜)
    """
    try:
        REQUEST_DIR.mkdir(exist_ok=True, parents=True)
        
        request_data = {
            'series_ids': sequence_series_ids,
            'main_series_id': series_id,
            'requested_at': timezone.now().isoformat(),
            'status': 'pending',
            'requested_by': getattr(request.user, 'username', 'anonymous') if hasattr(request, 'user') and hasattr(request.user, 'is_authenticated') and request.user.is_authenticated else 'anonymous'
        }
        
        timestamp = int(timezone.now().timestamp() * 1000)
        request_id = f"{series_id}_{timestamp}"
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ì¶”ë¡  ìš”ì²­ ìƒì„±: {request_file.name}")
        
        import time
        max_wait_time = 600  # 10ë¶„ (ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŒ)
        check_interval = 2
        elapsed_time = 0
        
        while elapsed_time < max_wait_time:
            time.sleep(check_interval)
            elapsed_time += check_interval
            
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    current_data = json.load(f)
                
                current_status = current_data.get('status')
                if current_status == 'completed':
                    result = current_data.get('result', {})
                    return Response({
                        'success': True,
                        'series_id': series_id,
                        'request_id': request_id,
                        'tumor_detected': result.get('tumor_detected'),
                        'tumor_volume_voxels': result.get('tumor_volume_voxels'),
                        'seg_instance_id': result.get('seg_instance_id'),
                        'elapsed_time_seconds': result.get('elapsed_time_seconds'),
                        'saved_to_orthanc': True,
                        'processed_by': 'local_worker'
                    })
                elif current_status == 'failed':
                    result = current_data.get('result', {})
                    return Response({
                        'success': False,
                        'error': result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'),
                        'request_id': request_id
                    }, status=500)
            except:
                pass
        
        return Response({
            'success': False,
            'error': f'ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (ìµœëŒ€ {max_wait_time}ì´ˆ)',
            'request_id': request_id
        }, status=504)
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ìš”ì²­ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['POST'])
def request_local_inference(request, series_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­
    """
    sequence_series_ids = request.data.get("sequence_series_ids", [])
    if len(sequence_series_ids) != 4:
        return Response({'success': False, 'error': '4ê°œ ì‹œë¦¬ì¦ˆ í•„ìš”'}, status=400)
    return _create_local_inference_request(request, series_id, sequence_series_ids)


@api_view(['GET'])
def check_inference_status(request, request_id):
    """
    ì¶”ë¡  ìš”ì²­ ìƒíƒœ í™•ì¸
    """
    try:
        request_files = list(REQUEST_DIR.glob(f"{request_id}.json"))
        if not request_files:
            return Response({'success': False, 'error': 'ìš”ì²­ ì—†ìŒ'}, status=404)
        
        with open(request_files[0], 'r', encoding='utf-8') as f:
            request_data = json.load(f)
        
        return Response({'success': True, 'request_id': request_id, 'status': request_data.get('status'), 'result': request_data.get('result')})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['GET'])
def list_inference_requests(request):
    """
    ì¶”ë¡  ìš”ì²­ ëª©ë¡ ì¡°íšŒ
    """
    try:
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime, reverse=True)
        requests_list = []
        for rf in request_files[:50]:
            with open(rf, 'r', encoding='utf-8') as f:
                d = json.load(f)
                requests_list.append({'request_id': rf.stem, 'status': d.get('status'), 'requested_at': d.get('requested_at')})
        return Response({'success': True, 'requests': requests_list})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['GET'])
def get_pending_requests(request):
    """
    ì›Œì»¤ìš©: ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì¡°íšŒ
    """
    try:
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime)
        pending = []
        for rf in request_files:
            with open(rf, 'r', encoding='utf-8') as f:
                d = json.load(f)
                if d.get('status') == 'pending':
                    pending.append({'request_id': rf.stem, 'series_ids': d.get('series_ids'), 'main_series_id': d.get('main_series_id')})
        return Response({'success': True, 'requests': pending})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['GET'])
def get_pending_inference(request):
    """
    ì¡°ì›ë‹˜ ì›Œì»¤ í˜¸í™˜ìš©
    """
    try:
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime)
        for rf in request_files:
            with open(rf, 'r', encoding='utf-8') as f:
                d = json.load(f)
                if d.get('status') == 'pending':
                    d['status'] = 'processing'
                    with open(rf, 'w', encoding='utf-8') as f2:
                        json.dump(d, f2, indent=2, ensure_ascii=False)
                    return Response({'id': rf.stem, 'series_id': d.get('main_series_id'), 'series_ids': d.get('series_ids', [])})
        return Response({'id': None})
    except Exception as e:
        return Response({'id': None, 'error': str(e)}, status=500)


@api_view(['POST'])
def complete_inference(request, request_id):
    """
    ì¡°ì›ë‹˜ ì›Œì»¤ í˜¸í™˜ìš©
    """
    try:
        request_file = REQUEST_DIR / f"{request_id}.json"
        if not request_file.exists(): return Response({'success': False}, status=404)
        with open(request_file, 'r', encoding='utf-8') as f:
            d = json.load(f)
        d['status'] = 'completed' if request.data.get('success') else 'failed'
        d['result'] = request.data
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(d, f, indent=2, ensure_ascii=False)
        return Response({'success': True})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['POST'])
@authentication_classes([CSRFExemptSessionAuthentication])
@permission_classes([AllowAny])
def complete_inference_request(request, request_id):
    return complete_inference(request, request_id)


@api_view(['POST'])
def update_request_status(request, request_id):
    try:
        request_file = REQUEST_DIR / f"{request_id}.json"
        if not request_file.exists(): return Response({'success': False}, status=404)
        with open(request_file, 'r', encoding='utf-8') as f:
            d = json.load(f)
        d['status'] = request.data.get('status', d['status'])
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(d, f, indent=2, ensure_ascii=False)
        return Response({'success': True})
    except Exception as e:
        return Response({'success': False}, status=500)

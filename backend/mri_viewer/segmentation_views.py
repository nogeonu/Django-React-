"""
MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ API Views (MAMA_MIA_DELIVERY_PKG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
- Orthanc ì—°ë™: ê¸°ì¡´ ì‹œìŠ¤í…œ ë¡œì§ ìœ ì§€
- ì¶”ë¡ : ìƒˆë¡œìš´ MAMA_MIA íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
- ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡ : ë¡œì»¬ í™˜ê²½ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ê°€ëŠ¥
"""
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.response import Response
from rest_framework import status
from rest_framework.authentication import SessionAuthentication
from rest_framework.permissions import AllowAny
from django.utils import timezone
from django.views.decorators.csrf import csrf_exempt
import requests
import io
import logging
import os
import base64
import numpy as np
import pydicom
import tempfile
import shutil
import json
from pathlib import Path
from .orthanc_client import OrthancClient
import sys

# ìƒˆë¡œìš´ MAMA_MIA ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ import (ì§€ì—° ë¡œë“œë¡œ ë³€ê²½)
# Django ì‹œì‘ ì‹œ import ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import

logger = logging.getLogger(__name__)

# Orthanc ì„¤ì •
ORTHANC_URL = os.getenv('ORTHANC_URL', 'http://34.42.223.43:8042')
ORTHANC_USER = os.getenv('ORTHANC_USER', 'admin')
ORTHANC_PASSWORD = os.getenv('ORTHANC_PASSWORD', 'admin123')

# ëª¨ë¸ ê²½ë¡œ (ìš°ì„ ìˆœìœ„: src/best_model.pth -> checkpoints/best_model.pth)
MODEL_PATH = Path(__file__).parent.parent / "mri_segmentation" / "src" / "best_model.pth"
if not MODEL_PATH.exists():
    MODEL_PATH = Path(__file__).parent.parent / "mri_segmentation" / "checkpoints" / "best_model.pth"
if not MODEL_PATH.exists():
    logger.warning(f"Model file not found at expected locations. Searched: {MODEL_PATH}")

# ì „ì—­ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (í•œ ë²ˆë§Œ ë¡œë“œ)
_pipeline = None

def get_pipeline():
    """ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹±ê¸€í†¤ (ì§€ì—° ë¡œë“œ)"""
    global _pipeline
    if _pipeline is None:
        # ì§€ì—° importë¡œ Django ì‹œì‘ ì‹œ ì˜¤ë¥˜ ë°©ì§€
        sys.path.insert(0, str(Path(__file__).parent.parent / "mri_segmentation" / "src"))
        from inference_pipeline import SegmentationInferencePipeline
        
        logger.info(f"Loading segmentation model from: {MODEL_PATH}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        import torch
        device = "cpu"  # ê¸°ë³¸ê°’ì€ CPU
        if os.getenv('USE_GPU', 'false').lower() == 'true':
            if torch.cuda.is_available():
                device = "cuda"
                logger.info("Using CUDA GPU for inference")
            else:
                logger.warning("GPU requested but not available. Using CPU instead.")
        else:
            logger.info("Using CPU for inference (set USE_GPU=true to enable GPU)")
        
        _pipeline = SegmentationInferencePipeline(
            model_path=str(MODEL_PATH),
            device=device,
            threshold=0.5
        )
        logger.info("Model loaded successfully!")
    return _pipeline


# CSRF ì²´í¬ë¥¼ ê±´ë„ˆë›°ëŠ” ì»¤ìŠ¤í…€ ì¸ì¦ í´ë˜ìŠ¤
class CSRFExemptSessionAuthentication(SessionAuthentication):
    def enforce_csrf(self, request):
        return  # CSRF ì²´í¬ë¥¼ ê±´ë„ˆëœ€


@api_view(['POST'])
@authentication_classes([CSRFExemptSessionAuthentication])
@permission_classes([AllowAny])
def mri_segmentation(request, instance_id):
    """
    MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ë° Orthancì— ì €ì¥ (ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” 4ì±„ë„)
    
    POST /api/mri/segmentation/instances/<instance_id>/segment/
    """
    try:
        # Request bodyì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ ID ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œ)
        sequence_ids = request.data.get('sequence_instance_ids', [instance_id])
        
        logger.info(f"ğŸ” MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘: {len(sequence_ids)}ê°œ ì‹œí€€ìŠ¤")
        logger.info(f"   Instance IDs: {sequence_ids}")
        
        # 4ì±„ë„ì¸ ê²½ìš° perform_segment_series_logic ì‚¬ìš©
        if len(sequence_ids) == 4:
            # ê° ì¸ìŠ¤í„´ìŠ¤ì˜ ì‹œë¦¬ì¦ˆ ID ì°¾ê¸°
            client = OrthancClient()
            sequence_series_ids = []
            for inst_id in sequence_ids:
                inst_info = client.get_instance_info(inst_id)
                parent_series = inst_info.get('ParentSeries')
                if parent_series:
                    sequence_series_ids.append(parent_series)
            
            if len(sequence_series_ids) == 4:
                return _perform_segment_series_logic(request, sequence_series_ids[0], sequence_series_ids)
            else:
                return Response({
                    'success': False,
                    'error': '4ê°œ ì‹œí€€ìŠ¤ì˜ ì‹œë¦¬ì¦ˆ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=400)
        else:
            # ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œëŠ” ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠìŒ
            return Response({
                'success': False,
                'error': 'ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œëŠ” ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 4ì±„ë„ DCE-MRIë§Œ ì§€ì›í•©ë‹ˆë‹¤.'
            }, status=400)
            
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'instance_id': instance_id,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def segmentation_health(request):
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ API ì„œë²„ ìƒíƒœ í™•ì¸
    
    GET /api/mri/segmentation/health/
    """
    try:
        # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        model_file_exists = MODEL_PATH.exists()
        
        # ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        model_loaded = False
        error_msg = None
        try:
            pipeline = get_pipeline()
            model_loaded = pipeline is not None
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            error_msg = str(e)
            model_loaded = False
        
        return Response({
            'success': True,
            'status': 'healthy' if model_loaded else 'model_not_loaded',
            'service': 'New Segmentation Pipeline',
            'model_loaded': model_loaded,
            'model_file_exists': model_file_exists,
            'model_path': str(MODEL_PATH),
            'orthanc_url': ORTHANC_URL,
            'error': error_msg if error_msg else None
        })
    except Exception as e:
        return Response({
            'success': False,
            'status': 'unavailable',
            'error': str(e)
        }, status=status.HTTP_503_SERVICE_UNAVAILABLE)


@api_view(['POST'])
@authentication_classes([CSRFExemptSessionAuthentication])
@permission_classes([AllowAny])
def segment_series(request, series_id):
    """
    ì‹œë¦¬ì¦ˆ ì „ì²´ë¥¼ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜í•˜ê³  Orthancì— ì €ì¥
    
    POST /api/mri/segmentation/series/<series_id>/segment/
    """
    sequence_series_ids = request.data.get("sequence_series_ids", [])
    if len(sequence_series_ids) != 4:
        return Response({
            "success": False,
            "error": "4ê°œ ì‹œë¦¬ì¦ˆê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."
        }, status=400)
    
    return _perform_segment_series_logic(request, series_id, sequence_series_ids)


def _perform_segment_series_logic(request, series_id, sequence_series_ids):
    """
    ì‹œë¦¬ì¦ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ í•µì‹¬ ë¡œì§ (Mosec ì„œë¹„ìŠ¤ ì‚¬ìš©)
    DjangoëŠ” Mosecì— series_idsë§Œ ì „ë‹¬í•˜ê³ , Mosecì´ Orthancì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¶”ë¡  í›„ ì €ì¥
    """
    try:
        logger.info(f"ğŸ” ì‹œë¦¬ì¦ˆ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘: series_id={series_id}")
        logger.info("â˜ï¸ Mosec ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ì¶”ë¡  ì‹¤í–‰")
        
        client = OrthancClient()
        
        # 1. Orthancì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ì˜ Instance ID ìˆ˜ì§‘
        orthanc_instance_ids = []
        for seq_idx, seq_series_id in enumerate(sequence_series_ids):
            seq_info = client.get(f"/series/{seq_series_id}")
            seq_instances = seq_info.get("Instances", [])
            
            if len(seq_instances) == 0:
                return Response({
                    "success": False,
                    "error": f"ì‹œí€€ìŠ¤ {seq_idx+1}ì— ìŠ¬ë¼ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
                }, status=400)
            
            orthanc_instance_ids.append(seq_instances)
            logger.info(f"âœ… ì‹œí€€ìŠ¤ {seq_idx+1}/4: {len(seq_instances)}ê°œ ìŠ¬ë¼ì´ìŠ¤ ID ìˆ˜ì§‘ ì™„ë£Œ")
        
        # 2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œë¦¬ì¦ˆ UID ìƒì„±
        from pydicom.uid import generate_uid
        seg_series_uid = generate_uid()
        
        # 3. Mosecì— ìš”ì²­ ì „ì†¡ (instance_idsë§Œ ì „ì†¡)
        logger.info(f"ğŸš€ Mosec ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘... (4ê°œ ì‹œí€€ìŠ¤, Orthanc API ì‚¬ìš©)")
        
        payload = {
            "orthanc_instance_ids": orthanc_instance_ids,
            "orthanc_url": ORTHANC_URL,
            "orthanc_auth": [ORTHANC_USER, ORTHANC_PASSWORD],
            "seg_series_uid": seg_series_uid,
            "original_series_id": series_id,
            "start_instance_number": 1
        }
        
        response = requests.post(
            SEGMENTATION_MOSEC_URL,
            json=payload,
            headers={'Content-Type': 'application/json'},
            timeout=2400  # 40ë¶„ íƒ€ì„ì•„ì›ƒ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ê³ ë ¤)
        )
        
        if response.status_code != 200:
            logger.error(f"âŒ Mosec ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return Response({
                'success': False,
                'error': f'Mosec ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {response.status_code} - {response.text[:500]}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        
        # 4. Mosec ì‘ë‹µ ì²˜ë¦¬
        try:
            mosec_result = response.json()
            logger.info(f"ğŸ“¥ Mosec ì‘ë‹µ ìˆ˜ì‹ : {type(mosec_result)}")
            
            if not isinstance(mosec_result, dict):
                logger.error(f"âŒ Mosec ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: ì˜ˆìƒ dict, ì‹¤ì œ {type(mosec_result)}")
                return Response({
                    'success': False,
                    'error': f'Mosec ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: ì˜ˆìƒ dict, ì‹¤ì œ {type(mosec_result)}'
                }, status=500)
            
            # Mosecì´ Orthancì— ì €ì¥í•œ seg_instance_id í™•ì¸
            seg_instance_id = mosec_result.get('seg_instance_id')
            tumor_ratio_percent = mosec_result.get('tumor_ratio_percent', 0.0)
            tumor_pixel_count = mosec_result.get('tumor_pixel_count', 0)

            # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ (Mosec ì‘ë‹µì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜, orthanc_instance_idsì—ì„œ ê³„ì‚°)
            total_slices = mosec_result.get('total_slices', 0)
            successful_slices = mosec_result.get('successful_slices', 0)

            # total_slicesê°€ ì—†ìœ¼ë©´ orthanc_instance_idsì—ì„œ ê³„ì‚°
            if total_slices == 0 and orthanc_instance_ids:
                total_slices = len(orthanc_instance_ids[0]) if orthanc_instance_ids else 0
                successful_slices = total_slices  # Mosec ì„±ê³µ ì‹œ ëª¨ë“  ìŠ¬ë¼ì´ìŠ¤ ì²˜ë¦¬ ì™„ë£Œë¡œ ê°€ì •

            # tumor_detectedëŠ” tumor_ratio_percentê°€ 0ë³´ë‹¤ í¬ë©´ True
            tumor_detected = tumor_ratio_percent > 0.0
            # tumor_volume_voxelsëŠ” tumor_pixel_countë¥¼ ì‚¬ìš© (ë˜ëŠ” ê³„ì‚°)
            tumor_volume_voxels = tumor_pixel_count

            if not seg_instance_id:
                logger.warning("âš ï¸ Mosec ì‘ë‹µì— seg_instance_idê°€ ì—†ìŠµë‹ˆë‹¤. Mosecì´ Orthancì— ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

            logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ: tumor_detected={tumor_detected}, tumor_ratio={tumor_ratio_percent:.2f}%, seg_instance_id={seg_instance_id}, slices={successful_slices}/{total_slices}")

            return Response({
                'success': True,
                'series_id': series_id,
                'tumor_detected': tumor_detected,
                'tumor_volume_voxels': tumor_volume_voxels,
                'tumor_ratio_percent': tumor_ratio_percent,
                'seg_instance_id': seg_instance_id,
                'saved_to_orthanc': seg_instance_id is not None,
                'processed_by': 'mosec',
                'total_slices': total_slices,
                'successful_slices': successful_slices
            })
            
        except Exception as e:
            logger.error(f"âŒ Mosec ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            return Response({
                'success': False,
                'error': f'Mosec ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'
            }, status=500)
    
    except requests.exceptions.Timeout:
        logger.error(f"âŒ Mosec ì„œë¹„ìŠ¤ íƒ€ì„ì•„ì›ƒ")
        return Response({
            'success': False,
            'error': 'AI ë¶„ì„ íƒ€ì„ì•„ì›ƒ (40ë¶„ ì´ˆê³¼)'
        }, status=status.HTTP_504_GATEWAY_TIMEOUT)
    except requests.exceptions.ConnectionError:
        logger.error(f"âŒ Mosec ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        return Response({
            'success': False,
            'error': 'Mosec ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.'
        }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¡œì§ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'series_id': series_id,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_segmentation_frames(request, seg_instance_id):
    """
    DICOM SEG íŒŒì¼ì—ì„œ ëª¨ë“  í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    """
    try:
        logger.info(f"ğŸ” DICOM SEG í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘: {seg_instance_id}")
        client = OrthancClient()
        seg_dicom_bytes = client.get_instance_file(seg_instance_id)
        
        dicom_data = io.BytesIO(seg_dicom_bytes)
        ds = pydicom.dcmread(dicom_data, force=True)
        
        num_frames = getattr(ds, 'NumberOfFrames', 1)
        rows = ds.Rows
        cols = ds.Columns
        
        try:
            pixel_array = ds.pixel_array
            if pixel_array.ndim == 2:
                pixel_array = pixel_array[np.newaxis, ...]
        except:
            pixel_data = np.frombuffer(ds.PixelData, dtype=np.uint8)
            if ds.BitsAllocated == 1:
                pixel_array = np.unpackbits(pixel_data).reshape(num_frames, rows, cols)
            else:
                pixel_array = pixel_data.reshape(num_frames, rows, cols)
        
        frames = []
        for i in range(num_frames):
            frame_data = (pixel_array[i] > 0).astype(np.uint8) * 255
            from PIL import Image
            img = Image.fromarray(frame_data, mode='L')
            buffer = io.BytesIO()
            img.save(buffer, format='PNG')
            mask_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            frames.append({
                "index": i,
                "mask_base64": mask_base64
            })
        
        return Response({
            "success": True,
            "num_frames": len(frames),
            "frames": frames
        })
        
    except Exception as e:
        logger.error(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            "success": False,
            "error": str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_segmentation_volume_instances(request, seg_instance_id):
    """
    DICOM SEG íŒŒì¼ì˜ ê° í”„ë ˆì„ì„ ê°œë³„ DICOM ì¸ìŠ¤í„´ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ Orthancì— ì—…ë¡œë“œí•˜ê³  ì¸ìŠ¤í„´ìŠ¤ ID ëª©ë¡ ë°˜í™˜
    3D ë³¼ë¥¨ ë Œë”ë§ì„ ìœ„í•´ ì‚¬ìš©
    """
    try:
        logger.info(f"ğŸ” DICOM SEG â†’ ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ ë³€í™˜ ì‹œì‘: {seg_instance_id}")
        client = OrthancClient()
        
        # 1. DICOM SEG íŒŒì¼ ë¡œë“œ
        seg_dicom_bytes = client.get_instance_file(seg_instance_id)
        dicom_data = io.BytesIO(seg_dicom_bytes)
        ds = pydicom.dcmread(dicom_data, force=True)
        
        # 2. ì›ë³¸ DICOM ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì°¸ì¡°ìš©)
        study_instance_uid = getattr(ds, 'StudyInstanceUID', None)
        if not study_instance_uid:
            return Response({
                'success': False,
                'error': 'StudyInstanceUID not found in SEG file'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # ì›ë³¸ ì‹œë¦¬ì¦ˆì˜ ì²« ë²ˆì§¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë©”íƒ€ë°ì´í„° ì°¸ì¡°ìš©)
        reference_dicom = None
        try:
            # StudyInstanceUIDë¡œ Study ì°¾ê¸°
            studies_response = requests.get(f"{client.base_url}/studies", auth=client.auth)
            studies_response.raise_for_status()
            all_studies = studies_response.json()
            
            study_id = None
            for study in all_studies:
                study_id_str = study if isinstance(study, str) else study.get('ID', study)
                study_info_response = requests.get(
                    f"{client.base_url}/studies/{study_id_str}",
                    auth=client.auth
                )
                if study_info_response.status_code == 200:
                    study_info = study_info_response.json()
                    tags = study_info.get('MainDicomTags', {})
                    if tags.get('StudyInstanceUID') == study_instance_uid:
                        study_id = study_id_str
                        break
            
            if study_id:
                # Studyì˜ Series ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                series_response = requests.get(
                    f"{client.base_url}/studies/{study_id}/series",
                    auth=client.auth
                )
                if series_response.status_code == 200:
                    series_list = series_response.json()
                    
                    # SEGê°€ ì•„ë‹Œ ì›ë³¸ ì‹œë¦¬ì¦ˆ ì°¾ê¸°
                    for series_id in series_list:
                        series_info_response = requests.get(
                            f"{client.base_url}/series/{series_id}",
                            auth=client.auth
                        )
                        if series_info_response.status_code == 200:
                            series_info = series_info_response.json()
                            modality = series_info.get('MainDicomTags', {}).get('Modality', '')
                            if modality != 'SEG':
                                instances = series_info.get('Instances', [])
                                if instances:
                                    reference_instance_id = instances[0]
                                    ref_bytes = client.get_instance_file(reference_instance_id)
                                    reference_dicom = pydicom.dcmread(io.BytesIO(ref_bytes), force=True)
                                    break
        except Exception as e:
            logger.warning(f"ì›ë³¸ DICOM ì°¸ì¡° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        
        # 3. í”„ë ˆì„ ë°ì´í„° ì¶”ì¶œ
        num_frames = getattr(ds, 'NumberOfFrames', 1)
        rows = ds.Rows
        cols = ds.Columns
        
        try:
            pixel_array = ds.pixel_array
            if pixel_array.ndim == 2:
                pixel_array = pixel_array[np.newaxis, ...]
        except:
            pixel_data = np.frombuffer(ds.PixelData, dtype=np.uint8)
            if ds.BitsAllocated == 1:
                pixel_array = np.unpackbits(pixel_data).reshape(num_frames, rows, cols)
            else:
                pixel_array = pixel_data.reshape(num_frames, rows, cols)
        
        # 4. ê° í”„ë ˆì„ì„ ê°œë³„ DICOM ì¸ìŠ¤í„´ìŠ¤ë¡œ ë³€í™˜
        instance_ids = []
        from pydicom.dataset import FileDataset, FileMetaDataset
        from pydicom.uid import generate_uid, ExplicitVRLittleEndian
        
        for frame_idx in range(num_frames):
            frame_data = (pixel_array[frame_idx] > 0).astype(np.uint8) * 255
            
            # ìƒˆ DICOM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            file_meta = FileMetaDataset()
            file_meta.TransferSyntaxUID = ExplicitVRLittleEndian
            file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.2'  # CT Image Storage
            file_meta.MediaStorageSOPInstanceUID = generate_uid()
            file_meta.ImplementationClassUID = generate_uid()
            
            new_ds = FileDataset(None, {}, file_meta=file_meta, preamble=b"\0" * 128)
            
            # ì›ë³¸ DICOMì—ì„œ ë©”íƒ€ë°ì´í„° ë³µì‚¬ (ìˆëŠ” ê²½ìš°)
            if reference_dicom:
                new_ds.PatientName = getattr(reference_dicom, 'PatientName', 'Anonymous')
                new_ds.PatientID = getattr(reference_dicom, 'PatientID', 'Unknown')
                new_ds.PatientBirthDate = getattr(reference_dicom, 'PatientBirthDate', '')
                new_ds.PatientSex = getattr(reference_dicom, 'PatientSex', '')
                new_ds.StudyInstanceUID = getattr(reference_dicom, 'StudyInstanceUID', study_instance_uid)
                new_ds.StudyDate = getattr(reference_dicom, 'StudyDate', '')
                new_ds.StudyTime = getattr(reference_dicom, 'StudyTime', '')
                new_ds.StudyID = getattr(reference_dicom, 'StudyID', '')
                new_ds.AccessionNumber = getattr(reference_dicom, 'AccessionNumber', '')
                
                # ImagePositionPatient, ImageOrientationPatient ë“± ë³µì‚¬ (ìˆëŠ” ê²½ìš°)
                if hasattr(reference_dicom, 'ImagePositionPatient') and hasattr(reference_dicom, 'ImageOrientationPatient'):
                    # Z ìœ„ì¹˜ë¥¼ í”„ë ˆì„ ì¸ë±ìŠ¤ì— ë”°ë¼ ì¡°ì •
                    pos = np.array(reference_dicom.ImagePositionPatient)
                    slice_thickness = float(getattr(reference_dicom, 'SliceThickness', 1.0))
                    iop = np.array(reference_dicom.ImageOrientationPatient)
                    # ìŠ¬ë¼ì´ìŠ¤ ë…¸ë§ ê³„ì‚°
                    row_cos = iop[:3]
                    col_cos = iop[3:6]
                    slice_normal = np.cross(row_cos, col_cos)
                    # í”„ë ˆì„ ì¸ë±ìŠ¤ì— ë”°ë¼ ìœ„ì¹˜ ì¡°ì •
                    new_pos = pos + slice_normal * slice_thickness * frame_idx
                    new_ds.ImagePositionPatient = new_pos.tolist()
                    new_ds.ImageOrientationPatient = iop.tolist()
                
                if hasattr(reference_dicom, 'PixelSpacing'):
                    new_ds.PixelSpacing = reference_dicom.PixelSpacing
                if hasattr(reference_dicom, 'SliceThickness'):
                    new_ds.SliceThickness = reference_dicom.SliceThickness
                if hasattr(reference_dicom, 'SpacingBetweenSlices'):
                    new_ds.SpacingBetweenSlices = reference_dicom.SpacingBetweenSlices
            else:
                # ê¸°ë³¸ê°’
                new_ds.PatientName = getattr(ds, 'PatientName', 'Anonymous')
                new_ds.PatientID = getattr(ds, 'PatientID', 'Unknown')
                new_ds.StudyInstanceUID = study_instance_uid
                new_ds.StudyDate = getattr(ds, 'StudyDate', '')
                new_ds.StudyTime = getattr(ds, 'StudyTime', '')
            
            # ì‹œë¦¬ì¦ˆ ì •ë³´ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ì „ìš© ì‹œë¦¬ì¦ˆ)
            seg_series_uid = getattr(ds, 'SeriesInstanceUID', generate_uid())
            new_ds.SeriesInstanceUID = f"{seg_series_uid}_volume"  # ë³¼ë¥¨ ë Œë”ë§ìš© ì‹œë¦¬ì¦ˆ
            new_ds.SeriesNumber = '9998'
            new_ds.SeriesDescription = 'AI Tumor Segmentation (Volume Rendering)'
            new_ds.Modality = 'MR'  # MRIë¡œ í‘œì‹œ (ë³¼ë¥¨ ë Œë”ë§ í˜¸í™˜ì„±)
            
            # SOP Instance ì •ë³´
            new_ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.4'  # MR Image Storage
            new_ds.SOPInstanceUID = file_meta.MediaStorageSOPInstanceUID
            new_ds.InstanceNumber = str(frame_idx + 1)
            
            # í”½ì…€ ë°ì´í„°
            new_ds.Rows = rows
            new_ds.Columns = cols
            new_ds.SamplesPerPixel = 1
            new_ds.PhotometricInterpretation = 'MONOCHROME2'
            new_ds.BitsAllocated = 8
            new_ds.BitsStored = 8
            new_ds.HighBit = 7
            new_ds.PixelRepresentation = 0
            new_ds.PixelData = frame_data.tobytes()
            
            # DICOM ì¸ì½”ë”© ì„¤ì •
            new_ds.is_little_endian = True
            new_ds.is_implicit_VR = False
            
            # Orthancì— ì—…ë¡œë“œ
            dicom_bytes = io.BytesIO()
            new_ds.save_as(dicom_bytes, write_like_original=False)
            dicom_bytes.seek(0)
            
            # Orthanc ì—…ë¡œë“œ
            upload_response = requests.post(
                f"{client.base_url}/instances",
                data=dicom_bytes.read(),
                headers={'Content-Type': 'application/dicom'},
                auth=client.auth
            )
            upload_response.raise_for_status()
            uploaded_id = upload_response.json()['ID']
            instance_ids.append(uploaded_id)
            
            logger.debug(f"í”„ë ˆì„ {frame_idx + 1}/{num_frames} ë³€í™˜ ì™„ë£Œ: {uploaded_id}")
        
        logger.info(f"âœ… DICOM SEG â†’ {len(instance_ids)}ê°œ ì¸ìŠ¤í„´ìŠ¤ ë³€í™˜ ì™„ë£Œ")
        
        return Response({
            'success': True,
            'num_frames': len(instance_ids),
            'instance_ids': instance_ids,
            'series_instance_uid': f"{seg_series_uid}_volume",
        })
        
    except Exception as e:
        logger.error(f"âŒ DICOM SEG â†’ ì¸ìŠ¤í„´ìŠ¤ ë³€í™˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ============================================================
# ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡  ìš”ì²­ API
# ============================================================

REQUEST_DIR = Path(os.getenv('INFERENCE_REQUEST_DIR', '/tmp/mri_inference_requests'))

def _create_local_inference_request(request, series_id, sequence_series_ids):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­ ìƒì„± (ë‚´ë¶€ í•¨ìˆ˜)
    """
    try:
        REQUEST_DIR.mkdir(exist_ok=True, parents=True)
        
        request_data = {
            'series_ids': sequence_series_ids,
            'main_series_id': series_id,
            'requested_at': timezone.now().isoformat(),
            'status': 'pending',
            'requested_by': getattr(request.user, 'username', 'anonymous') if hasattr(request, 'user') and hasattr(request.user, 'is_authenticated') and request.user.is_authenticated else 'anonymous'
        }
        
        timestamp = int(timezone.now().timestamp() * 1000)
        request_id = f"{series_id}_{timestamp}"
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ì¶”ë¡  ìš”ì²­ ìƒì„±: {request_file.name}")
        
        import time
        max_wait_time = 600  # 10ë¶„ (ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŒ)
        check_interval = 2
        elapsed_time = 0
        
        while elapsed_time < max_wait_time:
            time.sleep(check_interval)
            elapsed_time += check_interval
            
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    current_data = json.load(f)
                
                current_status = current_data.get('status')
                if current_status == 'completed':
                    result = current_data.get('result', {})
                    return Response({
                        'success': True,
                        'series_id': series_id,
                        'request_id': request_id,
                        'tumor_detected': result.get('tumor_detected'),
                        'tumor_volume_voxels': result.get('tumor_volume_voxels'),
                        'seg_instance_id': result.get('seg_instance_id'),
                        'elapsed_time_seconds': result.get('elapsed_time_seconds'),
                        'saved_to_orthanc': True,
                        'processed_by': 'local_worker'
                    })
                elif current_status == 'failed':
                    result = current_data.get('result', {})
                    return Response({
                        'success': False,
                        'error': result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'),
                        'request_id': request_id
                    }, status=500)
            except:
                pass
        
        return Response({
            'success': False,
            'error': f'ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (ìµœëŒ€ {max_wait_time}ì´ˆ)',
            'request_id': request_id
        }, status=504)
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ìš”ì²­ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['POST'])
def request_local_inference(request, series_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­
    """
    sequence_series_ids = request.data.get("sequence_series_ids", [])
    if len(sequence_series_ids) != 4:
        return Response({'success': False, 'error': '4ê°œ ì‹œë¦¬ì¦ˆ í•„ìš”'}, status=400)
    return _create_local_inference_request(request, series_id, sequence_series_ids)


@api_view(['GET'])
def check_inference_status(request, request_id):
    """
    ì¶”ë¡  ìš”ì²­ ìƒíƒœ í™•ì¸
    """
    try:
        request_files = list(REQUEST_DIR.glob(f"{request_id}.json"))
        if not request_files:
            return Response({'success': False, 'error': 'ìš”ì²­ ì—†ìŒ'}, status=404)
        
        with open(request_files[0], 'r', encoding='utf-8') as f:
            request_data = json.load(f)
        
        return Response({'success': True, 'request_id': request_id, 'status': request_data.get('status'), 'result': request_data.get('result')})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['GET'])
def list_inference_requests(request):
    """
    ì¶”ë¡  ìš”ì²­ ëª©ë¡ ì¡°íšŒ
    """
    try:
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime, reverse=True)
        requests_list = []
        for rf in request_files[:50]:
            with open(rf, 'r', encoding='utf-8') as f:
                d = json.load(f)
                requests_list.append({'request_id': rf.stem, 'status': d.get('status'), 'requested_at': d.get('requested_at')})
        return Response({'success': True, 'requests': requests_list})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['GET'])
def get_pending_requests(request):
    """
    ì›Œì»¤ìš©: ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì¡°íšŒ
    """
    try:
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime)
        pending = []
        for rf in request_files:
            with open(rf, 'r', encoding='utf-8') as f:
                d = json.load(f)
                if d.get('status') == 'pending':
                    pending.append({'request_id': rf.stem, 'series_ids': d.get('series_ids'), 'main_series_id': d.get('main_series_id')})
        return Response({'success': True, 'requests': pending})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['GET'])
def get_pending_inference(request):
    """
    ì¡°ì›ë‹˜ ì›Œì»¤ í˜¸í™˜ìš©
    """
    try:
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime)
        for rf in request_files:
            with open(rf, 'r', encoding='utf-8') as f:
                d = json.load(f)
                if d.get('status') == 'pending':
                    d['status'] = 'processing'
                    with open(rf, 'w', encoding='utf-8') as f2:
                        json.dump(d, f2, indent=2, ensure_ascii=False)
                    return Response({'id': rf.stem, 'series_id': d.get('main_series_id'), 'series_ids': d.get('series_ids', [])})
        return Response({'id': None})
    except Exception as e:
        return Response({'id': None, 'error': str(e)}, status=500)


@api_view(['POST'])
def complete_inference(request, request_id):
    """
    ì¡°ì›ë‹˜ ì›Œì»¤ í˜¸í™˜ìš©
    """
    try:
        request_file = REQUEST_DIR / f"{request_id}.json"
        if not request_file.exists(): return Response({'success': False}, status=404)
        with open(request_file, 'r', encoding='utf-8') as f:
            d = json.load(f)
        d['status'] = 'completed' if request.data.get('success') else 'failed'
        d['result'] = request.data
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(d, f, indent=2, ensure_ascii=False)
        return Response({'success': True})
    except Exception as e:
        return Response({'success': False, 'error': str(e)}, status=500)


@api_view(['POST'])
@authentication_classes([CSRFExemptSessionAuthentication])
@permission_classes([AllowAny])
def complete_inference_request(request, request_id):
    return complete_inference(request, request_id)


@api_view(['POST'])
def update_request_status(request, request_id):
    try:
        request_file = REQUEST_DIR / f"{request_id}.json"
        if not request_file.exists(): return Response({'success': False}, status=404)
        with open(request_file, 'r', encoding='utf-8') as f:
            d = json.load(f)
        d['status'] = request.data.get('status', d['status'])
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(d, f, indent=2, ensure_ascii=False)
        return Response({'success': True})
    except Exception as e:
        return Response({'success': False}, status=500)

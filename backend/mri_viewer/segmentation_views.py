"""
MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ API Views (MAMA_MIA_DELIVERY_PKG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
- Orthanc ì—°ë™: ê¸°ì¡´ ì‹œìŠ¤í…œ ë¡œì§ ìœ ì§€
- ì¶”ë¡ : ìƒˆë¡œìš´ MAMA_MIA íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
- ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡ : ë¡œì»¬ í™˜ê²½ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ê°€ëŠ¥
"""
from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status
from django.utils import timezone
from django.views.decorators.csrf import csrf_exempt
import requests
import io
import logging
import os
import base64
import numpy as np
import pydicom
import tempfile
import shutil
import json
from pathlib import Path
from .orthanc_client import OrthancClient
import sys

# ìƒˆë¡œìš´ MAMA_MIA ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ import (ì§€ì—° ë¡œë“œë¡œ ë³€ê²½)
# Django ì‹œì‘ ì‹œ import ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import

logger = logging.getLogger(__name__)

# Orthanc ì„¤ì •
ORTHANC_URL = os.getenv('ORTHANC_URL', 'http://34.42.223.43:8042')
ORTHANC_USER = os.getenv('ORTHANC_USER', 'admin')
ORTHANC_PASSWORD = os.getenv('ORTHANC_PASSWORD', 'admin123')

# ëª¨ë¸ ê²½ë¡œ (ìš°ì„ ìˆœìœ„: src/best_model.pth -> checkpoints/best_model.pth)
MODEL_PATH = Path(__file__).parent.parent / "mri_segmentation" / "src" / "best_model.pth"
if not MODEL_PATH.exists():
    MODEL_PATH = Path(__file__).parent.parent / "mri_segmentation" / "checkpoints" / "best_model.pth"
if not MODEL_PATH.exists():
    logger.warning(f"Model file not found at expected locations. Searched: {MODEL_PATH}")

# ì „ì—­ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (í•œ ë²ˆë§Œ ë¡œë“œ)
_pipeline = None

def get_pipeline():
    """ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹±ê¸€í†¤ (ì§€ì—° ë¡œë“œ)"""
    global _pipeline
    if _pipeline is None:
        # ì§€ì—° importë¡œ Django ì‹œì‘ ì‹œ ì˜¤ë¥˜ ë°©ì§€
        sys.path.insert(0, str(Path(__file__).parent.parent / "mri_segmentation" / "src"))
        from inference_pipeline import SegmentationInferencePipeline
        
        logger.info(f"Loading segmentation model from: {MODEL_PATH}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        import torch
        device = "cpu"  # ê¸°ë³¸ê°’ì€ CPU
        if os.getenv('USE_GPU', 'false').lower() == 'true':
            if torch.cuda.is_available():
                device = "cuda"
                logger.info("Using CUDA GPU for inference")
            else:
                logger.warning("GPU requested but not available. Using CPU instead.")
        else:
            logger.info("Using CPU for inference (set USE_GPU=true to enable GPU)")
        
        _pipeline = SegmentationInferencePipeline(
            model_path=str(MODEL_PATH),
            device=device,
            threshold=0.5
        )
        logger.info("Model loaded successfully!")
    return _pipeline


@api_view(['POST'])
def mri_segmentation(request, instance_id):
    """
    ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜ (CSRF ë©´ì œ)
    """
    # CSRF ì²´í¬ ìš°íšŒë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ ì¸ì¦ í´ë˜ìŠ¤
    from rest_framework.authentication import SessionAuthentication
    
    class CSRFExemptSessionAuthentication(SessionAuthentication):
        def enforce_csrf(self, request):
            return  # CSRF ì²´í¬ë¥¼ ê±´ë„ˆëœ€
    
    # ë·° ë ˆë²¨ì—ì„œ ì¸ì¦ í´ë˜ìŠ¤ ì˜¤ë²„ë¼ì´ë“œ
    request.authenticators = [CSRFExemptSessionAuthentication()]
    """
    MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ë° Orthancì— ì €ì¥ (ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” 4ì±„ë„)
    
    POST /api/mri/segmentation/instances/<instance_id>/segment/
    Body (optional): {
        "sequence_instance_ids": [id1, id2, id3, id4]  // 4-channel DCE-MRI
    }
    """
    try:
        # Request bodyì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ ID ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œ)
        sequence_ids = request.data.get('sequence_instance_ids', [instance_id])
        
        logger.info(f"ğŸ” MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘: {len(sequence_ids)}ê°œ ì‹œí€€ìŠ¤")
        logger.info(f"   Instance IDs: {sequence_ids}")
        
        # 4ì±„ë„ì¸ ê²½ìš° segment_seriesì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
        if len(sequence_ids) == 4:
            # ê° ì¸ìŠ¤í„´ìŠ¤ì˜ ì‹œë¦¬ì¦ˆ ID ì°¾ê¸°
            client = OrthancClient()
            sequence_series_ids = []
            for inst_id in sequence_ids:
                inst_info = client.get_instance_info(inst_id)
                series_id = inst_info.get('ParentSeries')
                if series_id:
                    sequence_series_ids.append(series_id)
            
            if len(sequence_series_ids) == 4:
                # segment_series í•¨ìˆ˜ í˜¸ì¶œ
                request.data['sequence_series_ids'] = sequence_series_ids
                return segment_series(request, sequence_series_ids[0])
            else:
                return Response({
                    'success': False,
                    'error': '4ê°œ ì‹œí€€ìŠ¤ì˜ ì‹œë¦¬ì¦ˆ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }, status=400)
        else:
            # ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œëŠ” ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠìŒ
            return Response({
                'success': False,
                'error': 'ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œëŠ” ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 4ì±„ë„ DCE-MRIë§Œ ì§€ì›í•©ë‹ˆë‹¤.'
            }, status=400)
            
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'instance_id': instance_id,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def segmentation_health(request):
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ API ì„œë²„ ìƒíƒœ í™•ì¸
    
    GET /api/mri/segmentation/health/
    """
    try:
        # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        model_file_exists = MODEL_PATH.exists()
        
        # ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        model_loaded = False
        error_msg = None
        try:
            pipeline = get_pipeline()
            model_loaded = pipeline is not None
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            error_msg = str(e)
            model_loaded = False
        
        return Response({
            'success': True,
            'status': 'healthy' if model_loaded else 'model_not_loaded',
            'service': 'New Segmentation Pipeline',
            'model_loaded': model_loaded,
            'model_file_exists': model_file_exists,
            'model_path': str(MODEL_PATH),
            'orthanc_url': ORTHANC_URL,
            'error': error_msg if error_msg else None
        })
    except Exception as e:
        return Response({
            'success': False,
            'status': 'unavailable',
            'error': str(e)
        }, status=status.HTTP_503_SERVICE_UNAVAILABLE)


@api_view(['POST'])
def segment_series(request, series_id):
    """
    ì‹œë¦¬ì¦ˆ ì „ì²´ë¥¼ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜í•˜ê³  Orthancì— ì €ì¥
    
    ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ìë™ìœ¼ë¡œ ìš”ì²­ ìƒì„±, ì•„ë‹ˆë©´ GCPì—ì„œ ì§ì ‘ ì‹¤í–‰
    
    POST /api/mri/segmentation/series/<series_id>/segment/
    Body (required): {
        "sequence_series_ids": [series1_id, series2_id, series3_id, series4_id]  // 4-channel í•„ìˆ˜
    }
    Query params (optional): {
        "use_local": true/false  // ì—°êµ¬ì‹¤ ì»´í“¨í„° ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: ìë™ ê°ì§€)
    }
    """
    from rest_framework.authentication import SessionAuthentication
    from rest_framework.permissions import AllowAny
    import tempfile
    import shutil
    from pathlib import Path
    import sys
    
    # CSRF ì²´í¬ ìš°íšŒ: SessionAuthenticationì˜ enforce_csrfë¥¼ ë¹„í™œì„±í™”
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ CSRF í† í° ì—†ì´ í˜¸ì¶œ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
    class CSRFExemptSessionAuthentication(SessionAuthentication):
        def enforce_csrf(self, request):
            return  # CSRF ì²´í¬ë¥¼ ê±´ë„ˆëœ€
    
    # ë·° ë ˆë²¨ì—ì„œ ì¸ì¦ í´ë˜ìŠ¤ ì˜¤ë²„ë¼ì´ë“œ
    request.authenticators = [CSRFExemptSessionAuthentication()]
    
    try:
        logger.info(f"ğŸ” ì‹œë¦¬ì¦ˆ 3D ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘: series_id={series_id}")
        
        client = OrthancClient()
        
        # ìš”ì²­ bodyì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ ID ê°€ì ¸ì˜¤ê¸° (í•„ìˆ˜)
        sequence_series_ids = request.data.get("sequence_series_ids", [])
        
        # 4ê°œ ì‹œë¦¬ì¦ˆ í•„ìˆ˜ ì²´í¬
        if len(sequence_series_ids) != 4:
            return Response({
                "success": False,
                "error": "4ê°œ ì‹œë¦¬ì¦ˆê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤. DCE-MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•´ì„œëŠ” Seq0, Seq1, Seq2, SeqLast ì‹œë¦¬ì¦ˆê°€ ëª¨ë‘ ì„ íƒë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
            }, status=400)
        
        # ì—°êµ¬ì‹¤ ì»´í“¨í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        use_local = request.query_params.get('use_local', '').lower() == 'true'
        force_gcp = request.query_params.get('force_gcp', '').lower() == 'true'
        
        # í™˜ê²½ ë³€ìˆ˜ë¡œ ê¸°ë³¸ê°’ ì„¤ì • ê°€ëŠ¥
        if not use_local and not force_gcp:
            use_local = os.getenv('USE_LOCAL_INFERENCE', 'false').lower() == 'true'
        
        # ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ ì‚¬ìš© ì‹œ
        if use_local and not force_gcp:
            logger.info("ğŸ  ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ë¥¼ í†µí•´ ì¶”ë¡  ìš”ì²­ ìƒì„±")
            # request_local_inference ë¡œì§ì„ ì¸ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬ (csrf_exempt ì¶©ëŒ ë°©ì§€)
            return _create_local_inference_request(request, series_id, sequence_series_ids)
        
        # GCPì—ì„œ ì§ì ‘ ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹)
        logger.info("â˜ï¸ GCP ì„œë²„ì—ì„œ ì§ì ‘ ì¶”ë¡  ì‹¤í–‰")
        
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (DICOM íŒŒì¼ ì €ì¥ìš©)
        temp_dir = tempfile.mkdtemp(prefix="mri_seg_")
        reference_dicom_dir = None
        seg_dicom_path = None
        
        try:
            # 1. Orthancì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ì˜ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
            logger.info("ğŸ“¥ Orthancì—ì„œ 4ê°œ ì‹œí€€ìŠ¤ì˜ DICOM ì‘ë‹µ ëŒ€ê¸°/ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            for seq_idx, seq_series_id in enumerate(sequence_series_ids):
                seq_info = client.get(f"/series/{seq_series_id}")
                seq_instances = seq_info.get("Instances", [])
                
                if len(seq_instances) == 0:
                    return Response({
                        "success": False,
                        "error": f"ì‹œí€€ìŠ¤ {seq_idx+1}ì— ìŠ¬ë¼ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
                    }, status=400)
                
                # ì‹œí€€ìŠ¤ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
                seq_dir = Path(temp_dir) / f"seq_{seq_idx:02d}"
                seq_dir.mkdir(parents=True, exist_ok=True)
                
                # ê° ì¸ìŠ¤í„´ìŠ¤ì˜ DICOM íŒŒì¼ ì €ì¥
                for inst_idx, instance_id in enumerate(seq_instances):
                    dicom_bytes = client.get_instance_file(instance_id)
                    dicom_path = seq_dir / f"slice_{inst_idx:04d}.dcm"
                    with open(dicom_path, 'wb') as f:
                        f.write(dicom_bytes)
                
                # ì²« ë²ˆì§¸ ì‹œí€€ìŠ¤ë¥¼ ì°¸ì¡° DICOMìœ¼ë¡œ ì‚¬ìš©
                if seq_idx == 0:
                    reference_dicom_dir = str(seq_dir)
                
                logger.info(f"âœ… ì‹œí€€ìŠ¤ {seq_idx+1}/4: {len(seq_instances)}ê°œ ìŠ¬ë¼ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")
            
            # 2. MAMA-MIA ëª¨ë¸ ë¡œë“œ (ì‹±ê¸€í†¤ ì‚¬ìš©)
            logger.info("ğŸ”„ MAMA-MIA íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")
            pipeline = get_pipeline()
            
            if pipeline is None:
                return Response({
                    "success": False,
                    "error": "ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }, status=500)
            
            # 3. ì¶”ë¡  ì‹¤í–‰ (DICOM SEG ì¶œë ¥)
            logger.info("ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì¤‘ (ì´ ì‘ì—…ì€ CPUì—ì„œ ì•½ 10~20ì´ˆ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
            
            seg_dicom_path = Path(temp_dir) / "segmentation.dcm"
            
            # MAMA-MIA predictëŠ” image_pathê°€ í´ë”ì´ë©´ ë‚´ë¶€ì˜ ì‹œí€€ìŠ¤ë¥¼ ì°¾ì•„ ì²˜ë¦¬í•¨
            result = pipeline.predict(
                image_path=temp_dir,  # 4ê°œ seq_XX í´ë”ê°€ ìˆëŠ” ë£¨íŠ¸ ì„ì‹œ í´ë”
                output_path=str(seg_dicom_path),
                output_format="dicom"
            )
            
            logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ: tumor_detected={result['tumor_detected']}, volume={result['tumor_volume_voxels']} voxels")
            
            # 4. DICOM SEGë¥¼ Orthancì— ì—…ë¡œë“œ
            logger.info("ğŸ“¤ DICOM SEGë¥¼ Orthancì— ì—…ë¡œë“œ ì¤‘...")
            
            if not seg_dicom_path.exists():
                raise Exception("ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ íŒŒì¼(DICOM SEG)ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
            with open(seg_dicom_path, 'rb') as f:
                seg_dicom_bytes = f.read()
            
            upload_result = client.upload_dicom(seg_dicom_bytes)
            seg_instance_id = upload_result.get('ID')
            
            logger.info(f"âœ… Orthanc ì—…ë¡œë“œ ì™„ë£Œ: {seg_instance_id}")
            
            # 5. ê²°ê³¼ ë°˜í™˜
            return Response({
                'success': True,
                'series_id': series_id,
                'tumor_detected': result['tumor_detected'],
                'tumor_volume_voxels': result['tumor_volume_voxels'],
                'seg_instance_id': seg_instance_id,
                'saved_to_orthanc': True
            })
            
        except Exception as e:
            logger.error(f"âŒ ì‘ì—… ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                if temp_dir and Path(temp_dir).exists():
                    shutil.rmtree(temp_dir)
                    logger.info("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
            except Exception as cleanup_error:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {cleanup_error}")
    
    except Exception as e:
        logger.error(f"âŒ ì‹œë¦¬ì¦ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'series_id': series_id,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)



@api_view(['GET'])
def get_segmentation_frames(request, seg_instance_id):
    """
    DICOM SEG íŒŒì¼ì—ì„œ ëª¨ë“  í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    
    GET /api/mri/segmentation/instances/<seg_instance_id>/frames/
    """
    try:
        logger.info(f"ğŸ” DICOM SEG í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘: {seg_instance_id}")
        
        client = OrthancClient()
        
        # Orthancì—ì„œ DICOM SEG íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        seg_dicom_bytes = client.get_instance_file(seg_instance_id)
        
        # DICOM íŒŒì¼ íŒŒì‹±
        dicom_data = io.BytesIO(seg_dicom_bytes)
        ds = pydicom.dcmread(dicom_data, force=True)
        
        # NumberOfFrames í™•ì¸
        num_frames = getattr(ds, 'NumberOfFrames', 1)
        rows = ds.Rows
        cols = ds.Columns
        
        logger.info(f"ğŸ“Š DICOM SEG ì •ë³´: {num_frames} frames, {rows}Ã—{cols}")
        
        # PixelData ì¶”ì¶œ - pydicom ì‚¬ìš© (1-bit ì••ì¶• ìë™ ì²˜ë¦¬)
        try:
            pixel_array = ds.pixel_array  # pydicomì´ ìë™ìœ¼ë¡œ ì–¸íŒ©
            if pixel_array.ndim == 2:
                pixel_array = pixel_array[np.newaxis, ...]
            logger.info(f"   Pixel array shape: {pixel_array.shape}")
        except:
            # Fallback
            pixel_data = np.frombuffer(ds.PixelData, dtype=np.uint8)
            if ds.BitsAllocated == 1:
                pixel_array = np.unpackbits(pixel_data).reshape(num_frames, rows, cols)
            else:
                pixel_array = pixel_data.reshape(num_frames, rows, cols)
        
        # ê° í”„ë ˆì„ì„ base64ë¡œ ì¸ì½”ë”©
        frames = []
        for i in range(num_frames):
            frame_data = (pixel_array[i] > 0).astype(np.uint8) * 255
            
            # PNGë¡œ ì¸ì½”ë”©
            from PIL import Image
            img = Image.fromarray(frame_data, mode='L')
            buffer = io.BytesIO()
            img.save(buffer, format='PNG')
            mask_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            frames.append({
                "index": i,
                "mask_base64": mask_base64
            })
        
        logger.info(f"âœ… {len(frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")
        
        return Response({
            "success": True,
            "num_frames": len(frames),
            "frames": frames
        })
        
    except Exception as e:
        logger.error(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            "success": False,
            "error": str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# ============================================================
# ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡  ìš”ì²­ API
# ============================================================

# ìš”ì²­ ë””ë ‰í† ë¦¬ (ì—°êµ¬ì‹¤ ì»´í“¨í„°ì™€ ê³µìœ )
REQUEST_DIR = Path(os.getenv('INFERENCE_REQUEST_DIR', '/tmp/mri_inference_requests'))


def _create_local_inference_request(request, series_id, sequence_series_ids):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­ ìƒì„± (ë‚´ë¶€ í•¨ìˆ˜)
    DRF Request ê°ì²´ë¥¼ ì§ì ‘ ì²˜ë¦¬
    """
    try:
        if len(sequence_series_ids) != 4:
            return Response({
                'success': False,
                'error': '4ê°œ ì‹œë¦¬ì¦ˆê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=400)
        
        # ìš”ì²­ ë””ë ‰í† ë¦¬ ìƒì„±
        REQUEST_DIR.mkdir(exist_ok=True, parents=True)
        
        # ìš”ì²­ ë°ì´í„° ìƒì„±
        request_data = {
            'series_ids': sequence_series_ids,
            'main_series_id': series_id,
            'requested_at': timezone.now().isoformat(),
            'status': 'pending',
            'requested_by': getattr(request.user, 'username', 'anonymous') if hasattr(request, 'user') and hasattr(request.user, 'is_authenticated') and request.user.is_authenticated else 'anonymous'
        }
        
        # ìš”ì²­ íŒŒì¼ ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€)
        timestamp = int(timezone.now().timestamp() * 1000)
        request_id = f"{series_id}_{timestamp}"
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ì¶”ë¡  ìš”ì²­ ìƒì„±: {request_file.name}")
        logger.info(f"   - ì‹œë¦¬ì¦ˆ: {sequence_series_ids}")
        logger.info(f"   - ìš”ì²­ì: {request_data['requested_by']}")
        
        # ì›Œì»¤ê°€ ì²˜ë¦¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 5ë¶„)
        import time
        max_wait_time = 300  # 5ë¶„
        check_interval = 2  # 2ì´ˆë§ˆë‹¤ í™•ì¸
        elapsed_time = 0
        
        logger.info("â³ ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘...")
        
        while elapsed_time < max_wait_time:
            time.sleep(check_interval)
            elapsed_time += check_interval
            
            # ìš”ì²­ ìƒíƒœ í™•ì¸
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    current_data = json.load(f)
                
                current_status = current_data.get('status')
                
                if current_status == 'completed':
                    # ì™„ë£Œë¨ - ê²°ê³¼ ë°˜í™˜
                    result = current_data.get('result', {})
                    logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time}ì´ˆ)")
                    
                    return Response({
                        'success': True,
                        'series_id': series_id,
                        'request_id': request_id,
                        'tumor_detected': result.get('tumor_detected'),
                        'tumor_volume_voxels': result.get('tumor_volume_voxels'),
                        'seg_instance_id': result.get('seg_instance_id'),
                        'elapsed_time_seconds': result.get('elapsed_time_seconds'),
                        'saved_to_orthanc': True,
                        'processed_by': 'local_worker'
                    })
                
                elif current_status == 'failed':
                    # ì‹¤íŒ¨
                    result = current_data.get('result', {})
                    error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                    logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {error_msg}")
                    
                    return Response({
                        'success': False,
                        'error': error_msg,
                        'request_id': request_id
                    }, status=500)
                
                elif current_status == 'processing':
                    # ì²˜ë¦¬ ì¤‘
                    logger.info(f"   ì²˜ë¦¬ ì¤‘... ({elapsed_time}ì´ˆ ê²½ê³¼)")
                
            except (FileNotFoundError, json.JSONDecodeError) as e:
                # íŒŒì¼ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨
                pass
            
            # ì§„í–‰ë¥  í‘œì‹œ (30ì´ˆë§ˆë‹¤)
            if elapsed_time % 30 == 0:
                logger.info(f"   ëŒ€ê¸° ì¤‘... ({elapsed_time}/{max_wait_time}ì´ˆ)")
        
        # íƒ€ì„ì•„ì›ƒ
        logger.warning(f"â±ï¸ ìš”ì²­ ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ ({max_wait_time}ì´ˆ ê²½ê³¼)")
        return Response({
            'success': False,
            'error': f'ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (ìµœëŒ€ {max_wait_time}ì´ˆ)',
            'request_id': request_id,
            'message': 'ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.'
        }, status=504)
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ìš”ì²­ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=500)


@api_view(['POST'])
def request_local_inference(request, series_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­
    
    POST /api/mri/segmentation/series/<series_id>/request-local/
    Body: {
        "sequence_series_ids": [series1_id, series2_id, series3_id, series4_id]
    }
    """
    try:
        sequence_series_ids = request.data.get("sequence_series_ids", [])
        
        if len(sequence_series_ids) != 4:
            return Response({
                'success': False,
                'error': '4ê°œ ì‹œë¦¬ì¦ˆê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=400)
        
        # ìš”ì²­ ë””ë ‰í† ë¦¬ ìƒì„±
        REQUEST_DIR.mkdir(exist_ok=True, parents=True)
        
        # ìš”ì²­ ë°ì´í„° ìƒì„±
        request_data = {
            'series_ids': sequence_series_ids,
            'main_series_id': series_id,
            'requested_at': timezone.now().isoformat(),
            'status': 'pending',
            'requested_by': getattr(request.user, 'username', 'anonymous') if hasattr(request, 'user') and hasattr(request.user, 'is_authenticated') and request.user.is_authenticated else 'anonymous'
        }
        
        # ìš”ì²­ íŒŒì¼ ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€)
        timestamp = int(timezone.now().timestamp() * 1000)
        request_id = f"{series_id}_{timestamp}"
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ì¶”ë¡  ìš”ì²­ ìƒì„±: {request_file.name}")
        logger.info(f"   - ì‹œë¦¬ì¦ˆ: {sequence_series_ids}")
        logger.info(f"   - ìš”ì²­ì: {request_data['requested_by']}")
        
        # ì›Œì»¤ê°€ ì²˜ë¦¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 5ë¶„)
        import time
        max_wait_time = 300  # 5ë¶„
        check_interval = 2  # 2ì´ˆë§ˆë‹¤ í™•ì¸
        elapsed_time = 0
        
        logger.info("â³ ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘...")
        
        while elapsed_time < max_wait_time:
            time.sleep(check_interval)
            elapsed_time += check_interval
            
            # ìš”ì²­ ìƒíƒœ í™•ì¸
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    current_data = json.load(f)
                
                current_status = current_data.get('status')
                
                if current_status == 'completed':
                    # ì™„ë£Œë¨ - ê²°ê³¼ ë°˜í™˜
                    result = current_data.get('result', {})
                    logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time}ì´ˆ)")
                    
                    return Response({
                        'success': True,
                        'series_id': series_id,
                        'request_id': request_id,
                        'tumor_detected': result.get('tumor_detected'),
                        'tumor_volume_voxels': result.get('tumor_volume_voxels'),
                        'seg_instance_id': result.get('seg_instance_id'),
                        'elapsed_time_seconds': result.get('elapsed_time_seconds'),
                        'saved_to_orthanc': True,
                        'processed_by': 'local_worker'
                    })
                
                elif current_status == 'failed':
                    # ì‹¤íŒ¨
                    result = current_data.get('result', {})
                    error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                    logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {error_msg}")
                    
                    return Response({
                        'success': False,
                        'error': error_msg,
                        'request_id': request_id
                    }, status=500)
                
                elif current_status == 'processing':
                    # ì²˜ë¦¬ ì¤‘
                    logger.info(f"   ì²˜ë¦¬ ì¤‘... ({elapsed_time}ì´ˆ ê²½ê³¼)")
                
            except (FileNotFoundError, json.JSONDecodeError) as e:
                # íŒŒì¼ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨
                pass
            
            # ì§„í–‰ë¥  í‘œì‹œ (30ì´ˆë§ˆë‹¤)
            if elapsed_time % 30 == 0:
                logger.info(f"   ëŒ€ê¸° ì¤‘... ({elapsed_time}/{max_wait_time}ì´ˆ)")
        
        # íƒ€ì„ì•„ì›ƒ
        logger.warning(f"â±ï¸ íƒ€ì„ì•„ì›ƒ: ì›Œì»¤ê°€ {max_wait_time}ì´ˆ ë‚´ì— ì‘ë‹µí•˜ì§€ ì•ŠìŒ")
        
        return Response({
            'success': False,
            'error': f'ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ê°€ {max_wait_time}ì´ˆ ë‚´ì— ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.',
            'request_id': request_id,
            'status': 'timeout',
            'note': 'ìš”ì²­ì€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— /api/mri/segmentation/status/{request_id}/ ì—ì„œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.'
        }, status=504)
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ìš”ì²­ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def check_inference_status(request, request_id):
    """
    ì¶”ë¡  ìš”ì²­ ìƒíƒœ í™•ì¸
    
    GET /api/mri/segmentation/status/<request_id>/
    """
    try:
        # ìš”ì²­ íŒŒì¼ ì°¾ê¸°
        request_files = list(REQUEST_DIR.glob(f"{request_id}.json"))
        
        if not request_files:
            return Response({
                'success': False,
                'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'request_id': request_id
            }, status=404)
        
        # ìš”ì²­ ë°ì´í„° ì½ê¸°
        with open(request_files[0], 'r', encoding='utf-8') as f:
            request_data = json.load(f)
        
        # ìƒíƒœë³„ ë©”ì‹œì§€
        status_messages = {
            'pending': 'ëŒ€ê¸° ì¤‘: ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.',
            'processing': 'ì²˜ë¦¬ ì¤‘: ì¶”ë¡ ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.',
            'completed': 'ì™„ë£Œ: ì¶”ë¡ ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'failed': 'ì‹¤íŒ¨: ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
        }
        
        current_status = request_data.get('status', 'unknown')
        
        response_data = {
            'success': True,
            'request_id': request_id,
            'status': current_status,
            'message': status_messages.get(current_status, 'ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ'),
            'requested_at': request_data.get('requested_at'),
            'started_at': request_data.get('started_at'),
            'completed_at': request_data.get('completed_at'),
            'series_ids': request_data.get('series_ids'),
            'requested_by': request_data.get('requested_by')
        }
        
        # ê²°ê³¼ê°€ ìˆìœ¼ë©´ í¬í•¨
        if 'result' in request_data:
            result = request_data['result']
            response_data['result'] = {
                'success': result.get('success'),
                'seg_instance_id': result.get('seg_instance_id'),
                'tumor_detected': result.get('tumor_detected'),
                'tumor_volume_voxels': result.get('tumor_volume_voxels'),
                'elapsed_time_seconds': result.get('elapsed_time_seconds'),
                'error': result.get('error')
            }
        
        return Response(response_data)
        
    except Exception as e:
        logger.error(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def list_inference_requests(request):
    """
    ì¶”ë¡  ìš”ì²­ ëª©ë¡ ì¡°íšŒ
    
    GET /api/mri/segmentation/requests/
    Query params:
        - status: pending, processing, completed, failed
        - limit: ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸: 50)
    """
    try:
        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
        filter_status = request.GET.get('status')
        limit = int(request.GET.get('limit', 50))
        
        # ìš”ì²­ íŒŒì¼ ì°¾ê¸°
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime, reverse=True)
        
        requests_list = []
        for request_file in request_files[:limit]:
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    request_data = json.load(f)
                
                # ìƒíƒœ í•„í„°ë§
                if filter_status and request_data.get('status') != filter_status:
                    continue
                
                requests_list.append({
                    'request_id': request_file.stem,
                    'status': request_data.get('status'),
                    'requested_at': request_data.get('requested_at'),
                    'started_at': request_data.get('started_at'),
                    'completed_at': request_data.get('completed_at'),
                    'series_ids': request_data.get('series_ids'),
                    'requested_by': request_data.get('requested_by'),
                    'has_result': 'result' in request_data
                })
            except Exception as e:
                logger.warning(f"âš ï¸ ìš”ì²­ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {request_file.name} - {e}")
                continue
        
        return Response({
            'success': True,
            'count': len(requests_list),
            'requests': requests_list,
            'filter': {
                'status': filter_status,
                'limit': limit
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ ìš”ì²­ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_pending_requests(request):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ìš©: ëŒ€ê¸° ì¤‘ì¸ ì¶”ë¡  ìš”ì²­ ì¡°íšŒ (HTTP API ë°©ì‹)
    
    GET /api/mri/segmentation/pending-requests/
    
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ê°€ ì´ APIë¥¼ í´ë§í•˜ì—¬ ìš”ì²­ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ê³µìœ  ë””ë ‰í† ë¦¬ë‚˜ ë‚´ë¶€ IPê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤!
    """
    try:
        # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ë§Œ ì°¾ê¸°
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime)
        
        pending_requests = []
        for request_file in request_files:
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    request_data = json.load(f)
                
                # pending ìƒíƒœë§Œ ë°˜í™˜
                if request_data.get('status') == 'pending':
                    pending_requests.append({
                        'request_id': request_file.stem,
                        'series_ids': request_data.get('series_ids'),
                        'main_series_id': request_data.get('main_series_id'),
                        'requested_at': request_data.get('requested_at'),
                        'requested_by': request_data.get('requested_by')
                    })
            except Exception as e:
                logger.warning(f"âš ï¸ ìš”ì²­ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {request_file.name} - {e}")
                continue
        
        return Response({
            'success': True,
            'count': len(pending_requests),
            'requests': pending_requests
        })
        
    except Exception as e:
        logger.error(f"âŒ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
def get_pending_inference(request):
    """
    ì¡°ì›ë‹˜ ì›Œì»¤ í˜¸í™˜ìš©: ëŒ€ê¸° ì¤‘ì¸ ì¶”ë¡  ìš”ì²­ ì¡°íšŒ (ë‹¨ì¼ ìš”ì²­ ë°˜í™˜)
    
    GET /api/inference/pending
    
    ì¡°ì›ë‹˜ì˜ ì›Œì»¤ê°€ ì‚¬ìš©í•˜ëŠ” í˜•ì‹:
    - ìš”ì²­ì´ ìˆìœ¼ë©´: {"id": request_id, "series_id": "...", "series_ids": [...]}
    - ìš”ì²­ì´ ì—†ìœ¼ë©´: {"id": null}
    """
    try:
        # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ë§Œ ì°¾ê¸° (ê°€ì¥ ì˜¤ë˜ëœ ê²ƒë¶€í„°)
        request_files = sorted(REQUEST_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime)
        
        for request_file in request_files:
            try:
                with open(request_file, 'r', encoding='utf-8') as f:
                    request_data = json.load(f)
                
                # pending ìƒíƒœë§Œ ë°˜í™˜
                if request_data.get('status') == 'pending':
                    # ìƒíƒœë¥¼ processingìœ¼ë¡œ ë³€ê²½
                    request_data['status'] = 'processing'
                    request_data['started_at'] = timezone.now().isoformat()
                    
                    with open(request_file, 'w', encoding='utf-8') as f:
                        json.dump(request_data, f, indent=2, ensure_ascii=False)
                    
                    logger.info(f"âœ… ìš”ì²­ í• ë‹¹: {request_file.stem}")
                    
                    # ì¡°ì›ë‹˜ ì›Œì»¤ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
                    return Response({
                        'id': request_file.stem,
                        'series_id': request_data.get('main_series_id'),
                        'series_ids': request_data.get('series_ids', [])
                    })
            except Exception as e:
                logger.warning(f"âš ï¸ ìš”ì²­ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {request_file.name} - {e}")
                continue
        
        # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì—†ìŒ
        return Response({'id': None})
        
    except Exception as e:
        logger.error(f"âŒ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'id': None,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST'])
def complete_inference(request, request_id):
    """
    ì¡°ì›ë‹˜ ì›Œì»¤ í˜¸í™˜ìš©: ì¶”ë¡  ì™„ë£Œ ê²°ê³¼ ì—…ë¡œë“œ
    
    POST /api/inference/{request_id}/complete
    Body: {
        "success": true,
        "seg_instance_id": "...",
        "tumor_detected": true,
        "tumor_volume_voxels": 1234,
        "inference_time_seconds": 45.2
    }
    """
    try:
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        if not request_file.exists():
            return Response({
                'success': False,
                'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=404)
        
        with open(request_file, 'r', encoding='utf-8') as f:
            request_data = json.load(f)
        
        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        request_data['status'] = 'completed' if request.data.get('success') else 'failed'
        request_data['completed_at'] = timezone.now().isoformat()
        request_data['result'] = {
            'success': request.data.get('success'),
            'seg_instance_id': request.data.get('seg_instance_id'),
            'tumor_detected': request.data.get('tumor_detected'),
            'tumor_volume_voxels': request.data.get('tumor_volume_voxels'),
            'elapsed_time_seconds': request.data.get('inference_time_seconds') or request.data.get('elapsed_time_seconds'),
            'error': request.data.get('error')
        }
        
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ ê²°ê³¼ ì—…ë¡œë“œ: {request_id}")
        
        return Response({
            'success': True
        })
        
    except Exception as e:
        logger.error(f"âŒ ê²°ê³¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST'])
def complete_inference_request(request, request_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ìš©: ì¶”ë¡  ì™„ë£Œ ê²°ê³¼ ì—…ë¡œë“œ (HTTP API ë°©ì‹)
    
    POST /api/mri/segmentation/complete-request/<request_id>/
    Body: {
        "success": true,
        "seg_instance_id": "...",
        "tumor_detected": true,
        "tumor_volume_voxels": 12345,
        "elapsed_time_seconds": 30.5,
        "error": null
    }
    """
    try:
        # ìš”ì²­ íŒŒì¼ ì°¾ê¸°
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        if not request_file.exists():
            return Response({
                'success': False,
                'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=404)
        
        # ìš”ì²­ ë°ì´í„° ì½ê¸°
        with open(request_file, 'r', encoding='utf-8') as f:
            request_data = json.load(f)
        
        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        request_data['status'] = 'completed' if request.data.get('success') else 'failed'
        request_data['completed_at'] = timezone.now().isoformat()
        request_data['result'] = {
            'success': request.data.get('success'),
            'seg_instance_id': request.data.get('seg_instance_id'),
            'tumor_detected': request.data.get('tumor_detected'),
            'tumor_volume_voxels': request.data.get('tumor_volume_voxels'),
            'elapsed_time_seconds': request.data.get('elapsed_time_seconds'),
            'error': request.data.get('error')
        }
        
        # íŒŒì¼ ì €ì¥
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ ê²°ê³¼ ì—…ë¡œë“œ: {request_id}")
        
        return Response({
            'success': True,
            'message': 'ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'request_id': request_id
        })
        
    except Exception as e:
        logger.error(f"âŒ ê²°ê³¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['POST'])
def update_request_status(request, request_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„° ì›Œì»¤ìš©: ìš”ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸ (processing ë“±)
    
    POST /api/mri/segmentation/update-status/<request_id>/
    Body: {
        "status": "processing",
        "started_at": "2024-01-01T00:00:00"
    }
    """
    try:
        request_file = REQUEST_DIR / f"{request_id}.json"
        
        if not request_file.exists():
            return Response({
                'success': False,
                'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }, status=404)
        
        with open(request_file, 'r', encoding='utf-8') as f:
            request_data = json.load(f)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        if 'status' in request.data:
            request_data['status'] = request.data['status']
        if 'started_at' in request.data:
            request_data['started_at'] = request.data['started_at']
        
        with open(request_file, 'w', encoding='utf-8') as f:
            json.dump(request_data, f, indent=2, ensure_ascii=False)
        
        return Response({
            'success': True,
            'request_id': request_id,
            'status': request_data.get('status')
        })
        
    except Exception as e:
        logger.error(f"âŒ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return Response({
            'success': False,
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

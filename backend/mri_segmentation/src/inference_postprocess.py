"""
Post-processing Module for Phase 1 Segmentation Inference
Converts model output (probabilities) to final segmentation mask.
"""
import torch
import numpy as np
import logging
import sys
from monai.transforms import (
    Compose, Invertd, SaveImaged, AsDiscreted,
    KeepLargestConnectedComponentd, FillHolesd
)
from scipy import ndimage
import config

# Logger ì„¤ì • (Django/Gunicornì—ì„œ journalì— ê¸°ë¡ë˜ë„ë¡)
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler = logging.StreamHandler(sys.stderr)
    handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
    logger.addHandler(handler)
    logger.setLevel(logging.DEBUG)


def get_postprocess_transforms(threshold=0.5, apply_morphology=True):
    """
    Returns post-processing transform pipeline.
    
    Args:
        threshold: Probability threshold for binarization (default: 0.5)
        apply_morphology: Whether to apply morphological cleaning
    
    Returns:
        Compose: MONAI transform pipeline
    """
    transforms_list = [
        AsDiscreted(keys=["pred"], threshold=threshold),
    ]
    
    if apply_morphology:
        transforms_list.extend([
            KeepLargestConnectedComponentd(keys=["pred"], applied_labels=[1]),
            FillHolesd(keys=["pred"], applied_labels=[1])
        ])
    
    return Compose(transforms_list)


def postprocess_prediction(
    prediction, 
    original_meta_dict=None,
    preprocessed_data=None, # For Invertd
    threshold=0.5,
    apply_morphology=True,
    restore_original_spacing=True
):
    """
    Post-process model prediction to final segmentation mask.
    
    Args:
        prediction: Model output tensor [1, 1, H, W, D] (probabilities after sigmoid)
        original_meta_dict: Metadata from preprocessing for coordinate restoration
        threshold: Binarization threshold
        apply_morphology: Whether to clean up small components
        restore_original_spacing: Whether to resample back to original patient spacing
    
    Returns:
        np.ndarray: Final segmentation mask in original coordinate space
    """
    # Remove batch dimension
    pred = prediction.squeeze(0).squeeze(0)  # [H, W, D]
    
    # Apply threshold
    binary_mask = (pred > threshold).cpu().numpy().astype(np.uint8)
    
    # Morphological cleaning
    if apply_morphology:
        # Keep largest connected component
        labeled, num_features = ndimage.label(binary_mask)
        if num_features > 0:
            sizes = ndimage.sum(binary_mask, labeled, range(1, num_features + 1))
            largest_component = np.argmax(sizes) + 1
            binary_mask = (labeled == largest_component).astype(np.uint8)
        
        # Fill holes
        binary_mask = ndimage.binary_fill_holes(binary_mask).astype(np.uint8)
    
    # Restore to original spacing/orientation if requested
    if restore_original_spacing and preprocessed_data is not None:
        from monai.transforms import Invertd, EnsureChannelFirstd, Compose
        from monai.data import MetaTensor
        
        # Prepare data for inversion
        # We need the original MetaTensor that holds transform information
        input_image = preprocessed_data.get("image")
        
        # ğŸ” ë””ë²„ê¹…: ì¡°ì›ë‹˜ ë¶„ì„ í™•ì¸
        logger.debug("[DEBUG] Invertd ë³µì› ì‹œì‘")
        logger.debug(f"  - binary_mask shape (ì „ì²˜ë¦¬ í›„): {binary_mask.shape}")
        logger.debug(f"  - input_image type: {type(input_image)}")
        logger.debug(f"  - input_image is MetaTensor: {isinstance(input_image, MetaTensor)}")
        if isinstance(input_image, MetaTensor):
            logger.debug(f"  - input_image.affine exists: {hasattr(input_image, 'affine')}")
            if hasattr(input_image, 'affine'):
                logger.debug(f"  - input_image.affine shape: {input_image.affine.shape if input_image.affine is not None else None}")
            if hasattr(input_image, 'meta'):
                logger.debug(f"  - input_image.meta keys: {list(input_image.meta.keys())[:10] if hasattr(input_image, 'meta') else None}")
        logger.debug(f"  - original_meta_dict: {original_meta_dict is not None}")
        if original_meta_dict:
            logger.debug(f"  - original_meta_dict keys: {list(original_meta_dict.keys())[:10]}")
            logger.debug(f"  - original_meta_dict spacing: {original_meta_dict.get('spacing', 'NOT FOUND')}")
            logger.debug(f"  - original_meta_dict pixdim: {original_meta_dict.get('pixdim', 'NOT FOUND')}")
            logger.debug(f"  - original_meta_dict spatial_shape: {original_meta_dict.get('spatial_shape', 'NOT FOUND')}")
        
        # Create a dictionary for Invertd
        # Note: binary_mask is numpy [H, W, D], we need [C, H, W, D] for MONAI
        # And convert to Tensor (Invertd expects Tensor/MetaTensor)
        # IMPORTANT: We must wrap it as MetaTensor with the current affine (1.5mm)
        # so Invertd knows the starting point.
        mask_tensor = torch.from_numpy(binary_mask).unsqueeze(0).float()
        
        # If input_image has batch dim, remove it matching pipeline logic
        if len(input_image.shape) == 5: # [B, C, H, W, D]
             input_image = input_image.squeeze(0)
             
        # Create MetaTensor with affine from input_image
        if isinstance(input_image, MetaTensor):
            mask_tensor = MetaTensor(mask_tensor, affine=input_image.affine)
            logger.debug(f"  - mask_tensor created as MetaTensor with affine")
        else:
            logger.warning(f"  - âš ï¸ WARNING: input_image is NOT MetaTensor! Type: {type(input_image)}")
        
        data = dict(preprocessed_data)
        data["image"] = input_image
        data["pred"] = mask_tensor
        
        # Import transforms pipeline
        from inference_preprocess import get_inference_transforms
        transforms = get_inference_transforms()
        
        # Define inverter
        inverter = Invertd(
            keys=["pred"],
            transform=transforms,
            orig_keys=["image"],
            nearest_interp=True,
            to_tensor=True
        )
        
        # Apply inversion
        # Invertd expects a LIST of dicts (batch) or a single dict?
        # MONAI transforms usually handle single dict.
        try:
            result = inverter(data)
            restored = result["pred"]
            
            # restored is [C, H, W, D]
            binary_mask_after_invertd = restored.squeeze(0).numpy().astype(np.uint8)
            logger.debug(f"  - Invertd ì‹¤í–‰ ì™„ë£Œ (ì˜ˆì™¸ ì—†ìŒ)")
            logger.debug(f"  - binary_mask shape (Invertd í›„): {binary_mask_after_invertd.shape}")
            
            # ğŸ” ê²€ì¦: Invertdê°€ ì œëŒ€ë¡œ ë³µì›í–ˆëŠ”ì§€ í™•ì¸
            # ì›ë³¸ í¬ê¸°ì™€ ë¹„êµ (original_meta_dictì˜ spatial_shape í™•ì¸)
            if original_meta_dict and 'spatial_shape' in original_meta_dict:
                original_shape = original_meta_dict['spatial_shape']
                restored_shape = binary_mask_after_invertd.shape
                logger.debug(f"  - ì›ë³¸ í¬ê¸° (meta_dict): {original_shape}")
                logger.debug(f"  - ë³µì› í›„ í¬ê¸°: {restored_shape}")
                
                if restored_shape != tuple(original_shape):
                    logger.warning(f"  - âš ï¸ WARNING: Invertdê°€ ì œëŒ€ë¡œ ë³µì›í•˜ì§€ ëª»í•¨!")
                    logger.warning(f"  - ì°¨ì› ë¶ˆì¼ì¹˜ ê°ì§€ â†’ Fallback ì‚¬ìš©")
                    # Fallback ì‚¬ìš©
                    binary_mask = binary_mask  # ì›ë˜ í¬ê¸° ìœ ì§€
                    use_fallback = True
                else:
                    logger.debug(f"  - âœ… Invertd ë³µì› ì„±ê³µ!")
                    binary_mask = binary_mask_after_invertd
                    use_fallback = False
            else:
                logger.warning(f"  - âš ï¸ WARNING: original_meta_dictì— spatial_shape ì—†ìŒ")
                logger.warning(f"  - Invertd ê²°ê³¼ ì‚¬ìš© (ê²€ì¦ ë¶ˆê°€)")
                binary_mask = binary_mask_after_invertd
                use_fallback = False
            
            # Fallbackì´ í•„ìš”í•œ ê²½ìš°
            if use_fallback:
                logger.info(f"  - Fallbackìœ¼ë¡œ ìˆ˜ë™ ë³µì› ì‹œë„...")
                # ì¡°ì›ë‹˜ ì œì•ˆ: spatial_shapeë¥¼ ì‚¬ìš©í•´ì„œ ì •í™•í•œ í¬ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§
                if original_meta_dict and 'spatial_shape' in original_meta_dict:
                    target_shape = original_meta_dict['spatial_shape']
                    current_shape = binary_mask.shape
                    
                    # í˜„ì¬ í¬ê¸° â†’ ëª©í‘œ í¬ê¸° ê³„ì‚°
                    scale_factors = [
                        target_shape[0] / current_shape[0],
                        target_shape[1] / current_shape[1],
                        target_shape[2] / current_shape[2]
                    ]
                    
                    logger.debug(f"  - í˜„ì¬ í¬ê¸°: {current_shape}")
                    logger.debug(f"  - ëª©í‘œ í¬ê¸°: {target_shape}")
                    logger.debug(f"  - Scale factors: {scale_factors}")
                    
                    # scipy.ndimage.zoomì„ ì‚¬ìš©í•´ì„œ ì •í™•í•œ í¬ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§ (order=0: nearest neighbor)
                    from scipy.ndimage import zoom
                    binary_mask = zoom(binary_mask, scale_factors, order=0).astype(np.uint8)
                    logger.info(f"  - âœ… Fallback ë³µì› ì„±ê³µ: {binary_mask.shape}")
                else:
                    logger.error(f"  - âŒ spatial_shape ì—†ìŒ - í¬ê¸° ë³µì› ë¶ˆê°€")
        except Exception as e:
            import traceback
            error_msg = str(e)
            error_traceback = traceback.format_exc()
            logger.error(f"  - âŒ Invertd ì˜ˆì™¸ ë°œìƒ: {error_msg}")
            logger.debug(f"  - ì˜ˆì™¸ ìƒì„¸:\n{error_traceback}")
            logger.info(f"  - Fallbackìœ¼ë¡œ ìˆ˜ë™ ë³µì› ì‹œë„...")
            # ì¡°ì›ë‹˜ ì œì•ˆ: spatial_shapeë¥¼ ì‚¬ìš©í•´ì„œ ì •í™•í•œ í¬ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§
            if original_meta_dict is not None and 'spatial_shape' in original_meta_dict:
                target_shape = original_meta_dict['spatial_shape']
                current_shape = binary_mask.shape
                
                # í˜„ì¬ í¬ê¸° â†’ ëª©í‘œ í¬ê¸° ê³„ì‚°
                scale_factors = [
                    target_shape[0] / current_shape[0],
                    target_shape[1] / current_shape[1],
                    target_shape[2] / current_shape[2]
                ]
                
                logger.debug(f"  - í˜„ì¬ í¬ê¸°: {current_shape}")
                logger.debug(f"  - ëª©í‘œ í¬ê¸°: {target_shape}")
                logger.debug(f"  - Scale factors: {scale_factors}")
                
                # scipy.ndimage.zoomì„ ì‚¬ìš©í•´ì„œ ì •í™•í•œ í¬ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§ (order=0: nearest neighbor)
                from scipy.ndimage import zoom
                binary_mask = zoom(binary_mask, scale_factors, order=0).astype(np.uint8)
                logger.info(f"  - âœ… Fallback ë³µì› ì„±ê³µ: {binary_mask.shape}")
            else:
                logger.error(f"  - âŒ spatial_shape ì—†ìŒ - í¬ê¸° ë³µì› ë¶ˆê°€")

    elif restore_original_spacing and original_meta_dict is not None:
        # Legacy fallback
        from monai.transforms import Spacing
        # ì¡°ì›ë‹˜ ì¶”ì²œ: pixdim ìš°ì„ , ì—†ìœ¼ë©´ spacing ì‚¬ìš©
        original_spacing = None
        original_spacing = original_meta_dict.get('pixdim', None)
        if original_spacing is None:
            original_spacing = original_meta_dict.get('spacing', None)
        
        if original_spacing is not None:
            # spacing ê°’ ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸/íŠœí”Œ/í…ì„œ ë“± ë‹¤ì–‘í•œ í˜•íƒœ ì²˜ë¦¬)
            if hasattr(original_spacing, 'tolist'):
                spacing_values = original_spacing.tolist()
            elif hasattr(original_spacing, '__iter__') and not isinstance(original_spacing, str):
                spacing_values = list(original_spacing)
            else:
                spacing_values = [original_spacing]
            
            # ì•ì˜ 1 ì œê±° (pixdim í˜•íƒœì¸ ê²½ìš°: [1, x, y, z])
            if len(spacing_values) == 4:
                spacing_values = spacing_values[1:]
            
            spacing_transform = Spacing(pixdim=spacing_values, mode="nearest")
            mask_tensor = torch.from_numpy(binary_mask).unsqueeze(0).float()
            restored = spacing_transform(mask_tensor)
            binary_mask = restored.squeeze(0).numpy().astype(np.uint8)
    
    return binary_mask


def save_segmentation(mask, output_path, reference_meta_dict=None):
    """
    Save segmentation mask as NIfTI file.
    
    Args:
        mask: Binary segmentation mask (numpy array)
        output_path: Path to save the output file
        reference_meta_dict: Optional metadata to preserve affine/header info
    """
    import nibabel as nib
    
    if reference_meta_dict is not None and 'affine' in reference_meta_dict:
        affine = reference_meta_dict['affine']
    else:
        affine = np.eye(4)
    
    nifti_img = nib.Nifti1Image(mask, affine)
    nib.save(nifti_img, output_path)
    print(f"Segmentation saved to: {output_path}")


if __name__ == "__main__":
    # Example usage
    print("Post-processing module loaded successfully.")

def save_as_dicom_seg(mask, output_path, reference_dicom_path, prediction_label="Tumor"):
    """
    Save segmentation as DICOM SEG object using highdicom.
    
    Args:
        mask: 3D numpy array (binary mask) [H, W, D]
        output_path: Path to save .dcm file
        reference_dicom_path: Path to folder containing original DICOM series
        prediction_label: Label name
    """
    import pydicom
    import numpy as np
    from highdicom.seg import (
        Segmentation,
        SegmentDescription,
        SegmentAlgorithmTypeValues
    )
    from highdicom.content import (
        PixelMeasuresSequence,
        PlanePositionSequence,
        PlaneOrientationSequence,
        AlgorithmIdentificationSequence
    )
    from highdicom import UID
    from pydicom.sr.codedict import codes
    from pathlib import Path
    
    # 1. Read original DICOM series to get template
    dicom_files = sorted(Path(reference_dicom_path).glob("*.dcm"))
    
    # If no DICOM files in root, check subdirectories (e.g., seq_0, seq_1, ...)
    if not dicom_files:
        subdirs = sorted([d for d in Path(reference_dicom_path).iterdir() if d.is_dir()])
        if subdirs:
            # Use first sequence folder as reference (all sequences share same geometry)
            dicom_files = sorted(subdirs[0].glob("*.dcm"))
            if not dicom_files:
                raise FileNotFoundError(f"No .dcm files found in {reference_dicom_path} or subdirectories")
        else:
            raise FileNotFoundError(f"No .dcm files found in {reference_dicom_path}")
        
    source_images = [pydicom.dcmread(str(f)) for f in dicom_files]
    
    # Sort by ImagePositionPatient (spatial Z-axis) to match MONAI's volume order
    # MONAI LoadImage sorts files spatially. InstanceNumber might be inconsistent or reversed.
    def get_z_position(ds):
        # Calculate projection onto slice normal to robustly handle tilted acquisitions
        # ImageOrientationPatient ë° ImagePositionPatient í™•ì¸ (ê¸°ì¡´ DICOMì— ì—†ì„ ìˆ˜ ìˆìŒ)
        if not hasattr(ds, 'ImageOrientationPatient') or not ds.ImageOrientationPatient:
            # ê¸°ë³¸ê°’: RAS ì¢Œí‘œê³„
            iop = [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
            logger.warning(f"  âš ï¸ ImageOrientationPatientê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {iop}")
        else:
            iop = ds.ImageOrientationPatient
        
        # Row cosine (x) and Column cosine (y)
        row_cos = np.array(iop[:3])
        col_cos = np.array(iop[3:])
        # Slice normal (z) = cross product
        slice_norm = np.cross(row_cos, col_cos)
        
        # ImagePositionPatient í™•ì¸
        if not hasattr(ds, 'ImagePositionPatient') or not ds.ImagePositionPatient:
            # ê¸°ë³¸ê°’: SliceLocation ë˜ëŠ” InstanceNumber ì‚¬ìš©
            if hasattr(ds, 'SliceLocation') and ds.SliceLocation:
                pos = np.array([0.0, 0.0, float(ds.SliceLocation)])
            elif hasattr(ds, 'InstanceNumber') and ds.InstanceNumber:
                pos = np.array([0.0, 0.0, float(ds.InstanceNumber)])
            else:
                pos = np.array([0.0, 0.0, 0.0])
            logger.warning(f"  âš ï¸ ImagePositionPatientê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {pos}")
        else:
            pos = np.array(ds.ImagePositionPatient)
        
        # Projection
        return np.dot(pos, slice_norm)

    source_images.sort(key=get_z_position)
    
    # ì†ŒìŠ¤ ì´ë¯¸ì§€ì— FrameOfReferenceUIDê°€ ìˆëŠ”ì§€ í™•ì¸ ë° ì¶”ê°€ (highdicom.Segmentation í•„ìˆ˜)
    logger.info(f"ğŸ” ì†ŒìŠ¤ ì´ë¯¸ì§€ FrameOfReferenceUID í™•ì¸ ì¤‘...")
    frame_of_reference_uid = None
    
    # ë¨¼ì € ê¸°ì¡´ FrameOfReferenceUIDê°€ ìˆëŠ”ì§€ í™•ì¸
    for i, ds in enumerate(source_images):
        if hasattr(ds, 'FrameOfReferenceUID'):
            uid_value = ds.FrameOfReferenceUID
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ Noneì´ ì•„ë‹Œ ìœ íš¨í•œ UID í™•ì¸
            if uid_value and str(uid_value).strip():
                frame_of_reference_uid = str(uid_value).strip()
                logger.info(f"  - ê¸°ì¡´ FrameOfReferenceUID ë°œê²¬ (ìŠ¬ë¼ì´ìŠ¤ {i+1}): {frame_of_reference_uid}")
                break
            else:
                logger.debug(f"  - ìŠ¬ë¼ì´ìŠ¤ {i+1}: FrameOfReferenceUIDê°€ ë¹ˆ ê°’ì…ë‹ˆë‹¤")
        else:
            logger.debug(f"  - ìŠ¬ë¼ì´ìŠ¤ {i+1}: FrameOfReferenceUID ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤")
    
    # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if not frame_of_reference_uid:
        from pydicom.uid import generate_uid
        frame_of_reference_uid = generate_uid()
        logger.warning(f"  - âš ï¸ FrameOfReferenceUIDê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±: {frame_of_reference_uid}")
    
    # ëª¨ë“  ì†ŒìŠ¤ ì´ë¯¸ì§€ì— FrameOfReferenceUID ì¶”ê°€/ì—…ë°ì´íŠ¸ (ê°•ì œ ì„¤ì •)
    for i, ds in enumerate(source_images):
        ds.FrameOfReferenceUID = frame_of_reference_uid
        # ì‹¤ì œë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not hasattr(ds, 'FrameOfReferenceUID') or not ds.FrameOfReferenceUID:
            logger.error(f"  - âŒ ìŠ¬ë¼ì´ìŠ¤ {i+1}ì— FrameOfReferenceUID ì„¤ì • ì‹¤íŒ¨!")
            raise ValueError(f"Failed to set FrameOfReferenceUID on slice {i+1}")
    
    # ìµœì¢… ê²€ì¦
    logger.info(f"  - âœ… ëª¨ë“  ì†ŒìŠ¤ ì´ë¯¸ì§€ì— FrameOfReferenceUID ì„¤ì • ì™„ë£Œ: {frame_of_reference_uid}")
    logger.info(f"  - ê²€ì¦: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ FrameOfReferenceUID = {source_images[0].FrameOfReferenceUID}")
    logger.info(f"  - ê²€ì¦: ë§ˆì§€ë§‰ ì´ë¯¸ì§€ FrameOfReferenceUID = {source_images[-1].FrameOfReferenceUID}")
    
    # ì†ŒìŠ¤ ì´ë¯¸ì§€ì— í•„ìˆ˜ Study ë©”íƒ€ë°ì´í„° í™•ì¸ ë° ì¶”ê°€ (highdicom.Segmentationì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìŒ)
    logger.info(f"ğŸ” ì†ŒìŠ¤ ì´ë¯¸ì§€ Study ë©”íƒ€ë°ì´í„° í™•ì¸ ì¤‘...")
    for i, ds in enumerate(source_images):
        # AccessionNumber í™•ì¸ ë° ì¶”ê°€
        if not hasattr(ds, 'AccessionNumber') or not ds.AccessionNumber:
            # StudyIDë¥¼ ê¸°ë°˜ìœ¼ë¡œ AccessionNumber ìƒì„±
            if hasattr(ds, 'StudyID') and ds.StudyID:
                ds.AccessionNumber = str(ds.StudyID)
            else:
                ds.AccessionNumber = "UNKNOWN"
            if i == 0:  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ë¡œê·¸
                logger.info(f"  - AccessionNumber ì¶”ê°€: {ds.AccessionNumber}")
        
        # ReferringPhysicianName í™•ì¸ ë° ì¶”ê°€ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
        if not hasattr(ds, 'ReferringPhysicianName'):
            ds.ReferringPhysicianName = ""
    
    logger.info(f"  - âœ… ëª¨ë“  ì†ŒìŠ¤ ì´ë¯¸ì§€ Study ë©”íƒ€ë°ì´í„° ì„¤ì • ì™„ë£Œ")
    
    # 2. Prepare Mask Data
    # CRITICAL: highdicom.Segmentation expects:
    #   - pixel_array shape: (Frames, Rows, Columns) where Frames = len(source_images)
    #   - Each frame corresponds 1:1 with source_images[i]
    
    # Input mask is [H, W, D] from MONAI (after Invertd restoration)
    # We need [D, H, W] for highdicom (Frames=D, Rows=H, Cols=W)
    
    logger.info(f"ğŸ“¦ DICOM SEG ìƒì„± ì‹œì‘")
    logger.info(f"  - Input mask shape: {mask.shape}")
    logger.info(f"  - Source images count: {len(source_images)}")
    
    # Transpose to [D, H, W]
    mask_frames = mask.transpose(2, 0, 1)
    logger.info(f"  - Transposed mask shape: {mask_frames.shape}")
    logger.info(f"  - mask_frames dtype: {mask_frames.dtype}")
    logger.info(f"  - mask_frames min/max: {mask_frames.min()}/{mask_frames.max()}")
    
    # Verify dimensions match
    # Invertdê°€ ì •ìƒ ì‘ë™í–ˆë‹¤ë©´ ì°¨ì›ì´ ì¼ì¹˜í•´ì•¼ í•¨
    # ë¶ˆì¼ì¹˜ ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ë¬¸ì œ ì•Œë¦¼ (ì•ˆì „ì¥ì¹˜)
    if mask_frames.shape[0] != len(source_images):
        logger.error(f"  - âŒ ì°¨ì› ë¶ˆì¼ì¹˜ ê°ì§€!")
        logger.error(f"    mask_frames.shape[0] = {mask_frames.shape[0]}")
        logger.error(f"    len(source_images) = {len(source_images)}")
        raise ValueError(
            f"Dimension mismatch: mask has {mask_frames.shape[0]} frames "
            f"but source_images has {len(source_images)} images. "
            f"Original mask shape: {mask.shape}. "
            f"This indicates Invertd failed to restore original spacing. "
            f"Please check restore_original_spacing=True and Invertd transform."
        )
    
    logger.info(f"  - âœ… ì°¨ì› ì¼ì¹˜ í™•ì¸: {mask_frames.shape[0]} frames = {len(source_images)} images")
    
    # Ensure boolean type for BINARY segmentation
    mask_frames = mask_frames > 0
    non_empty_frames = np.sum(np.any(mask_frames, axis=(1,2)))
    logger.debug(f"  - Non-empty frames: {non_empty_frames}/{len(source_images)}")
    
    # 3. Create Segment Description
    segment_description = SegmentDescription(
        segment_number=1,
        segment_label=prediction_label,
        segmented_property_category=codes.SCT.Tissue,
        segmented_property_type=codes.SCT.Neoplasm,
        algorithm_type=SegmentAlgorithmTypeValues.AUTOMATIC,
        algorithm_identification=AlgorithmIdentificationSequence(
            name="MAMA-MIA-AI",
            version="1.0",
            family=codes.DCM.ArtificialIntelligence
        )
    )
    
    # 4. Create Segmentation Object
    logger.info(f"ğŸ”¨ highdicom.Segmentation ê°ì²´ ìƒì„± ì¤‘...")
    logger.info(f"  - pixel_array shape: {mask_frames.shape}")
    logger.info(f"  - pixel_array dtype: {mask_frames.dtype}")
    logger.info(f"  - source_images ê°œìˆ˜: {len(source_images)}")
    
    # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ source_imageì˜ ImagePositionPatient í™•ì¸
    if len(source_images) > 0:
        first_pos = getattr(source_images[0], 'ImagePositionPatient', 'N/A')
        last_pos = getattr(source_images[-1], 'ImagePositionPatient', 'N/A')
        logger.info(f"  - ì²« ë²ˆì§¸ ìŠ¬ë¼ì´ìŠ¤ ImagePositionPatient: {first_pos}")
        logger.info(f"  - ë§ˆì§€ë§‰ ìŠ¬ë¼ì´ìŠ¤ ImagePositionPatient: {last_pos}")
    
    seg_dataset = Segmentation(
        source_images=source_images,
        pixel_array=mask_frames,
        segmentation_type="BINARY",
        segment_descriptions=[segment_description],
        series_instance_uid=UID(),
        series_number=1000,
        sop_instance_uid=UID(),
        instance_number=1,
        manufacturer="MAMA-MIA Team",
        manufacturer_model_name="Phase1-Segmentation",
        software_versions="1.0",
        device_serial_number="123456"
    )
    
    # ìƒì„±ëœ DICOM SEGì˜ NumberOfFrames í™•ì¸
    num_frames_in_seg = getattr(seg_dataset, 'NumberOfFrames', None)
    logger.info(f"  - ìƒì„±ëœ DICOM SEGì˜ NumberOfFrames: {num_frames_in_seg}")
    
    # 5. Save
    logger.info(f"ğŸ’¾ DICOM SEG íŒŒì¼ ì €ì¥ ì¤‘: {output_path}")
    seg_dataset.save_as(output_path)
    logger.info(f"âœ… DICOM SEG ì €ì¥ ì™„ë£Œ: {output_path}")
    
    # ì €ì¥ í›„ íŒŒì¼ í¬ê¸° í™•ì¸
    file_size = Path(output_path).stat().st_size
    logger.info(f"  - ì €ì¥ëœ íŒŒì¼ í¬ê¸°: {file_size / 1024 / 1024:.2f} MB")

# ì—°êµ¬ì‹¤ ì»´í“¨í„° ì¶”ë¡  ì‹œìŠ¤í…œ - ì™„ì „ ê°€ì´ë“œ

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”

ì´ ì‹œìŠ¤í…œì€ **ì—°êµ¬ì‹¤ ì»´í“¨í„°**ì—ì„œ MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ **Orthanc (GCP)**ì— ìë™ìœ¼ë¡œ ì—…ë¡œë“œí•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.

### ì¥ì 
- âœ… GCP ì„œë²„ ë¦¬ì†ŒìŠ¤ ì ˆì•½ (CPU/ë©”ëª¨ë¦¬)
- âœ… ì—°êµ¬ì‹¤ GPU í™œìš© (ë¹ ë¥¸ ì¶”ë¡  ì†ë„)
- âœ… GCP ë¹„ìš© ì ˆê°
- âœ… ê¸°ì¡´ Django ì½”ë“œ ë³€ê²½ ìµœì†Œí™”

---

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1ë‹¨ê³„: ì €ì¥ì†Œ í´ë¡  ë° í™˜ê²½ ì„¤ì •

```bash
# 1. ì €ì¥ì†Œ í´ë¡  (ì—°êµ¬ì‹¤ ì»´í“¨í„°)
cd ~
git clone https://github.com/your-repo/Django-React.git
cd Django-React/backend/mri_segmentation

# 2. Python ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ë˜ëŠ”
venv\Scripts\activate  # Windows

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r src/requirements.txt

# 4. GPU ë²„ì „ PyTorch ì„¤ì¹˜ (NVIDIA GPUê°€ ìˆëŠ” ê²½ìš°)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 2ë‹¨ê³„: ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ

```bash
# GCP ì„œë²„ì—ì„œ ëª¨ë¸ íŒŒì¼ ë³µì‚¬
scp user@34.42.223.43:/srv/django-react/app/backend/mri_segmentation/src/best_model.pth src/

# ë˜ëŠ” ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œ ë³µì‚¬
# ëª¨ë¸ íŒŒì¼ í¬ê¸°: ì•½ 500MB-1GB
```

### 3ë‹¨ê³„: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# env.exampleì„ .envë¡œ ë³µì‚¬
cp env.example .env

# .env íŒŒì¼ ìˆ˜ì •
nano .env
```

**.env íŒŒì¼ ë‚´ìš©:**
```bash
# Orthanc ì„œë²„ ì„¤ì •
ORTHANC_URL=http://34.42.223.43:8042
ORTHANC_USER=admin
ORTHANC_PASSWORD=your-actual-password

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
MODEL_PATH=src/best_model.pth

# ì¶”ë¡  ì„¤ì •
DEVICE=cuda  # ë˜ëŠ” cpu
THRESHOLD=0.5

# ì›Œì»¤ ì„¤ì • (ìë™ ëª¨ë“œìš©)
REQUEST_DIR=/tmp/mri_inference_requests
POLL_INTERVAL=30
```

### 4ë‹¨ê³„: ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ í™•ì¸

```bash
# Orthanc ì„œë²„ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
curl -u admin:your-password http://34.42.223.43:8042/system

# ì •ìƒ ì‘ë‹µ ì˜ˆì‹œ:
# {
#   "Name": "Orthanc",
#   "Version": "1.11.0",
#   ...
# }
```

---

## ğŸ’» ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: ìˆ˜ë™ ì‹¤í–‰ (ê°„ë‹¨)

```bash
# 1. Orthanc Web UIì—ì„œ ì‹œë¦¬ì¦ˆ ID í™•ì¸
# http://34.42.223.43:8042 ì ‘ì†

# 2. ì¶”ë¡  ì‹¤í–‰
python local_inference.py \
    --series-ids \
    "series-id-1" \
    "series-id-2" \
    "series-id-3" \
    "series-id-4"

# GPU ëª¨ë“œ (ê¶Œì¥)
python local_inference.py \
    --series-ids \
    "series-id-1" \
    "series-id-2" \
    "series-id-3" \
    "series-id-4" \
    --device cuda

# ì„ê³„ê°’ ì¡°ì •
python local_inference.py \
    --series-ids \
    "series-id-1" \
    "series-id-2" \
    "series-id-3" \
    "series-id-4" \
    --threshold 0.7
```

### ë°©ë²• 2: ìë™ ì›Œì»¤ ì‹¤í–‰ (ê¶Œì¥)

ì›Œì»¤ê°€ ìë™ìœ¼ë¡œ ìš”ì²­ì„ ê°ì§€í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.

#### 2-1. í¬ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
```bash
python local_inference_worker.py
```

#### 2-2. ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
```bash
# Linux/Mac
nohup python local_inference_worker.py > worker.log 2>&1 &

# í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep local_inference_worker

# ì¤‘ì§€
pkill -f local_inference_worker
```

#### 2-3. systemd ì„œë¹„ìŠ¤ ì‹¤í–‰ (í”„ë¡œë•ì…˜ ê¶Œì¥)

```bash
# 1. ì„œë¹„ìŠ¤ íŒŒì¼ ìˆ˜ì •
sudo nano systemd/mri-inference-worker.service

# User, WorkingDirectory, ExecStart ê²½ë¡œë¥¼ ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
# User=your-username
# WorkingDirectory=/home/your-username/Django-React/backend/mri_segmentation
# ExecStart=/home/your-username/Django-React/backend/mri_segmentation/venv/bin/python local_inference_worker.py

# 2. ì„œë¹„ìŠ¤ íŒŒì¼ ë³µì‚¬
sudo cp systemd/mri-inference-worker.service /etc/systemd/system/

# 3. ì„œë¹„ìŠ¤ í™œì„±í™” ë° ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl enable mri-inference-worker
sudo systemctl start mri-inference-worker

# 4. ìƒíƒœ í™•ì¸
sudo systemctl status mri-inference-worker

# 5. ë¡œê·¸ í™•ì¸
sudo journalctl -u mri-inference-worker -f

# 6. ì¬ì‹œì‘ (í•„ìš”ì‹œ)
sudo systemctl restart mri-inference-worker
```

---

## ğŸ”— Django ì—°ë™

### Djangoì—ì„œ ì¶”ë¡  ìš”ì²­ ìƒì„±

**backend/mri_viewer/segmentation_views.py**ì— ë‹¤ìŒ ì½”ë“œ ì¶”ê°€:

```python
import json
from pathlib import Path
from django.utils import timezone

REQUEST_DIR = Path('/tmp/mri_inference_requests')

@api_view(['POST'])
def request_local_inference(request, series_id):
    """
    ì—°êµ¬ì‹¤ ì»´í“¨í„°ì—ì„œ ì¶”ë¡  ì‹¤í–‰ ìš”ì²­
    """
    sequence_series_ids = request.data.get("sequence_series_ids", [])
    
    if len(sequence_series_ids) != 4:
        return Response({
            'success': False,
            'error': '4ê°œ ì‹œë¦¬ì¦ˆê°€ í•„ìš”í•©ë‹ˆë‹¤.'
        }, status=400)
    
    # ìš”ì²­ íŒŒì¼ ìƒì„±
    REQUEST_DIR.mkdir(exist_ok=True, parents=True)
    
    request_data = {
        'series_ids': sequence_series_ids,
        'series_id': series_id,
        'requested_at': timezone.now().isoformat(),
        'status': 'pending',
        'requested_by': request.user.username if request.user.is_authenticated else 'anonymous'
    }
    
    request_file = REQUEST_DIR / f"{series_id}_{int(timezone.now().timestamp())}.json"
    with open(request_file, 'w', encoding='utf-8') as f:
        json.dump(request_data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"âœ… ì¶”ë¡  ìš”ì²­ ìƒì„±: {request_file.name}")
    
    return Response({
        'success': True,
        'message': 'ì¶”ë¡  ìš”ì²­ì´ íì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.',
        'request_id': request_file.stem,
        'series_id': series_id
    })


@api_view(['GET'])
def check_inference_status(request, request_id):
    """
    ì¶”ë¡  ìš”ì²­ ìƒíƒœ í™•ì¸
    """
    request_files = list(REQUEST_DIR.glob(f"{request_id}.json"))
    
    if not request_files:
        return Response({
            'success': False,
            'error': 'ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        }, status=404)
    
    with open(request_files[0], 'r', encoding='utf-8') as f:
        request_data = json.load(f)
    
    return Response({
        'success': True,
        'status': request_data.get('status'),
        'requested_at': request_data.get('requested_at'),
        'started_at': request_data.get('started_at'),
        'completed_at': request_data.get('completed_at'),
        'result': request_data.get('result')
    })
```

**urls.pyì— ì¶”ê°€:**
```python
path('segmentation/request-local/<str:series_id>/', segmentation_views.request_local_inference),
path('segmentation/status/<str:request_id>/', segmentation_views.check_inference_status),
```

---

## ğŸ“Š ì„±ëŠ¥ ë° ëª¨ë‹ˆí„°ë§

### ì„±ëŠ¥ ë¹„êµ

| í™˜ê²½ | ë””ë°”ì´ìŠ¤ | ì¶”ë¡  ì‹œê°„ | ë¹„ìš© |
|------|---------|----------|------|
| ì—°êµ¬ì‹¤ (RTX 4090) | GPU | ~20ì´ˆ | ë¬´ë£Œ |
| ì—°êµ¬ì‹¤ (RTX 3090) | GPU | ~30ì´ˆ | ë¬´ë£Œ |
| ì—°êµ¬ì‹¤ (i9 CPU) | CPU | ~15ë¶„ | ë¬´ë£Œ |
| GCP (4 vCPU) | CPU | ~20ë¶„ | ìœ ë£Œ |

### ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```bash
# ì›Œì»¤ ë¡œê·¸ í™•ì¸ (systemd)
sudo journalctl -u mri-inference-worker -f

# ì›Œì»¤ ë¡œê·¸ í™•ì¸ (íŒŒì¼)
tail -f worker.log

# ìµœê·¼ 100ì¤„ í™•ì¸
tail -n 100 worker.log
```

### GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§

```bash
# NVIDIA GPU ì‚¬ìš©ë¥  í™•ì¸
watch -n 1 nvidia-smi

# ë˜ëŠ” ê°„ë‹¨íˆ
nvidia-smi
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### Q1: ì›Œì»¤ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
**í™•ì¸ ì‚¬í•­:**
1. ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
   ```bash
   ps aux | grep local_inference_worker
   # ë˜ëŠ”
   sudo systemctl status mri-inference-worker
   ```

2. ìš”ì²­ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
   ```bash
   ls -lh /tmp/mri_inference_requests/
   ```

3. ë¡œê·¸ í™•ì¸
   ```bash
   tail -f worker.log
   ```

### Q2: Orthanc ì—°ê²° ì‹¤íŒ¨
**í•´ê²°:**
```bash
# 1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
ping 34.42.223.43

# 2. Orthanc ì„œë²„ ìƒíƒœ í™•ì¸
curl http://34.42.223.43:8042/system

# 3. ì¸ì¦ ì •ë³´ í™•ì¸
curl -u admin:your-password http://34.42.223.43:8042/system
```

### Q3: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
**í•´ê²°:**
```bash
# 1. GPU ì‚¬ìš©ë¥  í™•ì¸
nvidia-smi

# 2. ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# 3. CPU ëª¨ë“œë¡œ ì „í™˜
# .env íŒŒì¼ ìˆ˜ì •: DEVICE=cpu
```

### Q4: ëª¨ë¸ íŒŒì¼ ì—†ìŒ
**í•´ê²°:**
```bash
# GCP ì„œë²„ì—ì„œ ëª¨ë¸ íŒŒì¼ ë³µì‚¬
scp user@34.42.223.43:/srv/django-react/app/backend/mri_segmentation/src/best_model.pth src/

# ë˜ëŠ” ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œ ë³µì‚¬
# ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
find ~ -name "best_model.pth"
```

---

## ğŸ”’ ë³´ì•ˆ ê¶Œì¥ì‚¬í•­

1. **ì¸ì¦ ì •ë³´ ë³´í˜¸**
   ```bash
   # .env íŒŒì¼ ê¶Œí•œ ì„¤ì •
   chmod 600 .env
   
   # .gitignoreì— ì¶”ê°€
   echo ".env" >> .gitignore
   ```

2. **ë°©í™”ë²½ ì„¤ì •**
   - GCP ì½˜ì†”ì—ì„œ ì—°êµ¬ì‹¤ ì»´í“¨í„° IPë§Œ í—ˆìš©
   - Orthanc í¬íŠ¸ (8042) ì ‘ê·¼ ì œí•œ

3. **HTTPS ì‚¬ìš© (ê¶Œì¥)**
   - Orthancì— SSL ì¸ì¦ì„œ ì„¤ì •
   - `ORTHANC_URL=https://34.42.223.43:8042`

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì´ˆê¸° ì„¤ì •
- [ ] Python í™˜ê²½ ì„¤ì • ì™„ë£Œ
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ
- [ ] ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] .env íŒŒì¼ ì„¤ì • ì™„ë£Œ
- [ ] Orthanc ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ

### ìˆ˜ë™ ì‹¤í–‰
- [ ] ì‹œë¦¬ì¦ˆ ID í™•ì¸
- [ ] ì¶”ë¡  ì‹¤í–‰ ì„±ê³µ
- [ ] Orthanc ì—…ë¡œë“œ ì„±ê³µ
- [ ] GCP Djangoì—ì„œ ê²°ê³¼ í™•ì¸

### ìë™ ì›Œì»¤
- [ ] ì›Œì»¤ ì‹¤í–‰ ì„±ê³µ
- [ ] systemd ì„œë¹„ìŠ¤ ë“±ë¡ ì™„ë£Œ
- [ ] ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ
- [ ] Django ì—°ë™ ì™„ë£Œ

---

## ğŸ“ ì§€ì› ë° ë¬¸ì˜

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. ë¡œê·¸ í™•ì¸ (`worker.log`, `journalctl`)
2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
3. GPU ìƒíƒœ í™•ì¸ (`nvidia-smi`)
4. ë¬¸ì„œ ì¬í™•ì¸

---

**ì‘ì„±ì¼**: 2026ë…„ 1ì›”
**ì‘ì„±ì**: AI Assistant
**ë²„ì „**: 1.0.0

"""
ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„œë¹„ìŠ¤ - mosec
ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡ ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì„œë¹„ìŠ¤ (í¬íŠ¸ 5003)
mosecì€ Rust ê¸°ë°˜ì˜ ê³ ì„±ëŠ¥ ëª¨ë¸ ì„œë¹™ í”„ë ˆì„ì›Œí¬ë¡œ, ë™ì  ë°°ì¹­ê³¼ íŒŒì´í”„ë¼ì¸ì„ ì§€ì›í•©ë‹ˆë‹¤.
"""
from mosec import Worker, Server
import os
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from typing import Dict, Any
from datetime import datetime
import json
import base64
import logging
from io import BytesIO

logger = logging.getLogger(__name__)

# UNet ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜ (ì›ë³¸ ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶¤)
class DoubleConv(nn.Module):
    """(Conv => BN => ReLU) * 2"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self.double_conv(x)


class UNet(nn.Module):
    """UNet ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ (ì›ë³¸ ëª¨ë¸ êµ¬ì¡°)"""
    def __init__(self, in_channels=1, out_channels=1):
        super(UNet, self).__init__()
        
        # Downsampling path (Encoder)
        self.downs = nn.ModuleList([
            DoubleConv(in_channels, 64),
            DoubleConv(64, 128),
            DoubleConv(128, 256),
            DoubleConv(256, 512)
        ])
        
        # Bottleneck
        self.bottleneck = DoubleConv(512, 1024)
        
        # Upsampling path (Decoder)
        # upsëŠ” ConvTranspose2dì™€ DoubleConvê°€ ë²ˆê°ˆì•„ ë‚˜ì˜´
        self.ups = nn.ModuleList([
            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),
            DoubleConv(1024, 512),
            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),
            DoubleConv(512, 256),
            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),
            DoubleConv(256, 128),
            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),
            DoubleConv(128, 64)
        ])
        
        # Final output layer
        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1, bias=False)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
    
    def forward(self, x):
        # Encoder path with skip connections
        skip_connections = []
        
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        
        # Bottleneck
        x = self.bottleneck(x)
        
        # Decoder path
        skip_connections = skip_connections[::-1]  # ì—­ìˆœ
        
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)  # ConvTranspose2d
            skip = skip_connections[idx // 2]
            
            # Skip connection concatenation
            if x.shape != skip.shape:
                x = nn.functional.interpolate(x, size=skip.shape[2:])
            
            x = torch.cat([skip, x], dim=1)
            x = self.ups[idx + 1](x)  # DoubleConv
        
        # Final output
        return torch.sigmoid(self.final_conv(x))

# ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ
current_dir = os.path.dirname(os.path.abspath(__file__))
# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” í”„ë¡œì íŠ¸ ë‚´ë¶€ ê²½ë¡œ)
# breast_ai_service/ml_model ë””ë ‰í† ë¦¬ì— ëª¨ë¸ íŒŒì¼ ì €ì¥

# ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ (UNet)
segmentation_model_path = os.environ.get(
    'SEGMENTATION_MODEL_PATH',
    os.path.join(current_dir, 'ml_model', 'unet_pytorch_best.pth')
)

# ë¶„ë¥˜ ëª¨ë¸ (ResNet ë“±)
classification_model_path = os.environ.get(
    'CLASSIFICATION_MODEL_PATH',
    os.path.join(current_dir, 'ml_model', 'best_breast_mri_model.pth')
)

model_loaded = False


class InferenceWorker(Worker):
    """
    ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡  ì›Œì»¤
    mosecì˜ Workerë¥¼ ìƒì†ë°›ì•„ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        super().__init__()
        # ë‘ ê°œì˜ ëª¨ë¸ ë¡œë“œ: ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ë¶„ë¥˜
        self.segmentation_model = None
        self.classification_model = None
        self.segmentation_loaded = False
        self.classification_loaded = False
        self.class_names = ['Benign', 'Malignant']  # ë¶„ë¥˜ ëª¨ë¸ìš©
        
        # 1. ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ (UNet)
        if os.path.exists(segmentation_model_path):
            try:
                print(f"ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì¤‘: {segmentation_model_path}")
                seg_loaded = torch.load(segmentation_model_path, map_location='cpu')
                
                # UNet ëª¨ë¸ ìƒì„± (ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì…ë ¥)
                self.segmentation_model = UNet(in_channels=1, out_channels=1)
                
                # state_dict ë¡œë“œ
                if isinstance(seg_loaded, dict):
                    if 'model_state_dict' in seg_loaded:
                        state_dict = seg_loaded['model_state_dict']
                    elif 'state_dict' in seg_loaded:
                        state_dict = seg_loaded['state_dict']
                    else:
                        state_dict = seg_loaded
                    
                    # final_conv.biasê°€ ìˆìœ¼ë©´ ì œê±° (ì½”ë“œì—ì„œëŠ” bias=Falseë¡œ ì„¤ì •ë¨)
                    if 'final_conv.bias' in state_dict:
                        state_dict = {k: v for k, v in state_dict.items() if k != 'final_conv.bias'}
                    
                    self.segmentation_model.load_state_dict(state_dict, strict=False)
                else:
                    # ëª¨ë¸ ê°ì²´ ìì²´ì¸ ê²½ìš°
                    self.segmentation_model = seg_loaded
                
                self.segmentation_model.eval()
                self.segmentation_loaded = True
                print(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (UNet)")
                
            except Exception as e:
                print(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
                self.segmentation_loaded = False
        else:
            print(f"âš ï¸  ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {segmentation_model_path}")
            self.segmentation_loaded = False
        
        # 2. ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ (ResNet ë“±)
        if os.path.exists(classification_model_path):
            try:
                print(f"ğŸ”„ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© ì¤‘: {classification_model_path}")
                cls_loaded = torch.load(classification_model_path, map_location='cpu')
                
                if isinstance(cls_loaded, dict):
                    if 'model_state_dict' in cls_loaded:
                        # state_dictì™€ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                        model_name = cls_loaded.get('model_name', 'unknown')
                        num_classes = cls_loaded.get('num_classes', 2)
                        self.class_names = cls_loaded.get('class_names', ['Benign', 'Malignant'])
                        
                        # ResNet ëª¨ë¸ ì•„í‚¤í…ì²˜ ì¬êµ¬ì„±
                        if 'resnet' in model_name.lower():
                            from torchvision import models
                            if '18' in model_name.lower():
                                self.classification_model = models.resnet18(pretrained=False)
                            elif '34' in model_name.lower():
                                self.classification_model = models.resnet34(pretrained=False)
                            elif '50' in model_name.lower():
                                self.classification_model = models.resnet50(pretrained=False)
                            else:
                                self.classification_model = models.resnet50(pretrained=False)
                            
                            # ë§ˆì§€ë§‰ ë ˆì´ì–´ ìˆ˜ì •
                            self.classification_model.fc = nn.Linear(self.classification_model.fc.in_features, num_classes)
                            self.classification_model.load_state_dict(cls_loaded['model_state_dict'])
                            self.classification_model.eval()
                            self.classification_loaded = True
                            print(f"âœ… ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name} ({num_classes} classes)")
                        else:
                            print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}")
                            self.classification_loaded = False
                    elif 'model' in cls_loaded:
                        self.classification_model = cls_loaded['model']
                        self.classification_model.eval()
                        self.classification_loaded = True
                        print(f"âœ… ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    else:
                        self.classification_model = cls_loaded
                        if hasattr(self.classification_model, 'eval'):
                            self.classification_model.eval()
                        self.classification_loaded = True
                        print(f"âœ… ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë”•ì…”ë„ˆë¦¬ í˜•ì‹)")
                else:
                    self.classification_model = cls_loaded
                    if hasattr(self.classification_model, 'eval'):
                        self.classification_model.eval()
                    self.classification_loaded = True
                    print(f"âœ… ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ëª¨ë¸ ê°ì²´)")
                    
            except Exception as e:
                print(f"âŒ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
                self.classification_loaded = False
        else:
            print(f"âš ï¸  ë¶„ë¥˜ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {classification_model_path}")
            self.classification_loaded = False
    
    def deserialize(self, data: bytes) -> Dict[str, Any]:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™” (JSON)"""
        try:
            request = json.loads(data.decode('utf-8'))
            return request
        except Exception as e:
            raise ValueError(f"ìš”ì²­ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    def forward(self, data):
        """
        ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰
        
        Args:
            data: ìš”ì²­ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                - image_data: ì´ë¯¸ì§€ ë°ì´í„° (base64 string)
                - image_url: ì´ë¯¸ì§€ URL
                - analysis_type: 'segmentation' ë˜ëŠ” 'classification' (ê¸°ë³¸ê°’: 'segmentation')
                - patient_id: í™˜ì ID (ì„ íƒ)
                - metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ)
        
        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # analysis_type í™•ì¸ (ê¸°ë³¸ê°’: segmentation)
        analysis_type = data.get('analysis_type', 'segmentation')
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¶„ì„
        if analysis_type == 'segmentation':
            return self._run_segmentation(data)
        # ë¶„ë¥˜ ë¶„ì„ (ì¢…ì–‘ë¶„ì„)
        elif analysis_type == 'classification':
            return self._run_classification(data)
        else:
            return {
                'success': False,
                'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì„ íƒ€ì…ì…ë‹ˆë‹¤: {analysis_type}',
                'data': None
            }
    
    def _run_segmentation(self, data):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì‹¤í–‰ (UNet)"""
        if not self.segmentation_loaded:
            return {
                'success': False,
                'error': 'ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'data': None
            }
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self._load_image(data)
            if image is None:
                return {
                    'success': False,
                    'error': 'ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'data': None
                }
            
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥
            original_size = image.size
            
            # RGBë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ëª¨ë¸ì´ in_channels=1ë¡œ í•™ìŠµë¨)
            if image.mode != 'L':
                image = image.convert('L')
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì „ì²˜ë¦¬ (256x256)
            transform = transforms.Compose([
                transforms.Resize((256, 256)),
                transforms.ToTensor(),
            ])
            
            input_tensor = transform(image).unsqueeze(0)  # [1, 1, 256, 256]
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ 
            with torch.no_grad():
                mask = self.segmentation_model(input_tensor)  # [1, 1, 256, 256]
                mask = mask.squeeze().cpu().numpy()  # [256, 256]
            
            # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
            mask_resized = Image.fromarray((mask * 255).astype(np.uint8), mode='L')
            mask_resized = mask_resized.resize(original_size, Image.BILINEAR)
            
            # ë§ˆìŠ¤í¬ë¥¼ base64ë¡œ ì¸ì½”ë”©
            buffered = BytesIO()
            mask_resized.save(buffered, format="PNG")
            mask_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            
            # ì¢…ì–‘ ì˜ì—­ ê³„ì‚°
            mask_array = np.array(mask_resized) / 255.0
            tumor_area = np.sum(mask_array > 0.5)
            total_area = mask_array.size
            tumor_percentage = (tumor_area / total_area) * 100
            
            # ê²°ê³¼ ìƒì„±
            findings = f"ì¢…ì–‘ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ. ì¢…ì–‘ ì˜ì—­: {tumor_percentage:.2f}%"
            if tumor_percentage > 10:
                recommendations = "ì¢…ì–‘ ì˜ì—­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¢…ì–‘ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì•…ì„±/ì–‘ì„± ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”."
            elif tumor_percentage > 1:
                recommendations = "ì‘ì€ ì¢…ì–‘ ì˜ì—­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¢…ì–‘ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            else:
                recommendations = "ì¢…ì–‘ ì˜ì—­ì´ ê±°ì˜ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¬ì´¬ì˜ ë˜ëŠ” ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            
            return {
                'success': True,
                'data': {
                    'mask_image': mask_base64,
                    'tumor_percentage': round(tumor_percentage, 2),
                    'findings': findings,
                    'recommendations': recommendations,
                    'patient_id': data.get('patient_id'),
                    'timestamp': datetime.now().isoformat(),
                    'model_version': 'UNet-1.0.0'
                }
            }
            
        except Exception as e:
            logger.error(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f'ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'data': None
            }
    
    def _load_image(self, data):
        """ì´ë¯¸ì§€ ë¡œë“œ í—¬í¼ ë©”ì„œë“œ"""
        image_data = data.get('image_data')
        image_url = data.get('image_url')
        
        if not image_data and not image_url:
            return None
        
        try:
            if image_data:
                # base64 ë””ì½”ë”©
                if isinstance(image_data, str):
                    if image_data.startswith('data:image'):
                        image_data = image_data.split(',')[1]
                    image_bytes = base64.b64decode(image_data)
                    return Image.open(BytesIO(image_bytes)).convert('RGB')
                else:
                    # numpy array
                    image_array = np.array(image_data)
                    if image_array.dtype != np.uint8:
                        image_array = (image_array * 255).astype(np.uint8)
                    return Image.fromarray(image_array).convert('RGB')
            elif image_url:
                import requests
                response = requests.get(image_url, timeout=10)
                response.raise_for_status()
                return Image.open(BytesIO(response.content)).convert('RGB')
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
        
        return None
    
    def _run_classification(self, data):
        """ë¶„ë¥˜ ëª¨ë¸ ì‹¤í–‰ (ì•…ì„±/ì–‘ì„± íŒë³„)"""
        if not self.classification_loaded:
            return {
                'success': False,
                'error': 'ë¶„ë¥˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'data': None
            }
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self._load_image(data)
            if image is None:
                return {
                    'success': False,
                    'error': 'ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'data': None
                }
            
            # ë¶„ë¥˜ ì „ì²˜ë¦¬ (224x224, ImageNet normalize)
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0)  # [1, 3, 224, 224]
            
            # ë¶„ë¥˜ ì¶”ë¡ 
            with torch.no_grad():
                output = self.classification_model(input_tensor)
                probabilities = torch.softmax(output, dim=1)
                prediction_idx = torch.argmax(probabilities, dim=1).item()
                confidence = float(probabilities[0][prediction_idx]) * 100
            
            # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘
            prediction = self.class_names[prediction_idx] if prediction_idx < len(self.class_names) else f'Class_{prediction_idx}'
            
            # í•œêµ­ì–´ ë³€í™˜
            class_name_kr = {
                'Benign': 'ì–‘ì„±',
                'Malignant': 'ì•…ì„±',
                'ì •ìƒ': 'ì •ìƒ',
                'ì´ìƒ': 'ì´ìƒ'
            }
            prediction_kr = class_name_kr.get(prediction, prediction)
            
            # í™•ë¥  ë”•ì…”ë„ˆë¦¬ ìƒì„±
            prob_dict = {}
            for i, prob in enumerate(probabilities[0]):
                class_name = self.class_names[i] if i < len(self.class_names) else f'Class_{i}'
                prob_dict[class_name] = float(prob) * 100
            
            # ë°œê²¬ì‚¬í•­ ë° ê¶Œì¥ì‚¬í•­ ìƒì„±
            findings = f"AI ì¢…ì–‘ ë¶„ì„ ê²°ê³¼: {prediction_kr} ({prediction}) (ì‹ ë¢°ë„ {confidence:.2f}%)"
            if prediction == 'Malignant' or prediction == 'ì•…ì„±':
                if confidence >= 80:
                    recommendations = "ì•…ì„± ì¢…ì–‘ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì „ë¬¸ì˜ ìƒë‹´ ë° ì¶”ê°€ ê²€ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                elif confidence >= 60:
                    recommendations = "ì•…ì„± ì¢…ì–‘ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                else:
                    recommendations = "ì•…ì„± ì¢…ì–‘ ê°€ëŠ¥ì„±ì´ ë‚®ì§€ë§Œ, ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            else:  # Benign
                if confidence >= 80:
                    recommendations = "ì–‘ì„± ì¢…ì–‘ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. ì •ê¸°ì ì¸ ê²€ì§„ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                elif confidence >= 60:
                    recommendations = "ì–‘ì„± ì¢…ì–‘ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì¶”ê°€ ê²€ì‚¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                else:
                    recommendations = "ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¬ì´¬ì˜ ë˜ëŠ” ì¶”ê°€ ê²€ì‚¬ë¥¼ ê³ ë ¤í•´ì£¼ì„¸ìš”."
            
            return {
                'success': True,
                'data': {
                    'prediction': prediction_kr,
                    'prediction_en': prediction,
                    'confidence': round(confidence, 2),
                    'probabilities': prob_dict,
                    'findings': findings,
                    'recommendations': recommendations,
                    'patient_id': data.get('patient_id'),
                    'timestamp': datetime.now().isoformat(),
                    'model_version': 'ResNet-1.0.0'
                }
            }
            
        except Exception as e:
            logger.error(f"ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f'ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'data': None
            }
    
    def serialize(self, data: Dict[str, Any]) -> bytes:
        """ì‘ë‹µ ë°ì´í„° ì§ë ¬í™” (JSON)"""
        return json.dumps(data, ensure_ascii=False).encode('utf-8')


if __name__ == "__main__":
    # mosec ì„œë²„ ì„¤ì •
    # í¬íŠ¸ 5003 ì‚¬ìš© (í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • ê°€ëŠ¥: export MOSEC_PORT=5003)
    port = int(os.environ.get('MOSEC_PORT', 5003))
    
    # mosecì€ ëª…ë ¹ì¤„ ì¸ìë¡œ í¬íŠ¸ë¥¼ ë°›ìœ¼ë¯€ë¡œ sys.argv ìˆ˜ì •
    import sys
    if '--port' not in sys.argv:
        sys.argv.extend(['--port', str(port)])
    
    server = Server()
    
    # ì¶”ë¡  ì›Œì»¤ ì¶”ê°€ (ì—¬ëŸ¬ ê°œ ì¶”ê°€ ì‹œ ë³‘ë ¬ ì²˜ë¦¬)
    # num íŒŒë¼ë¯¸í„°ë¡œ ì›Œì»¤ ìˆ˜ ì¡°ì • (GPU ê°œìˆ˜ ë˜ëŠ” CPU ì½”ì–´ ìˆ˜ì— ë§ì¶¤)
    server.append_worker(InferenceWorker, num=2)  # ì¶”ë¡  ì›Œì»¤ 2ê°œ
    
    # ì„œë²„ ì‹¤í–‰
    print(f"ğŸš€ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„œë¹„ìŠ¤ ì‹œì‘: http://0.0.0.0:{port}")
    server.run()


"""
ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„œë¹„ìŠ¤ - mosec
ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡ ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì„œë¹„ìŠ¤ (í¬íŠ¸ 5003)
mosecì€ Rust ê¸°ë°˜ì˜ ê³ ì„±ëŠ¥ ëª¨ë¸ ì„œë¹™ í”„ë ˆì„ì›Œí¬ë¡œ, ë™ì  ë°°ì¹­ê³¼ íŒŒì´í”„ë¼ì¸ì„ ì§€ì›í•©ë‹ˆë‹¤.
"""
from mosec import Worker, Server
from mosec.mixin import TypedMsgPackMixin
import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from typing import Dict, Any
from datetime import datetime
import json
import base64
from io import BytesIO

# ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ
current_dir = os.path.dirname(os.path.abspath(__file__))
# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” í”„ë¡œì íŠ¸ ë‚´ë¶€ ê²½ë¡œ)
# dl_service/ml_model ë””ë ‰í† ë¦¬ì— ëª¨ë¸ íŒŒì¼ ì €ì¥ (lung_cancer/ml_model êµ¬ì¡°ì™€ ë™ì¼)
model_path = os.environ.get(
    'DL_MODEL_PATH',
    os.path.join(current_dir, 'ml_model', 'best_breast_mri_model.pth')
)

model_loaded = False


class InferenceWorker(TypedMsgPackMixin, Worker):
    """
    ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡  ì›Œì»¤
    mosecì˜ Workerë¥¼ ìƒì†ë°›ì•„ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        super().__init__()
        # ëª¨ë¸ ë¡œë“œ
        self.model = None
        self.model_loaded = False
        
        if os.path.exists(model_path):
            try:
                self.model = torch.load(model_path, map_location='cpu')
                self.model.eval()
                self.model_loaded = True
                print(f"âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            except Exception as e:
                print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                self.model_loaded = False
        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            self.model_loaded = False
    
    def deserialize(self, data: bytes) -> Dict[str, Any]:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™” (JSON)"""
        try:
            request = json.loads(data.decode('utf-8'))
            return request
        except Exception as e:
            raise ValueError(f"ìš”ì²­ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    def forward(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰
        
        Args:
            data: ìš”ì²­ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                - image_data: ì´ë¯¸ì§€ ë°ì´í„° (list ë˜ëŠ” numpy array)
                - patient_id: í™˜ì ID (ì„ íƒ)
                - metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (ì„ íƒ)
        
        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.model_loaded:
            return {
                'success': False,
                'error': 'ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.',
                'data': None
            }
        
        try:
            # ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ (base64 ë˜ëŠ” URL)
            image_data = data.get('image_data')
            image_url = data.get('image_url')
            
            if not image_data and not image_url:
                return {
                    'success': False,
                    'error': 'image_data ë˜ëŠ” image_urlì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                    'data': None
                }
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            if image_data:
                # base64 ë””ì½”ë”©
                if isinstance(image_data, str):
                    if image_data.startswith('data:image'):
                        # data:image/png;base64,xxx í˜•ì‹
                        image_data = image_data.split(',')[1]
                    image_bytes = base64.b64decode(image_data)
                    image = Image.open(BytesIO(image_bytes)).convert('RGB')
                else:
                    # numpy arrayì¸ ê²½ìš°
                    image_array = np.array(image_data)
                    if image_array.dtype != np.uint8:
                        image_array = (image_array * 255).astype(np.uint8)
                    image = Image.fromarray(image_array).convert('RGB')
            else:
                # URLì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ (requests í•„ìš”)
                import requests
                response = requests.get(image_url, timeout=10)
                image = Image.open(BytesIO(response.content)).convert('RGB')
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ëª¨ë¸ì— ë§ê²Œ ì¡°ì • í•„ìš”)
            # ì¼ë°˜ì ì¸ ResNet ìŠ¤íƒ€ì¼ ì „ì²˜ë¦¬
            transform = transforms.Compose([
                transforms.Resize((224, 224)),  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            
            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                output = self.model(input_tensor)
                probabilities = torch.softmax(output, dim=1)
                prediction_idx = torch.argmax(probabilities, dim=1).item()
                confidence = float(probabilities[0][prediction_idx]) * 100
            
            # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘ (ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
            class_names = ['ì •ìƒ', 'ì´ìƒ']  # ì‹¤ì œ ëª¨ë¸ì˜ í´ë˜ìŠ¤ì— ë§ê²Œ ìˆ˜ì •
            prediction = class_names[prediction_idx] if prediction_idx < len(class_names) else f'Class_{prediction_idx}'
            
            # í™•ë¥  ë”•ì…”ë„ˆë¦¬ ìƒì„±
            prob_dict = {}
            for i, prob in enumerate(probabilities[0]):
                class_name = class_names[i] if i < len(class_names) else f'Class_{i}'
                prob_dict[class_name] = float(prob) * 100
            
            # ë°œê²¬ì‚¬í•­ ë° ê¶Œì¥ì‚¬í•­ ìƒì„±
            findings = f"AI ë¶„ì„ ê²°ê³¼: {prediction} (ì‹ ë¢°ë„ {confidence:.2f}%)"
            if confidence >= 80:
                recommendations = "ë†’ì€ ì‹ ë¢°ë„ë¡œ ì§„ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            elif confidence >= 60:
                recommendations = "ì¶”ê°€ ê²€ì‚¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            else:
                recommendations = "ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¬ì´¬ì˜ ë˜ëŠ” ì¶”ê°€ ê²€ì‚¬ë¥¼ ê³ ë ¤í•´ì£¼ì„¸ìš”."
            
            return {
                'success': True,
                'data': {
                    'prediction': prediction,
                    'confidence': round(confidence, 2),
                    'probabilities': prob_dict,
                    'findings': findings,
                    'recommendations': recommendations,
                    'patient_id': data.get('patient_id'),
                    'timestamp': datetime.now().isoformat(),
                    'model_version': '1.0.0'
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'data': None
            }
    
    def serialize(self, data: Dict[str, Any]) -> bytes:
        """ì‘ë‹µ ë°ì´í„° ì§ë ¬í™” (JSON)"""
        return json.dumps(data, ensure_ascii=False).encode('utf-8')


if __name__ == "__main__":
    # mosec ì„œë²„ ì„¤ì •
    # í¬íŠ¸ 5003 ì‚¬ìš© (í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • ê°€ëŠ¥: export MOSEC_PORT=5003)
    port = int(os.environ.get('MOSEC_PORT', 5003))
    
    server = Server()
    
    # ì¶”ë¡  ì›Œì»¤ ì¶”ê°€ (ì—¬ëŸ¬ ê°œ ì¶”ê°€ ì‹œ ë³‘ë ¬ ì²˜ë¦¬)
    # num íŒŒë¼ë¯¸í„°ë¡œ ì›Œì»¤ ìˆ˜ ì¡°ì • (GPU ê°œìˆ˜ ë˜ëŠ” CPU ì½”ì–´ ìˆ˜ì— ë§ì¶¤)
    server.append_worker(InferenceWorker, num=2)  # ì¶”ë¡  ì›Œì»¤ 2ê°œ
    
    # ì„œë²„ ì‹¤í–‰
    # mosecì€ í™˜ê²½ ë³€ìˆ˜ MOSEC_PORT ë˜ëŠ” ê¸°ë³¸ê°’ 8000 ì‚¬ìš©
    # í¬íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•˜ë ¤ë©´ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
    os.environ['MOSEC_PORT'] = str(port)
    print(f"ğŸš€ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„œë¹„ìŠ¤ ì‹œì‘: http://0.0.0.0:{port}")
    server.run()


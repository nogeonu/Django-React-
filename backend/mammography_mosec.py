#!/usr/bin/env python3
"""
ë§˜ëª¨ê·¸ë˜í”¼ AI ë¶„ì„ Mosec ì„œë¹„ìŠ¤ (í¬íŠ¸ 5007)
ResNet50 ê¸°ë°˜ 4-class ë¶„ë¥˜: Mass, Calcification, Architectural/Asymmetry, Normal
"""

import os
import io
import json
import logging
import numpy as np
import cv2
import pydicom
import requests
from PIL import Image
from typing import List, Dict

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms

from mosec import Server, Worker, get_logger

# ë¡œê¹… ì„¤ì •
logger = get_logger()
logger.setLevel(logging.INFO)

# GPU ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logger.info(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}")

# ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = os.path.expanduser("~/mammography_model/resnet50_mammography_best.pth")

# í´ë˜ìŠ¤ ì •ì˜
CLASS_NAMES = {
    0: 'Mass',
    1: 'Calcification',
    2: 'Architectural/Asymmetry',
    3: 'Normal'
}

# ImageNet ì •ê·œí™” (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê°’)
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]


def create_resnet50_model(num_classes=4):
    """ResNet50 ëª¨ë¸ ìƒì„± (4-class ë¶„ë¥˜)"""
    model = models.resnet50(pretrained=False)
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)
    return model


def otsu_threshold_optimized(image_16bit: np.ndarray):
    """
    OpenCVë¥¼ ì‚¬ìš©í•œ Otsu threshold (8ë¹„íŠ¸ ë³€í™˜ í›„ ì ìš©)
    
    Returns:
        threshold: ê³„ì‚°ëœ ì„ê³„ê°’ (16ë¹„íŠ¸ ìŠ¤ì¼€ì¼)
        binary_image: ì´ì§„ ì´ë¯¸ì§€ (0 ë˜ëŠ” 65535)
    """
    img_min, img_max = image_16bit.min(), image_16bit.max()
    if img_max > img_min:
        img_8bit = ((image_16bit.astype(np.float32) - img_min) / (img_max - img_min) * 255.0).astype(np.uint8)
    else:
        img_8bit = np.zeros_like(image_16bit, dtype=np.uint8)
    
    threshold_8bit, binary_8bit = cv2.threshold(img_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    threshold_16bit = int((threshold_8bit / 255.0) * (img_max - img_min) + img_min)
    binary_16bit = np.where(image_16bit > threshold_16bit, 65535, 0).astype(np.uint16)
    
    return threshold_16bit, binary_16bit


def find_contours_and_bounding_box(binary_image: np.ndarray):
    """
    ìœ¤ê³½ì„  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
    
    Returns:
        bounding_box: (x, y, width, height) ë˜ëŠ” None
    """
    binary_8bit = (binary_image / 256).astype(np.uint8)
    contours, _ = cv2.findContours(binary_8bit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return None
    
    largest_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(largest_contour)
    
    return (x, y, w, h)


def crop_image_with_bounding_box(image: np.ndarray, bounding_box, margin_ratio: float = 0.05):
    """
    ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìë¥´ê¸°
    
    Returns:
        cropped_image: ìë¥¸ ì´ë¯¸ì§€
    """
    x, y, w, h = bounding_box
    img_h, img_w = image.shape[:2]
    
    margin_x = int(w * margin_ratio)
    margin_y = int(h * margin_ratio)
    
    x_start = max(0, x - margin_x)
    y_start = max(0, y - margin_y)
    x_end = min(img_w, x + w + margin_x)
    y_end = min(img_h, y + h + margin_y)
    
    if len(image.shape) == 2:
        cropped_image = image[y_start:y_end, x_start:x_end]
    else:
        cropped_image = image[y_start:y_end, x_start:x_end, :]
    
    return cropped_image


def resize_image_preserve_aspect_ratio(image: np.ndarray, target_size=(512, 512)):
    """
    ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ì¡°ì •
    
    Returns:
        resized_image: í¬ê¸° ì¡°ì •ëœ ì´ë¯¸ì§€ (512x512, íŒ¨ë”© í¬í•¨)
    """
    target_h, target_w = target_size
    original_h, original_w = image.shape[:2]
    
    scale_height = target_h / original_h
    scale_width = target_w / original_w
    scale_factor = min(scale_height, scale_width)
    
    new_w = int(original_w * scale_factor)
    new_h = int(original_h * scale_factor)
    
    if len(image.shape) == 2:
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    else:
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # 512x512ë¡œ íŒ¨ë”© ì¶”ê°€ (ì¤‘ì•™ ì •ë ¬)
    if new_h < target_h or new_w < target_w:
        pad_top = (target_h - new_h) // 2
        pad_bottom = target_h - new_h - pad_top
        pad_left = (target_w - new_w) // 2
        pad_right = target_w - new_w - pad_left
        
        if len(image.shape) == 2:
            resized_image = cv2.copyMakeBorder(
                resized_image, pad_top, pad_bottom, pad_left, pad_right,
                cv2.BORDER_CONSTANT, value=0
            )
        else:
            resized_image = cv2.copyMakeBorder(
                resized_image, pad_top, pad_bottom, pad_left, pad_right,
                cv2.BORDER_CONSTANT, value=[0, 0, 0]
            )
    
    return resized_image


def preprocess_dicom_image(dicom_data: bytes, target_size=(512, 512)):
    """
    DICOM ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Args:
        dicom_data: DICOM íŒŒì¼ ë°”ì´íŠ¸ ë°ì´í„°
        target_size: ìµœì¢… ì¶œë ¥ í¬ê¸° (ê¸°ë³¸ê°’: (512, 512))
    
    Returns:
        processed_image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (512x512, uint8, RGB 3ì±„ë„)
    """
    # 1. DICOM íŒŒì¼ ì½ê¸°
    ds = pydicom.dcmread(io.BytesIO(dicom_data))
    pixel_array = ds.pixel_array
    
    # 2. uint16 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if pixel_array.dtype != np.uint16:
        rescale_slope = getattr(ds, 'RescaleSlope', 1.0)
        rescale_intercept = getattr(ds, 'RescaleIntercept', 0.0)
        medical_image = pixel_array * rescale_slope + rescale_intercept
        
        if medical_image.min() < 0:
            medical_image = medical_image + abs(medical_image.min())
        
        medical_image = medical_image.astype(np.uint16)
        
        img_max = medical_image.max()
        if img_max > 65535:
            medical_image = (medical_image / img_max * 65535).astype(np.uint16)
    else:
        medical_image = pixel_array.astype(np.uint16)
    
    # 3. MONOCHROME1 ì²˜ë¦¬ (ë°˜ì „ í•„ìš” ì‹œ)
    if hasattr(ds, 'PhotometricInterpretation') and ds.PhotometricInterpretation == "MONOCHROME1":
        medical_image = 65535 - medical_image
    
    # 4. Otsu ë°©ë²•ì„ ì‚¬ìš©í•œ ë°°ê²½ ì œê±°
    threshold, binary_image = otsu_threshold_optimized(medical_image)
    
    # 5. ìœ¤ê³½ì„  ë°©ë²•ì„ ì‚¬ìš©í•œ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
    bounding_box = find_contours_and_bounding_box(binary_image)
    
    if bounding_box is None:
        cropped_image = medical_image
    else:
        # 6. ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìë¥´ê¸°
        cropped_image = crop_image_with_bounding_box(medical_image, bounding_box)
    
    # 7. ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° íƒ€ê²Ÿ í¬ê¸°ë¡œ ì¡°ì •
    resized_image = resize_image_preserve_aspect_ratio(cropped_image, target_size)
    
    # 8. 8ë¹„íŠ¸ë¡œ ë³€í™˜
    image_8bit = (resized_image / 256).astype(np.uint8)
    
    # 9. RGB 3ì±„ë„ë¡œ ë³€í™˜ (ResNetì€ 3ì±„ë„ ì…ë ¥ í•„ìš”)
    image_rgb = cv2.cvtColor(image_8bit, cv2.COLOR_GRAY2RGB)
    
    return image_rgb


class MammographyWorker(Worker):
    """ë§˜ëª¨ê·¸ë˜í”¼ AI ë¶„ì„ ì›Œì»¤ (Orthanc API ì§ì ‘ í˜¸ì¶œ)"""
    
    def __init__(self):
        super().__init__()
        self.model = None
        self.transform = None
        logger.info(f"ğŸ’» Device: {DEVICE}")
    
    def deserialize(self, data: bytes) -> dict:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™” (Orthanc API ë°©ì‹ - MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ë™ì¼)"""
        try:
            json_data = json.loads(data.decode('utf-8'))
            logger.info(f"ğŸ“¥ ìˆ˜ì‹ í•œ ë°ì´í„° í‚¤: {list(json_data.keys())}")
            return json_data
        except Exception as e:
            logger.error(f"âŒ ì—­ì§ë ¬í™” ì˜¤ë¥˜: {str(e)}")
            raise
    
    def serialize(self, data: dict) -> bytes:
        """ê²°ê³¼ ì§ë ¬í™” (MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ë™ì¼)"""
        return json.dumps(data).encode('utf-8')
    
    def forward(self, data) -> dict:
        """
        ë§˜ëª¨ê·¸ë˜í”¼ ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡  (Orthanc API ì§ì ‘ í˜¸ì¶œ)
        
        Args:
            data: dict ë˜ëŠ” List[dict] (Mosec ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                {
                    "instance_ids": [id1, id2, id3, id4],
                    "orthanc_url": "http://localhost:8042",
                    "orthanc_auth": ["admin", "admin123"]
                }
        
        Returns:
            {"results": [...]}  # 4ê°œ ê²°ê³¼ í¬í•¨ ë”•ì…”ë„ˆë¦¬
        """
        # Mosecì´ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
        if isinstance(data, list) and len(data) > 0:
            request_data = data[0]
        elif isinstance(data, dict):
            request_data = data
        else:
            raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì…: {type(data)}")
        
        if self.model is None:
            logger.info("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model = create_resnet50_model(num_classes=4)
            
            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
            
            state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
            self.model.load_state_dict(state_dict)
            self.model.to(DEVICE)
            self.model.eval()
            
            # Transform ì •ì˜ (ImageNet ì •ê·œí™”)
            self.transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
            ])
            
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
        
        # Orthanc API ì„¤ì • (request_data ì‚¬ìš©)
        instance_ids = request_data.get("instance_ids", [])
        orthanc_url = request_data.get("orthanc_url", "http://localhost:8042")
        orthanc_auth = tuple(request_data.get("orthanc_auth", ["admin", "admin123"]))
        
        logger.info(f"ğŸ“¥ Orthancì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘: {orthanc_url}")
        logger.info(f"ğŸ“Š ì´ {len(instance_ids)}ì¥ ì´ë¯¸ì§€")
        
        results = []
        
        # Orthanc APIë¡œ ê° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
        for idx, instance_id in enumerate(instance_ids):
            try:
                # Orthanc APIë¡œ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                logger.info(f"ğŸ“¥ DICOM ë‹¤ìš´ë¡œë“œ {idx+1}/{len(instance_ids)}: {instance_id}")
                response = requests.get(
                    f"{orthanc_url}/instances/{instance_id}/file",
                    auth=orthanc_auth,
                    timeout=60
                )
                response.raise_for_status()
                dicom_bytes = response.content
                logger.info(f"âœ… DICOM ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(dicom_bytes)} bytes")
                
                # 2. DICOM ì „ì²˜ë¦¬ (Otsu + ìœ¤ê³½ì„  + í¬ë¡­ + ë¦¬ì‚¬ì´ì¦ˆ)
                image_rgb = preprocess_dicom_image(dicom_bytes, target_size=(512, 512))
                
                # 3. PIL Imageë¡œ ë³€í™˜ ë° Transform ì ìš©
                image_pil = Image.fromarray(image_rgb)
                image_tensor = self.transform(image_pil).unsqueeze(0).to(DEVICE)
                
                # 4. ëª¨ë¸ ì¶”ë¡ 
                with torch.no_grad():
                    outputs = self.model(image_tensor)
                    probabilities = torch.softmax(outputs, dim=1)[0]
                    confidence, predicted_class = torch.max(probabilities, 0)
                
                # 5. ê²°ê³¼ ìƒì„±
                class_id = predicted_class.item()
                class_name = CLASS_NAMES[class_id]
                confidence_value = confidence.item()
                
                # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥ 
                probabilities_dict = {
                    CLASS_NAMES[i]: float(probabilities[i].item())
                    for i in range(4)
                }
                
                results.append({
                    'success': True,
                    'class_id': class_id,
                    'class_name': class_name,
                    'confidence': confidence_value,
                    'probabilities': probabilities_dict
                })
                
                logger.info(f"âœ… ë¶„ë¥˜ ì™„ë£Œ {idx+1}/{len(instance_ids)}: {class_name} (ì‹ ë¢°ë„: {confidence_value:.4f})")
                
            except Exception as e:
                logger.error(f"âŒ ì¶”ë¡  ì˜¤ë¥˜ {idx+1}/{len(instance_ids)}: {str(e)}", exc_info=True)
                results.append({
                    'success': False,
                    'error': str(e)
                })
        
        # MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ë™ì¼í•˜ê²Œ ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        return {"results": results}


if __name__ == "__main__":
    logger.info("="*70)
    logger.info("ğŸš€ ë§˜ëª¨ê·¸ë˜í”¼ Mosec ì„œë¹„ìŠ¤ ì‹œì‘ (í¬íŠ¸ 5007)")
    logger.info("="*70)
    logger.info(f"ğŸ“¦ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {DEVICE}")
    logger.info(f"ğŸ“Š í´ë˜ìŠ¤: {list(CLASS_NAMES.values())}")
    logger.info("="*70)
    logger.info("âš ï¸  ëª…ë ¹ì¤„ ì¸ìë¡œ ì„¤ì •: --port 5007 --timeout 120000 --max-body-size 104857600")
    logger.info("="*70)
    
    server = Server()
    server.append_worker(
        MammographyWorker, 
        num=1, 
        max_batch_size=8,
        max_wait_time=60  # 60ì´ˆ ëŒ€ê¸°
    )
    server.run()  # ëª…ë ¹ì¤„ ì¸ìëŠ” Mosecì´ ìë™ìœ¼ë¡œ íŒŒì‹±


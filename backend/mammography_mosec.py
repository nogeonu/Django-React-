#!/usr/bin/env python3
"""
ë§˜ëª¨ê·¸ë˜í”¼ AI ë¶„ì„ Mosec ì„œë¹„ìŠ¤ (í¬íŠ¸ 5007)
ResNet50 ê¸°ë°˜ 4-class ë¶„ë¥˜: Mass, Calcification, Architectural/Asymmetry, Normal
"""

import os
import io
import json
import base64
import logging
import numpy as np
import cv2
import pydicom
from PIL import Image
from typing import List, Dict

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms

from mosec import Server, Worker, get_logger
from mosec.mixin import MsgpackMixin

# ë¡œê¹… ì„¤ì •
logger = get_logger()
logger.setLevel(logging.INFO)

# GPU ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logger.info(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}")

# ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = os.path.expanduser("~/mammography_model/resnet50_mammography_best.pth")

# í´ë˜ìŠ¤ ì •ì˜
CLASS_NAMES = {
    0: 'Mass',
    1: 'Calcification',
    2: 'Architectural/Asymmetry',
    3: 'Normal'
}

# ImageNet ì •ê·œí™” (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê°’)
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]


def create_resnet50_model(num_classes=4):
    """ResNet50 ëª¨ë¸ ìƒì„± (4-class ë¶„ë¥˜)"""
    model = models.resnet50(pretrained=False)
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)
    return model


def otsu_threshold_optimized(image_16bit: np.ndarray):
    """
    OpenCVë¥¼ ì‚¬ìš©í•œ Otsu threshold (8ë¹„íŠ¸ ë³€í™˜ í›„ ì ìš©)
    
    Returns:
        threshold: ê³„ì‚°ëœ ì„ê³„ê°’ (16ë¹„íŠ¸ ìŠ¤ì¼€ì¼)
        binary_image: ì´ì§„ ì´ë¯¸ì§€ (0 ë˜ëŠ” 65535)
    """
    img_min, img_max = image_16bit.min(), image_16bit.max()
    if img_max > img_min:
        img_8bit = ((image_16bit.astype(np.float32) - img_min) / (img_max - img_min) * 255.0).astype(np.uint8)
    else:
        img_8bit = np.zeros_like(image_16bit, dtype=np.uint8)
    
    threshold_8bit, binary_8bit = cv2.threshold(img_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    threshold_16bit = int((threshold_8bit / 255.0) * (img_max - img_min) + img_min)
    binary_16bit = np.where(image_16bit > threshold_16bit, 65535, 0).astype(np.uint16)
    
    return threshold_16bit, binary_16bit


def find_contours_and_bounding_box(binary_image: np.ndarray):
    """
    ìœ¤ê³½ì„  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
    
    Returns:
        bounding_box: (x, y, width, height) ë˜ëŠ” None
    """
    binary_8bit = (binary_image / 256).astype(np.uint8)
    contours, _ = cv2.findContours(binary_8bit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return None
    
    largest_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(largest_contour)
    
    return (x, y, w, h)


def crop_image_with_bounding_box(image: np.ndarray, bounding_box, margin_ratio: float = 0.05):
    """
    ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìë¥´ê¸°
    
    Returns:
        cropped_image: ìë¥¸ ì´ë¯¸ì§€
    """
    x, y, w, h = bounding_box
    img_h, img_w = image.shape[:2]
    
    margin_x = int(w * margin_ratio)
    margin_y = int(h * margin_ratio)
    
    x_start = max(0, x - margin_x)
    y_start = max(0, y - margin_y)
    x_end = min(img_w, x + w + margin_x)
    y_end = min(img_h, y + h + margin_y)
    
    if len(image.shape) == 2:
        cropped_image = image[y_start:y_end, x_start:x_end]
    else:
        cropped_image = image[y_start:y_end, x_start:x_end, :]
    
    return cropped_image


def resize_image_preserve_aspect_ratio(image: np.ndarray, target_size=(512, 512)):
    """
    ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ì¡°ì •
    
    Returns:
        resized_image: í¬ê¸° ì¡°ì •ëœ ì´ë¯¸ì§€ (512x512, íŒ¨ë”© í¬í•¨)
    """
    target_h, target_w = target_size
    original_h, original_w = image.shape[:2]
    
    scale_height = target_h / original_h
    scale_width = target_w / original_w
    scale_factor = min(scale_height, scale_width)
    
    new_w = int(original_w * scale_factor)
    new_h = int(original_h * scale_factor)
    
    if len(image.shape) == 2:
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    else:
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # 512x512ë¡œ íŒ¨ë”© ì¶”ê°€ (ì¤‘ì•™ ì •ë ¬)
    if new_h < target_h or new_w < target_w:
        pad_top = (target_h - new_h) // 2
        pad_bottom = target_h - new_h - pad_top
        pad_left = (target_w - new_w) // 2
        pad_right = target_w - new_w - pad_left
        
        if len(image.shape) == 2:
            resized_image = cv2.copyMakeBorder(
                resized_image, pad_top, pad_bottom, pad_left, pad_right,
                cv2.BORDER_CONSTANT, value=0
            )
        else:
            resized_image = cv2.copyMakeBorder(
                resized_image, pad_top, pad_bottom, pad_left, pad_right,
                cv2.BORDER_CONSTANT, value=[0, 0, 0]
            )
    
    return resized_image


def preprocess_dicom_image(dicom_data: bytes, target_size=(512, 512)):
    """
    DICOM ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Args:
        dicom_data: DICOM íŒŒì¼ ë°”ì´íŠ¸ ë°ì´í„°
        target_size: ìµœì¢… ì¶œë ¥ í¬ê¸° (ê¸°ë³¸ê°’: (512, 512))
    
    Returns:
        processed_image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (512x512, uint8, RGB 3ì±„ë„)
    """
    # 1. DICOM íŒŒì¼ ì½ê¸°
    ds = pydicom.dcmread(io.BytesIO(dicom_data))
    pixel_array = ds.pixel_array
    
    # 2. uint16 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if pixel_array.dtype != np.uint16:
        rescale_slope = getattr(ds, 'RescaleSlope', 1.0)
        rescale_intercept = getattr(ds, 'RescaleIntercept', 0.0)
        medical_image = pixel_array * rescale_slope + rescale_intercept
        
        if medical_image.min() < 0:
            medical_image = medical_image + abs(medical_image.min())
        
        medical_image = medical_image.astype(np.uint16)
        
        img_max = medical_image.max()
        if img_max > 65535:
            medical_image = (medical_image / img_max * 65535).astype(np.uint16)
    else:
        medical_image = pixel_array.astype(np.uint16)
    
    # 3. MONOCHROME1 ì²˜ë¦¬ (ë°˜ì „ í•„ìš” ì‹œ)
    if hasattr(ds, 'PhotometricInterpretation') and ds.PhotometricInterpretation == "MONOCHROME1":
        medical_image = 65535 - medical_image
    
    # 4. Otsu ë°©ë²•ì„ ì‚¬ìš©í•œ ë°°ê²½ ì œê±°
    threshold, binary_image = otsu_threshold_optimized(medical_image)
    
    # 5. ìœ¤ê³½ì„  ë°©ë²•ì„ ì‚¬ìš©í•œ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
    bounding_box = find_contours_and_bounding_box(binary_image)
    
    if bounding_box is None:
        cropped_image = medical_image
    else:
        # 6. ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìë¥´ê¸°
        cropped_image = crop_image_with_bounding_box(medical_image, bounding_box)
    
    # 7. ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° íƒ€ê²Ÿ í¬ê¸°ë¡œ ì¡°ì •
    resized_image = resize_image_preserve_aspect_ratio(cropped_image, target_size)
    
    # 8. 8ë¹„íŠ¸ë¡œ ë³€í™˜
    image_8bit = (resized_image / 256).astype(np.uint8)
    
    # 9. RGB 3ì±„ë„ë¡œ ë³€í™˜ (ResNetì€ 3ì±„ë„ ì…ë ¥ í•„ìš”)
    image_rgb = cv2.cvtColor(image_8bit, cv2.COLOR_GRAY2RGB)
    
    return image_rgb


class MammographyWorker(MsgpackMixin, Worker):
    """ë§˜ëª¨ê·¸ë˜í”¼ AI ë¶„ì„ ì›Œì»¤"""
    
    def __init__(self):
        super().__init__()
        self.model = None
        self.transform = None
    
    def forward(self, data: List[Dict]) -> List[Dict]:
        """
        ë§˜ëª¨ê·¸ë˜í”¼ ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡ 
        
        Args:
            data: [{"dicom_data": base64_encoded_dicom}, ...]
        
        Returns:
            [{"class_id": int, "class_name": str, "confidence": float, "probabilities": dict}, ...]
        """
        if self.model is None:
            logger.info("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model = create_resnet50_model(num_classes=4)
            
            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
            
            state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
            self.model.load_state_dict(state_dict)
            self.model.to(DEVICE)
            self.model.eval()
            
            # Transform ì •ì˜ (ImageNet ì •ê·œí™”)
            self.transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
            ])
            
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
        
        results = []
        
        for item in data:
            try:
                # 1. DICOM ë°ì´í„° ë””ì½”ë”©
                dicom_base64 = item.get('dicom_data')
                if not dicom_base64:
                    raise ValueError("dicom_dataê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                dicom_bytes = base64.b64decode(dicom_base64)
                
                # 2. DICOM ì „ì²˜ë¦¬ (Otsu + ìœ¤ê³½ì„  + í¬ë¡­ + ë¦¬ì‚¬ì´ì¦ˆ)
                image_rgb = preprocess_dicom_image(dicom_bytes, target_size=(512, 512))
                
                # 3. PIL Imageë¡œ ë³€í™˜ ë° Transform ì ìš©
                image_pil = Image.fromarray(image_rgb)
                image_tensor = self.transform(image_pil).unsqueeze(0).to(DEVICE)
                
                # 4. ëª¨ë¸ ì¶”ë¡ 
                with torch.no_grad():
                    outputs = self.model(image_tensor)
                    probabilities = torch.softmax(outputs, dim=1)[0]
                    confidence, predicted_class = torch.max(probabilities, 0)
                
                # 5. ê²°ê³¼ ìƒì„±
                class_id = predicted_class.item()
                class_name = CLASS_NAMES[class_id]
                confidence_value = confidence.item()
                
                # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥ 
                probabilities_dict = {
                    CLASS_NAMES[i]: float(probabilities[i].item())
                    for i in range(4)
                }
                
                results.append({
                    'success': True,
                    'class_id': class_id,
                    'class_name': class_name,
                    'confidence': confidence_value,
                    'probabilities': probabilities_dict
                })
                
                logger.info(f"âœ… ë¶„ë¥˜ ì™„ë£Œ: {class_name} (ì‹ ë¢°ë„: {confidence_value:.4f})")
                
            except Exception as e:
                logger.error(f"âŒ ì¶”ë¡  ì˜¤ë¥˜: {str(e)}", exc_info=True)
                results.append({
                    'success': False,
                    'error': str(e)
                })
        
        return results


if __name__ == "__main__":
    logger.info("="*70)
    logger.info("ğŸš€ ë§˜ëª¨ê·¸ë˜í”¼ Mosec ì„œë¹„ìŠ¤ ì‹œì‘ (í¬íŠ¸ 5007)")
    logger.info("="*70)
    logger.info(f"ğŸ“¦ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {DEVICE}")
    logger.info(f"ğŸ“Š í´ë˜ìŠ¤: {list(CLASS_NAMES.values())}")
    logger.info("="*70)
    
    server = Server()
    server.append_worker(
        MammographyWorker, 
        num=1, 
        max_batch_size=8,
        max_wait_time=60  # 60ì´ˆ ëŒ€ê¸°
    )
    server.run()


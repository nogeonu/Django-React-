#!/usr/bin/env python3
"""
ë§˜ëª¨ê·¸ë˜í”¼ AI ë¶„ì„ Mosec ì„œë¹„ìŠ¤ (í¬íŠ¸ 5007)
ResNet50 ê¸°ë°˜ 4-class ë¶„ë¥˜: Mass, Calcification, Architectural/Asymmetry, Normal
"""

import os
import io
import json
import logging
import base64
import numpy as np
import cv2
import pydicom
import requests
from PIL import Image
from typing import List, Dict, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms

from mosec import Server, Worker, get_logger

# ë¡œê¹… ì„¤ì •
logger = get_logger()
logger.setLevel(logging.INFO)

# GPU ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logger.info(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}")

# ëª¨ë¸ ê²½ë¡œ
MODEL_PATH = os.path.expanduser("~/mammography_model/resnet50_mammography_best.pth")

# í´ë˜ìŠ¤ ì •ì˜
CLASS_NAMES = {
    0: 'Mass',
    1: 'Calcification',
    2: 'Architectural/Asymmetry',
    3: 'Normal'
}

# ImageNet ì •ê·œí™” (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê°’)
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]


def create_resnet50_model(num_classes=4):
    """ResNet50 ëª¨ë¸ ìƒì„± (4-class ë¶„ë¥˜)"""
    model = models.resnet50(pretrained=False)
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)
    return model


def generate_gradcam(model, image_tensor, target_class, original_image_shape):
    """
    Grad-CAM íˆíŠ¸ë§µ ìƒì„±
    
    Args:
        model: ResNet50 ëª¨ë¸
        image_tensor: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ [1, 3, H, W] (requires_grad=True)
        target_class: íƒ€ê²Ÿ í´ë˜ìŠ¤ ì¸ë±ìŠ¤
        original_image_shape: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (H, W)
    
    Returns:
        heatmap: Grad-CAM íˆíŠ¸ë§µ (numpy array, 0-1 normalized)
    """
    model.eval()
    
    # ë§ˆì§€ë§‰ convolutional layer (ResNet50ì˜ layer4)
    target_layer = model.layer4
    
    # Gradientì™€ activation ì €ì¥
    gradients = []
    activations = []
    
    def backward_hook(module, grad_input, grad_output):
        if grad_output[0] is not None:
            gradients.append(grad_output[0].cpu().data.numpy())
    
    def forward_hook(module, input, output):
        activations.append(output.cpu().data.numpy())
    
    # Hook ë“±ë¡
    handle_backward = target_layer.register_full_backward_hook(backward_hook)
    handle_forward = target_layer.register_forward_hook(forward_hook)
    
    try:
        # Forward pass (gradient ê³„ì‚°ì„ ìœ„í•´ no_grad ì‚¬ìš© ì•ˆ í•¨)
        output = model(image_tensor)
        
        # Target classì— ëŒ€í•œ gradient ê³„ì‚°
        model.zero_grad()
        class_loss = output[0, target_class]
        class_loss.backward()
        
        # Grad-CAM ê³„ì‚°
        if len(gradients) == 0 or len(activations) == 0:
            logger.warning("âš ï¸ Grad-CAM: gradients ë˜ëŠ” activationsê°€ ë¹„ì–´ìˆìŒ")
            return None
        
        gradients_val = gradients[0][0]  # [C, H, W]
        activations_val = activations[0][0]  # [C, H, W]
        
        # ê° ì±„ë„ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ê³„ì‚° (gradientì˜ í‰ê· )
        weights = np.mean(gradients_val, axis=(1, 2))  # [C]
        
        # ê°€ì¤‘ì¹˜ í•©ì‚°ìœ¼ë¡œ CAM ìƒì„±
        cam = np.zeros(activations_val.shape[1:], dtype=np.float32)  # [H, W]
        for i, w in enumerate(weights):
            cam += w * activations_val[i]
        
        # ReLU ì ìš© (ì–‘ìˆ˜ ê°’ë§Œ)
        cam = np.maximum(cam, 0)
        
        # ì •ê·œí™”
        if cam.max() > 0:
            cam = cam / (cam.max() + 1e-8)
        else:
            logger.warning("âš ï¸ Grad-CAM: ëª¨ë“  ê°’ì´ 0ì…ë‹ˆë‹¤")
            return None
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        cam_resized = cv2.resize(cam, (original_image_shape[1], original_image_shape[0]))
        
        return cam_resized
        
    except Exception as e:
        logger.error(f"âŒ Grad-CAM ìƒì„± ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return None
    finally:
        # Hook ì œê±°
        handle_backward.remove()
        handle_forward.remove()


def create_gradcam_overlay_on_dicom(dicom_bytes, heatmap, crop_info, alpha=0.5):
    """
    ì›ë³¸ DICOM ì´ë¯¸ì§€ì™€ Grad-CAM íˆíŠ¸ë§µì„ ì˜¤ë²„ë ˆì´ (í¬ë¡­ ì •ë³´ ë°˜ì˜)
    
    Args:
        dicom_bytes: ì›ë³¸ DICOM íŒŒì¼ ë°”ì´íŠ¸
        heatmap: Grad-CAM íˆíŠ¸ë§µ (numpy array, float32, 0-1, í¬ë¡­ëœ ì´ë¯¸ì§€ ê¸°ì¤€ 512x512)
        crop_info: í¬ë¡­ ì •ë³´ {"bbox": (x, y, w, h), "original_shape": (H, W)}
        alpha: íˆíŠ¸ë§µ íˆ¬ëª…ë„ (0-1, ê¸°ë³¸ê°’ 0.5)
    
    Returns:
        overlay_base64: ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ì˜ base64 ë¬¸ìì—´
    """
    try:
        # DICOM íŒŒì¼ ì½ê¸°
        dcm = pydicom.dcmread(io.BytesIO(dicom_bytes))
        pixel_array = dcm.pixel_array
        
        # MONOCHROME1 ì²˜ë¦¬ (ë°˜ì „)
        if hasattr(dcm, 'PhotometricInterpretation') and dcm.PhotometricInterpretation == "MONOCHROME1":
            pixel_array = pixel_array.max() - pixel_array
        
        # ì •ê·œí™” (0-255)
        pixel_min = pixel_array.min()
        pixel_max = pixel_array.max()
        if pixel_max > pixel_min:
            pixel_normalized = ((pixel_array - pixel_min) / (pixel_max - pixel_min) * 255).astype(np.uint8)
        else:
            pixel_normalized = np.zeros_like(pixel_array, dtype=np.uint8)
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜
        if len(pixel_normalized.shape) == 2:
            dicom_rgb = cv2.cvtColor(pixel_normalized, cv2.COLOR_GRAY2RGB)
        else:
            dicom_rgb = pixel_normalized
        
        # ì›ë³¸ í¬ê¸°ì˜ ë¹ˆ íˆíŠ¸ë§µ ìƒì„±
        original_h, original_w = crop_info["original_shape"]
        heatmap_full = np.zeros((original_h, original_w), dtype=np.float32)
        
        bbox = crop_info["bbox"]
        if bbox is not None:
            x, y, w, h = bbox
            
            # íˆíŠ¸ë§µì„ í¬ë¡­ëœ ì˜ì—­ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            heatmap_cropped = cv2.resize(heatmap, (w, h), interpolation=cv2.INTER_LINEAR)
            
            # ì›ë³¸ ì´ë¯¸ì§€ì˜ í¬ë¡­ ì˜ì—­ì— íˆíŠ¸ë§µ ë°°ì¹˜
            heatmap_full[y:y+h, x:x+w] = heatmap_cropped
        else:
            # í¬ë¡­ì´ ì—†ì—ˆë‹¤ë©´ ì „ì²´ ì˜ì—­ì— ë¦¬ì‚¬ì´ì¦ˆ
            heatmap_full = cv2.resize(heatmap, (original_w, original_h), interpolation=cv2.INTER_LINEAR)
        
        # ì„ê³„ê°’ ì ìš©: ìƒìœ„ 30% ì´ìƒì˜ í™œì„±í™” ì˜ì—­ë§Œ í‘œì‹œ
        threshold = 0.3
        heatmap_thresholded = np.where(heatmap_full >= threshold, heatmap_full, 0)
        
        # íˆíŠ¸ë§µì„ ì»¬ëŸ¬ë§µìœ¼ë¡œ ë³€í™˜ (JET ì»¬ëŸ¬ë§µ)
        heatmap_uint8 = (heatmap_thresholded * 255).astype(np.uint8)
        heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
        
        # RGBë¡œ ë³€í™˜ (OpenCVëŠ” BGR ì‚¬ìš©)
        heatmap_rgb = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
        
        # ì„ê³„ê°’ ì´í•˜ ì˜ì—­ì€ íˆ¬ëª…í•˜ê²Œ ì²˜ë¦¬ (ë§ˆìŠ¤í¬ ìƒì„±)
        mask = (heatmap_thresholded > 0).astype(np.uint8)
        mask_3ch = np.stack([mask, mask, mask], axis=-1)
        
        # ì›ë³¸ ì´ë¯¸ì§€ì™€ íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ (ë§ˆìŠ¤í¬ ì ìš©)
        overlay = dicom_rgb.copy()
        overlay = np.where(mask_3ch > 0, 
                          cv2.addWeighted(dicom_rgb, 1 - alpha, heatmap_rgb, alpha, 0),
                          dicom_rgb)
        
        # PNGë¡œ ì¸ì½”ë”©
        _, buffer = cv2.imencode('.png', cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))
        overlay_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return overlay_base64
        
    except Exception as e:
        logger.error(f"âŒ DICOM ì˜¤ë²„ë ˆì´ ìƒì„± ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return None


def otsu_threshold_optimized(image_16bit: np.ndarray):
    """
    OpenCVë¥¼ ì‚¬ìš©í•œ Otsu threshold (8ë¹„íŠ¸ ë³€í™˜ í›„ ì ìš©)
    
    Returns:
        threshold: ê³„ì‚°ëœ ì„ê³„ê°’ (16ë¹„íŠ¸ ìŠ¤ì¼€ì¼)
        binary_image: ì´ì§„ ì´ë¯¸ì§€ (0 ë˜ëŠ” 65535)
    """
    img_min, img_max = image_16bit.min(), image_16bit.max()
    if img_max > img_min:
        img_8bit = ((image_16bit.astype(np.float32) - img_min) / (img_max - img_min) * 255.0).astype(np.uint8)
    else:
        img_8bit = np.zeros_like(image_16bit, dtype=np.uint8)
    
    threshold_8bit, binary_8bit = cv2.threshold(img_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    threshold_16bit = int((threshold_8bit / 255.0) * (img_max - img_min) + img_min)
    binary_16bit = np.where(image_16bit > threshold_16bit, 65535, 0).astype(np.uint16)
    
    return threshold_16bit, binary_16bit


def find_contours_and_bounding_box(binary_image: np.ndarray):
    """
    ìœ¤ê³½ì„  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
    
    Returns:
        bounding_box: (x, y, width, height) ë˜ëŠ” None
    """
    binary_8bit = (binary_image / 256).astype(np.uint8)
    contours, _ = cv2.findContours(binary_8bit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return None
    
    largest_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(largest_contour)
    
    return (x, y, w, h)


def crop_image_with_bounding_box(image: np.ndarray, bounding_box, margin_ratio: float = 0.05):
    """
    ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìë¥´ê¸°
    
    Returns:
        cropped_image: ìë¥¸ ì´ë¯¸ì§€
    """
    x, y, w, h = bounding_box
    img_h, img_w = image.shape[:2]
    
    margin_x = int(w * margin_ratio)
    margin_y = int(h * margin_ratio)
    
    x_start = max(0, x - margin_x)
    y_start = max(0, y - margin_y)
    x_end = min(img_w, x + w + margin_x)
    y_end = min(img_h, y + h + margin_y)
    
    if len(image.shape) == 2:
        cropped_image = image[y_start:y_end, x_start:x_end]
    else:
        cropped_image = image[y_start:y_end, x_start:x_end, :]
    
    return cropped_image


def resize_image_preserve_aspect_ratio(image: np.ndarray, target_size=(512, 512)):
    """
    ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ì¡°ì •
    
    Returns:
        resized_image: í¬ê¸° ì¡°ì •ëœ ì´ë¯¸ì§€ (512x512, íŒ¨ë”© í¬í•¨)
    """
    target_h, target_w = target_size
    original_h, original_w = image.shape[:2]
    
    scale_height = target_h / original_h
    scale_width = target_w / original_w
    scale_factor = min(scale_height, scale_width)
    
    new_w = int(original_w * scale_factor)
    new_h = int(original_h * scale_factor)
    
    if len(image.shape) == 2:
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    else:
        resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # 512x512ë¡œ íŒ¨ë”© ì¶”ê°€ (ì¤‘ì•™ ì •ë ¬)
    if new_h < target_h or new_w < target_w:
        pad_top = (target_h - new_h) // 2
        pad_bottom = target_h - new_h - pad_top
        pad_left = (target_w - new_w) // 2
        pad_right = target_w - new_w - pad_left
        
        if len(image.shape) == 2:
            resized_image = cv2.copyMakeBorder(
                resized_image, pad_top, pad_bottom, pad_left, pad_right,
                cv2.BORDER_CONSTANT, value=0
            )
        else:
            resized_image = cv2.copyMakeBorder(
                resized_image, pad_top, pad_bottom, pad_left, pad_right,
                cv2.BORDER_CONSTANT, value=[0, 0, 0]
            )
    
    return resized_image


def preprocess_dicom_image(dicom_data: bytes, target_size=(512, 512)):
    """
    DICOM ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Args:
        dicom_data: DICOM íŒŒì¼ ë°”ì´íŠ¸ ë°ì´í„°
        target_size: ìµœì¢… ì¶œë ¥ í¬ê¸° (ê¸°ë³¸ê°’: (512, 512))
    
    Returns:
        processed_image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (512x512, uint8, RGB 3ì±„ë„)
        crop_info: í¬ë¡­ ì •ë³´ ë”•ì…”ë„ˆë¦¬ {"bbox": (x, y, w, h), "original_shape": (H, W)}
    """
    # 1. DICOM íŒŒì¼ ì½ê¸°
    ds = pydicom.dcmread(io.BytesIO(dicom_data))
    pixel_array = ds.pixel_array
    original_shape = pixel_array.shape  # ì›ë³¸ í¬ê¸° ì €ì¥
    
    # 2. uint16 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if pixel_array.dtype != np.uint16:
        rescale_slope = getattr(ds, 'RescaleSlope', 1.0)
        rescale_intercept = getattr(ds, 'RescaleIntercept', 0.0)
        medical_image = pixel_array * rescale_slope + rescale_intercept
        
        if medical_image.min() < 0:
            medical_image = medical_image + abs(medical_image.min())
        
        medical_image = medical_image.astype(np.uint16)
        
        img_max = medical_image.max()
        if img_max > 65535:
            medical_image = (medical_image / img_max * 65535).astype(np.uint16)
    else:
        medical_image = pixel_array.astype(np.uint16)
    
    # 3. MONOCHROME1 ì²˜ë¦¬ (ë°˜ì „ í•„ìš” ì‹œ)
    if hasattr(ds, 'PhotometricInterpretation') and ds.PhotometricInterpretation == "MONOCHROME1":
        medical_image = 65535 - medical_image
    
    # 4. Otsu ë°©ë²•ì„ ì‚¬ìš©í•œ ë°°ê²½ ì œê±°
    threshold, binary_image = otsu_threshold_optimized(medical_image)
    
    # 5. ìœ¤ê³½ì„  ë°©ë²•ì„ ì‚¬ìš©í•œ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
    bounding_box = find_contours_and_bounding_box(binary_image)
    
    crop_info = {
        "bbox": bounding_box,  # (x, y, w, h) ë˜ëŠ” None
        "original_shape": original_shape  # (H, W)
    }
    
    if bounding_box is None:
        cropped_image = medical_image
    else:
        # 6. ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìë¥´ê¸°
        cropped_image = crop_image_with_bounding_box(medical_image, bounding_box)
    
    # 7. ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° íƒ€ê²Ÿ í¬ê¸°ë¡œ ì¡°ì •
    resized_image = resize_image_preserve_aspect_ratio(cropped_image, target_size)
    
    # 8. 8ë¹„íŠ¸ë¡œ ë³€í™˜
    image_8bit = (resized_image / 256).astype(np.uint8)
    
    # 9. RGB 3ì±„ë„ë¡œ ë³€í™˜ (ResNetì€ 3ì±„ë„ ì…ë ¥ í•„ìš”)
    image_rgb = cv2.cvtColor(image_8bit, cv2.COLOR_GRAY2RGB)
    
    return image_rgb, crop_info


class MammographyWorker(Worker):
    """ë§˜ëª¨ê·¸ë˜í”¼ AI ë¶„ì„ ì›Œì»¤ (Orthanc API ì§ì ‘ í˜¸ì¶œ)"""
    
    def __init__(self):
        super().__init__()
        self.model = None
        self.transform = None
        logger.info(f"ğŸ’» Device: {DEVICE}")
    
    def deserialize(self, data: bytes) -> dict:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™” (Orthanc API ë°©ì‹ - MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ë™ì¼)"""
        try:
            json_data = json.loads(data.decode('utf-8'))
            logger.info(f"ğŸ“¥ ìˆ˜ì‹ í•œ ë°ì´í„° í‚¤: {list(json_data.keys())}")
            return json_data
        except Exception as e:
            logger.error(f"âŒ ì—­ì§ë ¬í™” ì˜¤ë¥˜: {str(e)}")
            raise
    
    def serialize(self, data: dict) -> bytes:
        """ê²°ê³¼ ì§ë ¬í™” - forwardê°€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë©´ ê° í•­ëª©ì´ ì—¬ê¸°ë¡œ ì „ë‹¬ë¨"""
        logger.info(f"ğŸ“¦ serialize ì…ë ¥ íƒ€ì…: {type(data)}")
        
        # forwardê°€ [{"results": [...]}]ë¥¼ ë°˜í™˜í•˜ë©´, 
        # Mosecì´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜ë³µí•˜ë©´ì„œ ê° ë”•ì…”ë„ˆë¦¬ë¥¼ serializeì— ì „ë‹¬
        if not isinstance(data, dict):
            logger.error(f"âŒ serialize ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì…: {type(data)}, ê°’: {str(data)[:200]}")
            data = {"error": f"Invalid data type: {type(data)}"}
        
        json_str = json.dumps(data)
        logger.info(f"ğŸ“¦ JSON ê¸¸ì´: {len(json_str)} bytes, í‚¤: {list(data.keys()) if isinstance(data, dict) else 'N/A'}")
        return json_str.encode('utf-8')
    
    def forward(self, data) -> list:
        """
        ë§˜ëª¨ê·¸ë˜í”¼ ì´ë¯¸ì§€ ë¶„ë¥˜ ì¶”ë¡  (Orthanc API ì§ì ‘ í˜¸ì¶œ)
        
        Args:
            data: dict ë˜ëŠ” List[dict] (Mosec ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                {
                    "instance_ids": [id1, id2, id3, id4],
                    "orthanc_url": "http://localhost:8042",
                    "orthanc_auth": ["admin", "admin123"]
                }
        
        Returns:
            {"results": [...]}  # 4ê°œ ê²°ê³¼ í¬í•¨ ë”•ì…”ë„ˆë¦¬
        """
        # Mosecì´ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
        if isinstance(data, list) and len(data) > 0:
            request_data = data[0]
        elif isinstance(data, dict):
            request_data = data
        else:
            raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° íƒ€ì…: {type(data)}")
        
        if self.model is None:
            logger.info("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model = create_resnet50_model(num_classes=4)
            
            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
            
            state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
            self.model.load_state_dict(state_dict)
            self.model.to(DEVICE)
            self.model.eval()
            
            # Transform ì •ì˜ (ImageNet ì •ê·œí™”)
            self.transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
            ])
            
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
        
        # Orthanc API ì„¤ì • (request_data ì‚¬ìš©)
        instance_ids = request_data.get("instance_ids", [])
        orthanc_url = request_data.get("orthanc_url", "http://localhost:8042")
        orthanc_auth = tuple(request_data.get("orthanc_auth", ["admin", "admin123"]))
        
        logger.info(f"ğŸ“¥ Orthancì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘: {orthanc_url}")
        logger.info(f"ğŸ“Š ì´ {len(instance_ids)}ì¥ ì´ë¯¸ì§€")
        
        results = []
        
        # Orthanc APIë¡œ ê° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
        for idx, instance_id in enumerate(instance_ids):
            try:
                # Orthanc APIë¡œ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                logger.info(f"ğŸ“¥ DICOM ë‹¤ìš´ë¡œë“œ {idx+1}/{len(instance_ids)}: {instance_id}")
                response = requests.get(
                    f"{orthanc_url}/instances/{instance_id}/file",
                    auth=orthanc_auth,
                    timeout=60
                )
                response.raise_for_status()
                dicom_bytes = response.content
                logger.info(f"âœ… DICOM ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(dicom_bytes)} bytes")
                
                # 2. DICOM ì „ì²˜ë¦¬ (Otsu + ìœ¤ê³½ì„  + í¬ë¡­ + ë¦¬ì‚¬ì´ì¦ˆ)
                image_rgb, crop_info = preprocess_dicom_image(dicom_bytes, target_size=(512, 512))
                original_shape = image_rgb.shape[:2]  # (H, W) ì €ì¥
                
                # 3. PIL Imageë¡œ ë³€í™˜ ë° Transform ì ìš©
                image_pil = Image.fromarray(image_rgb)
                image_tensor = self.transform(image_pil).unsqueeze(0).to(DEVICE)
                
                # 4. ëª¨ë¸ ì¶”ë¡  (Grad-CAMì„ ìœ„í•´ gradient í™œì„±í™”)
                image_tensor_grad = image_tensor.clone().requires_grad_(True)
                outputs = self.model(image_tensor_grad)
                probabilities = torch.softmax(outputs, dim=1)[0]
                confidence, predicted_class = torch.max(probabilities, 0)
                
                # 5. Grad-CAM ìƒì„± ë° ì›ë³¸ DICOMì— ì˜¤ë²„ë ˆì´ (ë³‘ë³€ í´ë˜ìŠ¤ì—ë§Œ)
                gradcam_overlay_base64 = None
                class_id = predicted_class.item()
                class_name = CLASS_NAMES[class_id]
                
                # Normal í´ë˜ìŠ¤ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ Grad-CAM ìƒì„±
                if class_name != 'Normal':
                    try:
                        heatmap = generate_gradcam(
                            self.model, 
                            image_tensor_grad, 
                            class_id,
                            original_shape
                        )
                        
                        if heatmap is not None:
                            # ì›ë³¸ DICOM ì´ë¯¸ì§€ì— íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ (í¬ë¡­ ì •ë³´ ì‚¬ìš©)
                            gradcam_overlay_base64 = create_gradcam_overlay_on_dicom(
                                dicom_bytes, 
                                heatmap, 
                                crop_info,  # í¬ë¡­ ì •ë³´ ì „ë‹¬
                                alpha=0.5
                            )
                            logger.info(f"âœ… Grad-CAM ì˜¤ë²„ë ˆì´ ìƒì„± ì™„ë£Œ {idx+1}/{len(instance_ids)} - {class_name} (bbox: {crop_info['bbox']})")
                        else:
                            logger.warning(f"âš ï¸ Grad-CAM ìƒì„± ì‹¤íŒ¨ {idx+1}/{len(instance_ids)}")
                    except Exception as e:
                        logger.error(f"âŒ Grad-CAM ì˜¤ë²„ë ˆì´ ìƒì„± ì˜¤ë¥˜ {idx+1}/{len(instance_ids)}: {str(e)}", exc_info=True)
                else:
                    logger.info(f"â„¹ï¸ Normal í´ë˜ìŠ¤ - Grad-CAM ìƒì„± ìƒëµ {idx+1}/{len(instance_ids)}")
                
                # 6. ê²°ê³¼ ìƒì„±
                confidence_value = confidence.item()
                
                # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥ 
                probabilities_dict = {
                    CLASS_NAMES[i]: float(probabilities[i].item())
                    for i in range(4)
                }
                
                result_item = {
                    'success': True,
                    'class_id': class_id,
                    'class_name': class_name,
                    'confidence': confidence_value,
                    'probabilities': probabilities_dict
                }
                
                # Grad-CAM ì˜¤ë²„ë ˆì´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if gradcam_overlay_base64:
                    result_item['gradcam_overlay'] = gradcam_overlay_base64
                
                results.append(result_item)
                
                logger.info(f"âœ… ë¶„ë¥˜ ì™„ë£Œ {idx+1}/{len(instance_ids)}: {class_name} (ì‹ ë¢°ë„: {confidence_value:.4f})")
                
            except Exception as e:
                logger.error(f"âŒ ì¶”ë¡  ì˜¤ë¥˜ {idx+1}/{len(instance_ids)}: {str(e)}", exc_info=True)
                results.append({
                    'success': False,
                    'error': str(e)
                })
        
        # Mosec ë°°ì¹˜ ì²˜ë¦¬: ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ê° í•­ëª©ì´ serializeë¡œ ì „ë‹¬ë¨)
        # 4ê°œ ì´ë¯¸ì§€ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ ë°˜í™˜
        result_dict = {"results": results}
        logger.info(f"ğŸ“¤ forward ë°˜í™˜ íƒ€ì…: list, ê¸¸ì´: 1")
        logger.info(f"ğŸ“¤ results ê¸¸ì´: {len(results)}")
        return [result_dict]  # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ë°˜í™˜


if __name__ == "__main__":
    logger.info("="*70)
    logger.info("ğŸš€ ë§˜ëª¨ê·¸ë˜í”¼ Mosec ì„œë¹„ìŠ¤ ì‹œì‘ (í¬íŠ¸ 5007)")
    logger.info("="*70)
    logger.info(f"ğŸ“¦ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {DEVICE}")
    logger.info(f"ğŸ“Š í´ë˜ìŠ¤: {list(CLASS_NAMES.values())}")
    logger.info("="*70)
    logger.info("âš ï¸  ëª…ë ¹ì¤„ ì¸ìë¡œ ì„¤ì •: --port 5007 --timeout 120000 --max-body-size 104857600")
    logger.info("="*70)
    
    server = Server()
    server.append_worker(
        MammographyWorker, 
        num=1, 
        max_batch_size=8,
        max_wait_time=60  # 60ì´ˆ ëŒ€ê¸°
    )
    server.run()  # ëª…ë ¹ì¤„ ì¸ìëŠ” Mosecì´ ìë™ìœ¼ë¡œ íŒŒì‹±


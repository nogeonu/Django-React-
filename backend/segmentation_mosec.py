#!/usr/bin/env python3
"""
Mosec ê¸°ë°˜ MRI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„œë²„
Sliding Window Inferenceë¥¼ ì‚¬ìš©í•˜ì—¬ 96Ã—96Ã—96 ëª¨ë¸ë¡œ ì „ì²´ ë³¼ë¥¨ ì²˜ë¦¬
- ëª¨ë¸ í•™ìŠµ í¬ê¸°: [4, 96, 96, 96] (4 channels, 96 depth, 96 height, 96 width)
- ì‹¤ì œ ì²˜ë¦¬: [4, D, H, W] (DëŠ” ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜, ì˜ˆ: 134)
- Sliding Window: roi_size=(96, 96, 96), overlap=0.75
"""
import os
import io
import base64
import logging
import numpy as np
import torch
from monai.inferers import sliding_window_inference
import pydicom
from PIL import Image
from scipy import ndimage
from scipy.ndimage import binary_opening, binary_closing, gaussian_filter
from datetime import datetime
from pydicom.uid import generate_uid
from pydicom.dataset import Dataset, FileDataset
import requests
import tempfile

from mosec import Server, Worker, ValidationError
from monai.networks.nets import SwinUNETR

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜
MODEL_PATH = '/home/shrjsdn908/models/mri_models/Phase1_Segmentation_best.pth'
ORTHANC_URL = 'http://localhost:8042'
ORTHANC_USER = 'admin'
ORTHANC_PASSWORD = 'admin123'


def dicom_to_numpy(dicom_bytes):
    """DICOM ë°”ì´íŠ¸ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜"""
    dicom = pydicom.dcmread(io.BytesIO(dicom_bytes))
    pixel_array = dicom.pixel_array.astype(np.float32)
    
    # ì •ê·œí™”
    if pixel_array.max() > pixel_array.min():
        pixel_array = (pixel_array - pixel_array.min()) / (pixel_array.max() - pixel_array.min())
    
    return pixel_array, dicom


def create_4d_input_from_sequences(sequences_3d, target_spatial=None, target_depth=None):
    """4ê°œ ì‹œí€€ìŠ¤ì˜ 3D ë³¼ë¥¨ì„ [4, D, H, W]ë¡œ ë³€í™˜ (ì›ë³¸ í¬ê¸° ìœ ì§€ ë˜ëŠ” ë¦¬ì‚¬ì´ì¦ˆ)
    
    Args:
        sequences_3d: list of 4 numpy arrays, ê°ê° [D, H, W] í˜•íƒœ
        target_spatial: ê³µê°„ í¬ê¸° (Noneì´ë©´ ì›ë³¸ ìœ ì§€)
        target_depth: ê¹Šì´ í¬ê¸° (Noneì´ë©´ ì›ë³¸ ìœ ì§€)
    
    Returns:
        volume_4d: [4, D, H, W] numpy array
    """
    from scipy.ndimage import zoom
    
    if target_spatial is None or target_depth is None:
        # ì›ë³¸ í¬ê¸° ìœ ì§€
        volume_4d = np.stack(sequences_3d, axis=0)
        logger.info(f"âœ… 3D ë³¼ë¥¨ ìƒì„± ì™„ë£Œ (ì›ë³¸ í¬ê¸°): {volume_4d.shape} (4 channels, {volume_4d.shape[1]} depth, {volume_4d.shape[2]}Ã—{volume_4d.shape[3]})")
        return volume_4d
    
    # ë¦¬ì‚¬ì´ì¦ˆ ëª¨ë“œ
    resized_sequences = []
    for seq_3d in sequences_3d:
        d, h, w = seq_3d.shape
        zoom_factors = (target_depth / d, target_spatial / h, target_spatial / w)
        resized = zoom(seq_3d, zoom_factors, order=1)
        resized_sequences.append(resized)
    
    # [4, D, H, W]
    volume_4d = np.stack(resized_sequences, axis=0)
    
    logger.info(f"âœ… 3D ë³¼ë¥¨ ìƒì„± ì™„ë£Œ (ë¦¬ì‚¬ì´ì¦ˆ): {volume_4d.shape} (4 channels, {target_depth} depth, {target_spatial}Ã—{target_spatial})")
    return volume_4d


def create_mock_4d_input(slice_2d):
    """ë‹¨ì¼ 2D ìŠ¬ë¼ì´ìŠ¤ë¥¼ 4D MRI ì…ë ¥ìœ¼ë¡œ ë³€í™˜ (fallback)"""
    mock_3d = np.stack([slice_2d] * 96, axis=0)  # [96, H, W]
    return create_4d_input_from_sequences([mock_3d] * 4)


def postprocess_mask(mask, smooth_boundary=True):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ (ê²½ê³„ ì •í™•ë„ í–¥ìƒ)
    
    Args:
        mask: ì…ë ¥ ë§ˆìŠ¤í¬ (2D numpy array)
        smooth_boundary: ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬ ì—¬ë¶€
    
    Returns:
        mask_cleaned: í›„ì²˜ë¦¬ëœ ë§ˆìŠ¤í¬
    """
    # 1. êµ¬ë© ì±„ìš°ê¸°
    mask_filled = ndimage.binary_fill_holes(mask)
    
    # 2. ì‘ì€ ë…¸ì´ì¦ˆ ì œê±° (opening: erosion í›„ dilation)
    # ì‘ì€ ëŒì¶œë¶€ ì œê±°
    structure = np.ones((3, 3), dtype=bool)
    mask_opened = binary_opening(mask_filled, structure=structure)
    
    # 3. ì‘ì€ êµ¬ë© ì±„ìš°ê¸° (closing: dilation í›„ erosion)
    mask_closed = binary_closing(mask_opened, structure=structure)
    
    # 4. ê°€ì¥ í° ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ë§Œ ìœ ì§€
    labeled, num_features = ndimage.label(mask_closed)
    if num_features > 0:
        sizes = ndimage.sum(mask_closed, labeled, range(1, num_features + 1))
        max_label = np.argmax(sizes) + 1
        mask_cleaned = (labeled == max_label).astype(np.uint8)
    else:
        mask_cleaned = mask_closed.astype(np.uint8)
    
    # 5. ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
    if smooth_boundary:
        # ê²½ê³„ë¥¼ ì•½ê°„ ë¶€ë“œëŸ½ê²Œ (ê°€ìš°ì‹œì•ˆ í•„í„° + ì„ê³„ê°’)
        smoothed = gaussian_filter(mask_cleaned.astype(float), sigma=1.0)
        mask_cleaned = (smoothed > 0.5).astype(np.uint8)
    
    return mask_cleaned


def create_dicom_seg(original_dicom, mask_array, seg_series_uid, instance_number, original_series_id):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ DICOM SEG íŒŒì¼ë¡œ ë³€í™˜"""
    file_meta = Dataset()
    file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian
    file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.7'
    file_meta.MediaStorageSOPInstanceUID = generate_uid()
    file_meta.ImplementationClassUID = generate_uid()
    
    ds = FileDataset(None, {}, file_meta=file_meta, preamble=b"\0" * 128)
    
    # í™˜ì ì •ë³´
    ds.PatientName = getattr(original_dicom, 'PatientName', 'Anonymous')
    ds.PatientID = getattr(original_dicom, 'PatientID', 'Unknown')
    ds.PatientBirthDate = getattr(original_dicom, 'PatientBirthDate', '')
    ds.PatientSex = getattr(original_dicom, 'PatientSex', '')
    
    # ìŠ¤í„°ë”” ì •ë³´
    ds.StudyInstanceUID = getattr(original_dicom, 'StudyInstanceUID', generate_uid())
    ds.StudyDate = getattr(original_dicom, 'StudyDate', datetime.now().strftime('%Y%m%d'))
    ds.StudyTime = getattr(original_dicom, 'StudyTime', datetime.now().strftime('%H%M%S'))
    ds.StudyID = getattr(original_dicom, 'StudyID', '')
    ds.AccessionNumber = getattr(original_dicom, 'AccessionNumber', '')
    
    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œë¦¬ì¦ˆ ì •ë³´
    ds.SeriesInstanceUID = seg_series_uid
    ds.SeriesNumber = '9999'
    ds.SeriesDescription = f'AI Tumor Segmentation (Original Series: {original_series_id})'
    ds.Modality = 'SEG'
    
    # SOP Instance ì •ë³´
    ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.7'
    ds.SOPInstanceUID = file_meta.MediaStorageSOPInstanceUID
    ds.InstanceNumber = str(instance_number)
    
    # í”½ì…€ ë°ì´í„° ì •ë³´
    ds.Rows = mask_array.shape[0]
    ds.Columns = mask_array.shape[1]
    ds.SamplesPerPixel = 1
    ds.PhotometricInterpretation = 'MONOCHROME2'
    ds.BitsAllocated = 8
    ds.BitsStored = 8
    ds.HighBit = 7
    ds.PixelRepresentation = 0
    
    pixel_data = (mask_array * 255).astype(np.uint8)
    ds.PixelData = pixel_data.tobytes()
    
    # ê¸°íƒ€ ì •ë³´
    ds.ContentDate = datetime.now().strftime('%Y%m%d')
    ds.ContentTime = datetime.now().strftime('%H%M%S')
    ds.ImageType = ['DERIVED', 'SECONDARY', 'AI_SEGMENTATION']
    
    logger.info(f"âœ… DICOM SEG íŒŒì¼ ìƒì„± ì™„ë£Œ: {ds.SOPInstanceUID} (Series: {seg_series_uid}, Instance: {instance_number})")
    return ds


def create_dicom_seg_multiframe(original_dicom, mask_array_3d, seg_series_uid, start_instance_number, original_series_id):
    """
    3D ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ Multi-frame DICOM SEGë¡œ ë³€í™˜
    
    Args:
        original_dicom: ì›ë³¸ DICOM íŒŒì¼
        mask_array_3d: (96, H, W) í˜•íƒœì˜ 3D ë§ˆìŠ¤í¬
        seg_series_uid: ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œë¦¬ì¦ˆ UID
        start_instance_number: ì‹œì‘ Instance ë²ˆí˜¸
        original_series_id: ì›ë³¸ ì‹œë¦¬ì¦ˆ ID
    """
    num_frames = mask_array_3d.shape[0]
    
    file_meta = Dataset()
    file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian
    file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.66.4'  # Segmentation Storage
    file_meta.MediaStorageSOPInstanceUID = generate_uid()
    file_meta.ImplementationClassUID = generate_uid()
    
    ds = FileDataset(None, {}, file_meta=file_meta, preamble=b"\0" * 128)
    
    # í™˜ì ì •ë³´
    ds.PatientName = getattr(original_dicom, 'PatientName', 'Anonymous')
    ds.PatientID = getattr(original_dicom, 'PatientID', 'Unknown')
    ds.PatientBirthDate = getattr(original_dicom, 'PatientBirthDate', '')
    ds.PatientSex = getattr(original_dicom, 'PatientSex', '')
    
    # ìŠ¤í„°ë”” ì •ë³´
    ds.StudyInstanceUID = getattr(original_dicom, 'StudyInstanceUID', generate_uid())
    ds.StudyDate = getattr(original_dicom, 'StudyDate', datetime.now().strftime('%Y%m%d'))
    ds.StudyTime = getattr(original_dicom, 'StudyTime', datetime.now().strftime('%H%M%S'))
    ds.StudyID = getattr(original_dicom, 'StudyID', '')
    ds.AccessionNumber = getattr(original_dicom, 'AccessionNumber', '')
    
    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œë¦¬ì¦ˆ ì •ë³´
    ds.SeriesInstanceUID = seg_series_uid
    ds.SeriesNumber = '9999'
    ds.SeriesDescription = f'AI Tumor Segmentation (Original Series: {original_series_id})'
    ds.Modality = 'SEG'
    
    # SOP Instance ì •ë³´
    ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.66.4'  # Segmentation Storage
    ds.SOPInstanceUID = file_meta.MediaStorageSOPInstanceUID
    ds.InstanceNumber = str(start_instance_number)
    
    # Multi-frame í”½ì…€ ë°ì´í„° ì •ë³´
    ds.NumberOfFrames = num_frames
    ds.Rows = mask_array_3d.shape[1]
    ds.Columns = mask_array_3d.shape[2]
    ds.SamplesPerPixel = 1
    ds.PhotometricInterpretation = 'MONOCHROME2'
    ds.BitsAllocated = 8
    ds.BitsStored = 8
    ds.HighBit = 7
    ds.PixelRepresentation = 0
    
    # 96ê°œ í”„ë ˆì„ì„ í•˜ë‚˜ì˜ PixelDataë¡œ ê²°í•©
    pixel_data_list = []
    for i in range(num_frames):
        frame_data = (mask_array_3d[i] * 255).astype(np.uint8)
        pixel_data_list.append(frame_data.tobytes())
    
    ds.PixelData = b''.join(pixel_data_list)
    
    # ê¸°íƒ€ ì •ë³´
    ds.ContentDate = datetime.now().strftime('%Y%m%d')
    ds.ContentTime = datetime.now().strftime('%H%M%S')
    ds.ImageType = ['DERIVED', 'SECONDARY', 'AI_SEGMENTATION']
    
    logger.info(f"âœ… DICOM SEG íŒŒì¼ ìƒì„± ì™„ë£Œ: {ds.SOPInstanceUID} (Series: {seg_series_uid}, Instance: {start_instance_number}, Frames: {num_frames})")
    return ds


def upload_to_orthanc(dicom_dataset):
    """DICOM íŒŒì¼ì„ Orthancì— ì—…ë¡œë“œ"""
    with tempfile.NamedTemporaryFile(suffix='.dcm', delete=False) as tmp:
        try:
            dicom_dataset.save_as(tmp.name)
            with open(tmp.name, 'rb') as f:
                dicom_bytes = f.read()
            
            response = requests.post(
                f"{ORTHANC_URL}/instances",
                auth=(ORTHANC_USER, ORTHANC_PASSWORD),
                headers={'Content-Type': 'application/dicom'},
                data=dicom_bytes,
                timeout=30
            )
            response.raise_for_status()
            result = response.json()
            instance_id = result.get('ID')
            logger.info(f"âœ… Orthanc ì—…ë¡œë“œ ì™„ë£Œ: Instance ID = {instance_id}")
            return instance_id
        finally:
            if os.path.exists(tmp.name):
                os.unlink(tmp.name)


class SegmentationWorker(Worker):
    def __init__(self):
        super().__init__()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        logger.info(f"ğŸ’» Device: {self.device}")
    
    def deserialize(self, data: bytes) -> dict:
        """ìš”ì²­ ë°ì´í„° ì—­ì§ë ¬í™” (Orthanc API ë°©ì‹)"""
        try:
            import json
            import requests
            import base64
            
            json_data = json.loads(data.decode('utf-8'))
            
            logger.info(f"ğŸ“¥ ìˆ˜ì‹ í•œ ë°ì´í„° í‚¤: {list(json_data.keys())}")
            
            # Orthanc Instance ID ëª©ë¡ì´ ìˆìœ¼ë©´ Orthanc APIë¡œ ë‹¤ìš´ë¡œë“œ
            if "orthanc_instance_ids" in json_data:
                orthanc_url = json_data["orthanc_url"]
                orthanc_auth = tuple(json_data["orthanc_auth"])
                
                total_slices = len(json_data['orthanc_instance_ids'][0])
                logger.info(f"ğŸ“¥ Orthancì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘: {orthanc_url}")
                logger.info(f"ğŸ“Š ì´ {len(json_data['orthanc_instance_ids'])}ê°œ ì‹œí€€ìŠ¤, ê° {total_slices}ê°œ ìŠ¬ë¼ì´ìŠ¤ (ì „ì²´ ì²˜ë¦¬)")
                
                sequences_3d = []
                for seq_idx, seq_instances in enumerate(json_data["orthanc_instance_ids"]):
                    slices_data = []
                    for slice_idx, instance_id in enumerate(seq_instances):
                        # Orthanc APIë¡œ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                        response = requests.get(
                            f"{orthanc_url}/instances/{instance_id}/file",
                            auth=orthanc_auth,
                            timeout=30
                        )
                        response.raise_for_status()
                        
                        # Base64 ì¸ì½”ë”©
                        slices_data.append(base64.b64encode(response.content).decode('utf-8'))
                        
                        if (slice_idx + 1) % 20 == 0:
                            logger.info(f"  ì‹œí€€ìŠ¤ {seq_idx+1}: {slice_idx+1}/{len(seq_instances)} ìŠ¬ë¼ì´ìŠ¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                    
                    sequences_3d.append(slices_data)
                    logger.info(f"âœ… ì‹œí€€ìŠ¤ {seq_idx+1}/4 ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(slices_data)}ê°œ ìŠ¬ë¼ì´ìŠ¤")
                
                return {
                    "sequences_3d": sequences_3d,
                    "seg_series_uid": json_data.get("seg_series_uid"),
                    "original_series_id": json_data.get("original_series_id"),
                    "start_instance_number": json_data.get("start_instance_number", 1),
                    "total_slices": json_data.get("total_slices", total_slices)  # ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜ ì „ë‹¬
                }
            
            # ê¸°ì¡´ ë°©ì‹ (sequences_3dê°€ ì§ì ‘ í¬í•¨ëœ ê²½ìš°)
            if "sequences_3d" in json_data or "sequences" in json_data:
                logger.info("ğŸ“¥ 4-channel JSON ì…ë ¥ ê°ì§€")
                return json_data
                
        except Exception as e:
            logger.error(f"ì—­ì§ë ¬í™” ì‹¤íŒ¨: {e}", exc_info=True)
            return {"error": str(e)}
        
        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° í˜•ì‹. ë°›ì€ í‚¤: {list(json_data.keys()) if 'json_data' in locals() else 'JSON íŒŒì‹± ì‹¤íŒ¨'}")
        return {}

    def forward(self, data: dict) -> dict:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ """
        try:
            # ëª¨ë¸ ë¡œë“œ
            if self.model is None:
                logger.info(f"ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_PATH}")
                
                self.model = SwinUNETR(
                    spatial_dims=3,
                    in_channels=4,
                    out_channels=1,
                    feature_size=24,
                    use_checkpoint=False,
                )
                
                checkpoint = torch.load(MODEL_PATH, map_location=self.device, weights_only=False)
                
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint
                
                # í‚¤ ì´ë¦„ ë³€í™˜
                new_state_dict = {}
                for key, value in state_dict.items():
                    if 'lora_A' in key or 'lora_B' in key:
                        continue
                    new_key = key.replace('model.base_model.model.', '')
                    new_key = new_key.replace('.base_layer', '')
                    new_state_dict[new_key] = value
                
                self.model.load_state_dict(new_state_dict, strict=False)
                self.model = self.model.to(self.device)
                self.model.eval()
                logger.info("âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # DICOM ë³€í™˜
            if "sequences_3d" in data and len(data["sequences_3d"]) == 4:
                # 4-channel 3D DCE-MRI ëª¨ë“œ (ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ì²˜ë¦¬)
                total_slices = data.get("total_slices", len(data["sequences_3d"][0]))
                logger.info(f"ğŸ“Š 4-channel 3D DCE-MRI ì…ë ¥ ê°ì§€ ({total_slices} slices per sequence) - Sliding Window ì‚¬ìš©")
                sequences_3d = []
                original_dicom = None
                
                for seq_idx, seq_slices_b64 in enumerate(data["sequences_3d"]):
                    slices_2d = []
                    for slice_idx, slice_b64 in enumerate(seq_slices_b64):
                        slice_bytes = base64.b64decode(slice_b64)
                        slice_2d, dicom = dicom_to_numpy(slice_bytes)
                        slices_2d.append(slice_2d)
                        if seq_idx == 0 and slice_idx == len(seq_slices_b64) // 2:  # ì¤‘ì•™ ìŠ¬ë¼ì´ìŠ¤
                            original_dicom = dicom
                    
                    # [D, H, W] í˜•íƒœë¡œ ìŠ¤íƒ (DëŠ” ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜)
                    seq_volume = np.stack(slices_2d, axis=0)
                    sequences_3d.append(seq_volume)
                
                logger.info(f"âœ… 3D ë³¼ë¥¨ ë¡œë“œ ì™„ë£Œ: 4 sequences Ã— {len(seq_slices_b64)} slices")
                
                # 4D ì…ë ¥ ìƒì„±: [4, D, H, W] (ì›ë³¸ í¬ê¸° ìœ ì§€)
                volume_4d = create_4d_input_from_sequences(sequences_3d)
                logger.info(f"âœ… 4ì±„ë„ 3D ì…ë ¥ ìƒì„± ì™„ë£Œ: {volume_4d.shape}")
            elif "dicom_data" in data:
                # ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œ (JSON with base64)
                logger.info("ğŸ“Š ë‹¨ì¼ ì´ë¯¸ì§€ ì…ë ¥ ê°ì§€ (JSON)")
                dicom_bytes = base64.b64decode(data["dicom_data"])
                slice_2d, original_dicom = dicom_to_numpy(dicom_bytes)
                volume_4d = create_mock_4d_input(slice_2d)
            elif "dicom_bytes" in data:
                # ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œ (raw bytes - fallback)
                logger.info("ğŸ“Š ë‹¨ì¼ ì´ë¯¸ì§€ ì…ë ¥ ê°ì§€ (raw bytes)")
                dicom_bytes = data["dicom_bytes"]
                slice_2d, original_dicom = dicom_to_numpy(dicom_bytes)
                volume_4d = create_mock_4d_input(slice_2d)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. Keys: {list(data.keys())}")
            
            input_tensor = torch.from_numpy(volume_4d).unsqueeze(0).float().to(self.device)
            logger.info(f"ğŸ“Š Input shape: {input_tensor.shape}")
            
            # Sliding Window Inferenceë¡œ ì „ì²´ ë³¼ë¥¨ ì²˜ë¦¬
            # ëª¨ë¸ì€ 96Ã—96Ã—96 íŒ¨ì¹˜ë¡œ í•™ìŠµë˜ì—ˆì§€ë§Œ, sliding windowë¡œ ë” í° ë³¼ë¥¨ ì²˜ë¦¬ ê°€ëŠ¥
            with torch.no_grad():
                logger.info(f"ğŸ”„ Sliding Window Inference ì‹œì‘: roi_size=(96, 96, 96), overlap=0.5")
                output = sliding_window_inference(
                    inputs=input_tensor,              # [1, 4, D, H, W] (DëŠ” ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜)
                    roi_size=(96, 96, 96),            # ëª¨ë¸ì´ í•™ìŠµí•œ íŒ¨ì¹˜ í¬ê¸°
                    sw_batch_size=1,
                    predictor=self.model,
                    overlap=0.5  # 50% overlap (ë©”ëª¨ë¦¬ ì ˆì•½)
                )
                # output: [1, 1, D, H, W] (out_channels=1ì´ë¯€ë¡œ)
                pred_prob = torch.sigmoid(output).squeeze(0).squeeze(0).cpu().numpy()  # [D, H, W]
                
                # ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥ (0.5ë³´ë‹¤ ë‚®ê²Œ ì„¤ì •í•˜ë©´ ë” ë¯¼ê°í•˜ê²Œ ê²€ì¶œ)
                threshold = 0.5
                pred_mask = (pred_prob > threshold).astype(np.uint8)
                logger.info(f"ğŸ“Š Output shape: {pred_mask.shape}")
                logger.info(f"ğŸ“Š ëª¨ë¸ ì¶œë ¥ í†µê³„: min={pred_prob.min():.4f}, max={pred_prob.max():.4f}, mean={pred_prob.mean():.4f}")
                logger.info(f"ğŸ“Š ë§ˆìŠ¤í¬ í†µê³„: ì´ í”½ì…€={pred_mask.size}, ì¢…ì–‘ í”½ì…€={pred_mask.sum()}, ë¹„ìœ¨={pred_mask.sum()/pred_mask.size*100:.2f}%")
            
            # ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ í›„ì²˜ë¦¬ (ì›ë³¸ í¬ê¸° ìœ ì§€ ë˜ëŠ” ë¦¬ì‚¬ì´ì¦ˆ)
            logger.info(f"ğŸ“ {pred_mask.shape[0]}ê°œ ìŠ¬ë¼ì´ìŠ¤ ì „ì²´ í›„ì²˜ë¦¬ ì‹œì‘")
            from scipy.ndimage import zoom
            
            # ì›ë³¸ í¬ê¸° ê°€ì ¸ì˜¤ê¸° (4-channel ëª¨ë“œì—ì„œëŠ” original_dicomì—ì„œ, ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œì—ì„œëŠ” slice_2dì—ì„œ)
            if original_dicom is not None:
                h = getattr(original_dicom, 'Rows', 256)
                w = getattr(original_dicom, 'Columns', 256)
            elif 'slice_2d' in locals() and slice_2d is not None:
                h, w = slice_2d.shape
            else:
                # ëª¨ë¸ ì¶œë ¥ í¬ê¸° ì‚¬ìš©
                h, w = pred_mask.shape[1], pred_mask.shape[2]
            
            # ëª¨ë¸ ì¶œë ¥ í¬ê¸° í™•ì¸
            model_h, model_w = pred_mask.shape[1], pred_mask.shape[2]
            
            # í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë¦¬ì‚¬ì´ì¦ˆ, ê°™ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if h != model_h or w != model_w:
                logger.info(f"ğŸ“ ì›ë³¸ í¬ê¸°: {h}Ã—{w}, ëª¨ë¸ ì¶œë ¥ í¬ê¸°: {model_h}Ã—{model_w} â†’ ë¦¬ì‚¬ì´ì¦ˆ í•„ìš”")
                zoom_factors = (h / model_h, w / model_w)
                
                mask_resized_3d = []
                for i in range(pred_mask.shape[0]):
                    # í›„ì²˜ë¦¬ (ê²½ê³„ ì •í™•ë„ í–¥ìƒ)
                    mask_cleaned = postprocess_mask(pred_mask[i, :, :], smooth_boundary=True)
                    # Nearest neighborë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ê²½ê³„ ë³´ì¡´)
                    mask_resized = zoom(mask_cleaned, zoom_factors, order=0)
                    # ë¦¬ì‚¬ì´ì¦ˆ í›„ ì¶”ê°€ í›„ì²˜ë¦¬ (ê²½ê³„ ë¶€ë“œëŸ½ê²Œ)
                    mask_resized = postprocess_mask(mask_resized, smooth_boundary=True)
                    mask_resized_3d.append(mask_resized)
                
                mask_resized_3d = np.stack(mask_resized_3d, axis=0)  # [D, H, W]
            else:
                logger.info(f"ğŸ“ ì›ë³¸ í¬ê¸°ì™€ ëª¨ë¸ ì¶œë ¥ í¬ê¸° ë™ì¼: {h}Ã—{w} â†’ ë¦¬ì‚¬ì´ì¦ˆ ë¶ˆí•„ìš”")
                # í›„ì²˜ë¦¬ë§Œ ìˆ˜í–‰ (ê²½ê³„ ì •í™•ë„ í–¥ìƒ)
                mask_resized_3d = []
                for i in range(pred_mask.shape[0]):
                    mask_cleaned = postprocess_mask(pred_mask[i, :, :], smooth_boundary=True)
                    mask_resized_3d.append(mask_cleaned)
                
                mask_resized_3d = np.stack(mask_resized_3d, axis=0)  # [D, H, W]
            
            logger.info(f"âœ… {mask_resized_3d.shape[0]}ê°œ ìŠ¬ë¼ì´ìŠ¤ í›„ì²˜ë¦¬ ì™„ë£Œ: {mask_resized_3d.shape}")
            logger.info(f"ğŸ“Š í›„ì²˜ë¦¬ í›„ ë§ˆìŠ¤í¬ í†µê³„: min={mask_resized_3d.min()}, max={mask_resized_3d.max()}, ì´ í”½ì…€={mask_resized_3d.size}, ì¢…ì–‘ í”½ì…€={mask_resized_3d.sum()}")
            
            # ì¤‘ì•™ ìŠ¬ë¼ì´ìŠ¤ë¥¼ ëŒ€í‘œ ì´ë¯¸ì§€ë¡œ ì‚¬ìš© (PNG ë¯¸ë¦¬ë³´ê¸°ìš©)
            center_idx = mask_resized_3d.shape[0] // 2
            mask_resized = mask_resized_3d[center_idx]
            
            # Base64 ì¸ì½”ë”©
            mask_pil = Image.fromarray((mask_resized * 255).astype(np.uint8), mode='L')
            mask_bytes = io.BytesIO()
            mask_pil.save(mask_bytes, format='PNG')
            mask_base64 = base64.b64encode(mask_bytes.getvalue()).decode('utf-8')
            
            # í†µê³„
            tumor_pixels = int(np.sum(mask_resized))
            total_pixels = int(mask_resized.size)
            tumor_ratio = float(tumor_pixels / total_pixels)
            
            # Orthancì— ì €ì¥ (ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ Multi-frame DICOM SEG)
            seg_instance_id = None
            successful_slices = mask_resized_3d.shape[0]
            try:
                seg_series_uid = data.get('seg_series_uid')
                start_instance_number = data.get('start_instance_number', 1)
                original_series_id = data.get('original_series_id', 'unknown')
                
                dicom_seg = create_dicom_seg_multiframe(original_dicom, mask_resized_3d, seg_series_uid, start_instance_number, original_series_id)
                seg_instance_id = upload_to_orthanc(dicom_seg)
                logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ Orthanc ì €ì¥ ì™„ë£Œ: {seg_instance_id} ({successful_slices} frames)")
            except Exception as e:
                logger.error(f"âš ï¸ Orthanc ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            
            return {
                "success": True,
                "segmentation_mask_base64": mask_base64,
                "tumor_pixel_count": tumor_pixels,
                "total_pixel_count": total_pixels,
                "tumor_ratio_percent": tumor_ratio * 100,
                "image_size": [int(w), int(h)],
                "seg_instance_id": seg_instance_id,
                "saved_to_orthanc": seg_instance_id is not None,
                "successful_slices": successful_slices,  # ì²˜ë¦¬ëœ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜
                "total_slices": mask_resized_3d.shape[0]  # ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ ìˆ˜
            }
            
        except Exception as e:
            logger.error(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise ValidationError(f"Segmentation failed: {e}")
    
    def serialize(self, data: dict) -> bytes:
        """ì‘ë‹µ ë°ì´í„° ì§ë ¬í™”"""
        import json
        return json.dumps(data).encode('utf-8')


if __name__ == "__main__":
    server = Server()
    server.append_worker(
        SegmentationWorker,
        num=1,
        max_batch_size=1,
        timeout=2400000,  # 40ë¶„ (2400ì´ˆ = 2,400,000 ë°€ë¦¬ì´ˆ)
    )
    # CLI arguments are automatically parsed by Mosec
    # max_body_size is set via --max-body-size CLI arg
    # ìµœëŒ€ body size ì„¤ì •: 500MB (ë°”ì´íŠ¸ ë‹¨ìœ„)
    server.run()
